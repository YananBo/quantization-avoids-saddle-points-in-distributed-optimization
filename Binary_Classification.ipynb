{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d8ce3a-30ba-43c2-b1e2-4b81a8e787ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.016719    0.016719    0.016719    0.016719    0.016719  ]\n",
      " [-0.05097596 -0.05097596 -0.05097596 -0.05097596 -0.05097596]]\n",
      "[0.69371731 0.         0.         ... 0.         0.         0.        ]\n",
      "iteration 0 x1[0.016719 0.016719 0.016719 0.016719 0.016719] x2[-0.05097596 -0.05097596 -0.05097596 -0.05097596 -0.05097596] loss [0.69371731 0.69371731 0.69371731 0.69371731 0.69371731] losses 0.6937173087162906\n",
      "iteration 10 x1[-0.04705415 -0.045097   -0.04926223 -0.04982801 -0.04984705] x2[-0.04959002 -0.04912621 -0.05460729 -0.05147059 -0.05388146] loss [0.69221482 0.69226243 0.69207348 0.69212227 0.69207456] losses 0.6921495114508799\n",
      "iteration 20 x1[-0.07370185 -0.07377986 -0.07487756 -0.07612995 -0.07640015] x2[-0.07621936 -0.07655177 -0.07876462 -0.07591929 -0.07795281] loss [0.69090444 0.69089236 0.6907932  0.69083947 0.69076949] losses 0.6908397920853562\n",
      "iteration 30 x1[-0.10052069 -0.10243477 -0.10599537 -0.09978083 -0.10393153] x2[-0.10478392 -0.10554329 -0.10615607 -0.10477659 -0.10588176] loss [0.68894878 0.68883775 0.68866219 0.68898021 0.68876073] losses 0.6888379312821459\n",
      "iteration 40 x1[-0.12354532 -0.12627462 -0.12443419 -0.12164606 -0.1228884 ] x2[-0.12561806 -0.12966132 -0.1237362  -0.12396061 -0.123856  ] loss [0.68696969 0.68663209 0.68701803 0.68714414 0.687088  ] losses 0.6869703914290499\n",
      "iteration 50 x1[-0.15138942 -0.15336524 -0.14869402 -0.14853654 -0.14808256] x2[-0.14747907 -0.15272053 -0.1485388  -0.1451617  -0.14708372] loss [0.68427955 0.68384697 0.68437343 0.68458114 0.68449431] losses 0.6843150776402978\n",
      "iteration 60 x1[-0.16675575 -0.16989726 -0.16520988 -0.1659559  -0.16556994] x2[-0.1676076  -0.17087206 -0.16478313 -0.16205239 -0.16247601] loss [0.68206505 0.68164029 0.68235031 0.68248093 0.68247766] losses 0.6822028474274038\n",
      "iteration 70 x1[-0.18422364 -0.1843395  -0.17931667 -0.18133389 -0.17934973] x2[-0.1807425  -0.18644198 -0.18022441 -0.17768598 -0.17904635] loss [0.67996755 0.6795476  0.68035087 0.68038941 0.68043131] losses 0.6801373482194657\n",
      "iteration 80 x1[-0.19934594 -0.20058361 -0.20041399 -0.19873079 -0.19986095] x2[-0.19772499 -0.20258447 -0.19785629 -0.19504452 -0.19611715] loss [0.67757523 0.67709972 0.67748277 0.67783111 0.67766145] losses 0.6775300565562613\n",
      "iteration 90 x1[-0.22054252 -0.22419503 -0.22042964 -0.21748248 -0.21856441] x2[-0.21668478 -0.22101816 -0.21402059 -0.21491995 -0.21471769] loss [0.67431808 0.6736341  0.67455682 0.67472405 0.67465134] losses 0.6743768763244863\n",
      "iteration 100 x1[-0.23118475 -0.23618165 -0.23043621 -0.23019992 -0.23051568] x2[-0.22884943 -0.23346291 -0.22675674 -0.22578149 -0.22599245] loss [0.6723347  0.67147169 0.67258793 0.67269584 0.67264948] losses 0.6723479270602282\n",
      "iteration 110 x1[-0.24459149 -0.24952942 -0.24487705 -0.24461619 -0.24521902] x2[-0.24218999 -0.24513753 -0.24028785 -0.2372312  -0.23804461] loss [0.669891   0.66914817 0.67004456 0.67035856 0.67022639] losses 0.6699337352786685\n",
      "iteration 120 x1[-0.25835523 -0.2615585  -0.25766034 -0.25870425 -0.25780759] x2[-0.25778769 -0.26238223 -0.25467246 -0.25166798 -0.25266395] loss [0.66706123 0.66628451 0.66743816 0.66763641 0.66762332] losses 0.6672087260292717\n",
      "iteration 130 x1[-0.2762113  -0.27773779 -0.27209827 -0.27422484 -0.27238656] x2[-0.27078957 -0.27876991 -0.26842254 -0.26766661 -0.26844641] loss [0.66392972 0.6629264  0.66459959 0.66446231 0.66456767] losses 0.6640971374075848\n",
      "iteration 140 x1[-0.29150866 -0.28925713 -0.28774839 -0.29201327 -0.28878448] x2[-0.2903476  -0.29421972 -0.28461264 -0.28426057 -0.2833192 ] loss [0.66018691 0.66001144 0.66122709 0.66080808 0.66125794] losses 0.6606982939214531\n",
      "iteration 150 x1[-0.30530266 -0.30210854 -0.3023317  -0.30670265 -0.30350709] x2[-0.29982822 -0.30622799 -0.29528865 -0.29577584 -0.2947135 ] loss [0.65758038 0.65721187 0.65843554 0.65789536 0.65837177] losses 0.6578989839181324\n",
      "iteration 160 x1[-0.31734246 -0.31510629 -0.31403764 -0.31946386 -0.3158732 ] x2[-0.31275604 -0.31646335 -0.30442218 -0.30998688 -0.30622181] loss [0.65467876 0.65450192 0.65605378 0.65476519 0.65563   ] losses 0.6551259282669877\n",
      "iteration 170 x1[-0.32938373 -0.32564005 -0.32339076 -0.33003156 -0.32554022] x2[-0.32614318 -0.327223   -0.31283026 -0.32346294 -0.31597009] loss [0.65161906 0.65194317 0.65396498 0.651872   0.65332934] losses 0.6525457065138378\n",
      "iteration 180 x1[-0.3386247  -0.33927174 -0.33751141 -0.33945963 -0.33922669] x2[-0.33308721 -0.33683288 -0.32346773 -0.33344346 -0.32744326] loss [0.64962149 0.64906787 0.65097655 0.64947341 0.65026461] losses 0.6498807869631745\n",
      "iteration 190 x1[-0.35145965 -0.34995565 -0.34808962 -0.34969367 -0.34861108] x2[-0.34409616 -0.34567625 -0.33376665 -0.34616157 -0.33854007] loss [0.6466026  0.6465877  0.64837145 0.64655814 0.64768477] losses 0.6471609310708892\n",
      "iteration 200 x1[-0.3644322  -0.36151474 -0.36220192 -0.3650173  -0.36327693] x2[-0.35855848 -0.36097113 -0.34776028 -0.35990504 -0.35188829] loss [0.64301362 0.6430758  0.64475575 0.64275562 0.64406177] losses 0.6435325124963512\n",
      "iteration 210 x1[-0.38005445 -0.37287496 -0.37584568 -0.37945142 -0.37711573] x2[-0.37197459 -0.37380694 -0.36152424 -0.37115881 -0.36426651] loss [0.63909833 0.63982042 0.64111256 0.63929325 0.64056417] losses 0.639977747637872\n",
      "iteration 220 x1[-0.38934511 -0.37737489 -0.38280157 -0.39054201 -0.385657  ] x2[-0.38027511 -0.38179519 -0.3728953  -0.37888268 -0.374229  ] loss [0.63666565 0.63810883 0.63859898 0.63670052 0.63802552] losses 0.6376198988128026\n",
      "iteration 230 x1[-0.39836821 -0.38785393 -0.39403176 -0.39953667 -0.39551863] x2[-0.39037441 -0.39567688 -0.38507133 -0.3883282  -0.38554909] loss [0.63396526 0.63470536 0.63533407 0.6340989  0.63505932] losses 0.634632580148535\n",
      "iteration 240 x1[-0.40512106 -0.39778387 -0.39893922 -0.41200376 -0.40519503] x2[-0.4003366  -0.40867143 -0.39497058 -0.39976552 -0.39668182] loss [0.6315588  0.63142765 0.63322057 0.63065985 0.63208334] losses 0.6317900422860572\n",
      "iteration 250 x1[-0.41331916 -0.40437214 -0.41043971 -0.42046082 -0.41516519] x2[-0.40959878 -0.41638236 -0.40187603 -0.40736144 -0.40320912] loss [0.62900819 0.62934455 0.63056954 0.62830656 0.62969367] losses 0.6293845013312279\n",
      "iteration 260 x1[-0.42221552 -0.41736989 -0.41966584 -0.43065384 -0.42562175] x2[-0.41615816 -0.42526182 -0.41447262 -0.41727689 -0.41617832] loss [0.62671987 0.62608645 0.62734966 0.62530655 0.62621479] losses 0.6263354626242903\n",
      "iteration 270 x1[-0.43067089 -0.42997442 -0.42992631 -0.43885603 -0.43559736] x2[-0.42777931 -0.43317398 -0.42633478 -0.42914208 -0.42797033] loss [0.62369146 0.62297625 0.62402446 0.62224633 0.6229189 ] losses 0.6231714785681\n",
      "iteration 280 x1[-0.43702877 -0.43996471 -0.44162054 -0.44667608 -0.44630466] x2[-0.43446443 -0.43994997 -0.43350215 -0.43820293 -0.43655792] loss [0.62169787 0.62039821 0.62114744 0.61963825 0.61995453] losses 0.6205672593235221\n",
      "iteration 290 x1[-0.45041024 -0.452001   -0.45408601 -0.45695665 -0.45689568] x2[-0.4467263  -0.45095867 -0.44208012 -0.44736627 -0.44477913] loss [0.61771599 0.61679829 0.61788618 0.61659571 0.61702078] losses 0.6172033897091049\n",
      "iteration 300 x1[-0.45689045 -0.46173158 -0.46037266 -0.46346902 -0.46389771] x2[-0.45833675 -0.45949303 -0.45220288 -0.45749985 -0.45407331] loss [0.61485498 0.61389854 0.61528549 0.61394362 0.61443069] losses 0.6144826653199511\n",
      "iteration 310 x1[-0.46373007 -0.46953453 -0.46588659 -0.46678088 -0.46776594] x2[-0.46671725 -0.46599403 -0.462148   -0.46588189 -0.46352851] loss [0.61241919 0.61159999 0.61280802 0.61206107 0.61228398] losses 0.61223445120869\n",
      "iteration 320 x1[-0.46906357 -0.47558478 -0.47128966 -0.4725058  -0.47345758] x2[-0.47337275 -0.46950234 -0.4709552  -0.47366442 -0.4716782 ] loss [0.61048155 0.61005306 0.61051014 0.60987187 0.61004054] losses 0.61019143048949\n",
      "iteration 330 x1[-0.47829043 -0.48126916 -0.4803416  -0.4796816  -0.48088179] x2[-0.48052413 -0.47866556 -0.47762448 -0.48157274 -0.4793254 ] loss [0.60780365 0.60761973 0.60794337 0.60740216 0.60757432] losses 0.607668646643376\n",
      "iteration 340 x1[-0.48746526 -0.49029306 -0.48907652 -0.48703635 -0.48791379] x2[-0.49096129 -0.49047768 -0.48447107 -0.49234197 -0.48785761] loss [0.60455979 0.60416741 0.60537229 0.60440337 0.60499997] losses 0.604700566706887\n",
      "iteration 350 x1[-0.49686988 -0.49951655 -0.49733234 -0.49706325 -0.49689034] x2[-0.49996913 -0.49931032 -0.49241024 -0.50118569 -0.49626387] loss [0.6014741  0.60113751 0.6026696  0.60123732 0.60209328] losses 0.6017223621931336\n",
      "iteration 360 x1[-0.50314106 -0.5024808  -0.50482181 -0.50319702 -0.50419358] x2[-0.50492796 -0.50497434 -0.50146801 -0.50953965 -0.50568973] loss [0.59957342 0.59967802 0.59987639 0.59878479 0.5992651 ] losses 0.5994355438159207\n",
      "iteration 370 x1[-0.50872196 -0.51216493 -0.51263179 -0.50760864 -0.51042255] x2[-0.5125977  -0.5148851  -0.50781933 -0.51590588 -0.51188912] loss [0.59731618 0.59633266 0.59746589 0.59694746 0.59714461] losses 0.5970413585727177\n",
      "iteration 380 x1[-0.51702255 -0.51974114 -0.51858349 -0.51760154 -0.51850501] x2[-0.51821562 -0.52068276 -0.51639656 -0.5226254  -0.5202032 ] loss [0.59492213 0.59402574 0.59496712 0.59406308 0.59432285] losses 0.594460183555991\n",
      "iteration 390 x1[-0.52862393 -0.53110325 -0.52842255 -0.52755952 -0.52772396] x2[-0.52718763 -0.52608115 -0.52216448 -0.53478557 -0.52844781] loss [0.59135053 0.59111378 0.59226643 0.59021423 0.59128742] losses 0.5912464776813493\n",
      "iteration 400 x1[-0.53950794 -0.54340834 -0.53865321 -0.53599549 -0.53697024] x2[-0.53692633 -0.53306573 -0.53051686 -0.54279239 -0.53562396] loss [0.58772966 0.58773588 0.58901778 0.58731902 0.58840641] losses 0.5880417496362139\n",
      "iteration 410 x1[-0.54607851 -0.54977784 -0.54372942 -0.54259177 -0.54196323] x2[-0.54356602 -0.54229439 -0.53923163 -0.54438377 -0.54106418] loss [0.5853889  0.58496354 0.58657698 0.58586269 0.58656266] losses 0.5858709526120284\n",
      "iteration 420 x1[-0.55082653 -0.55677323 -0.55321873 -0.54740622 -0.55054091] x2[-0.5481828  -0.54629693 -0.54583305 -0.55058777 -0.54803315] loss [0.58372004 0.58300739 0.5837187  0.58390178 0.5837977 ] losses 0.5836291219694039\n",
      "iteration 430 x1[-0.55649318 -0.56299419 -0.55866812 -0.55100943 -0.55535819] x2[-0.55359    -0.5549678  -0.55306296 -0.55755378 -0.55563611] loss [0.58173668 0.58032626 0.5814436  0.58201407 0.58157191] losses 0.581418503879256\n",
      "iteration 440 x1[-0.56380902 -0.57110534 -0.56538022 -0.55774204 -0.56230163] x2[-0.55983029 -0.56045851 -0.55984579 -0.56404553 -0.56241104] loss [0.57929504 0.57787268 0.57901005 0.57963273 0.57909891] losses 0.5789818817945733\n",
      "iteration 450 x1[-0.5713189  -0.57910864 -0.57372543 -0.56345546 -0.56951262] x2[-0.56582155 -0.56635772 -0.56634339 -0.56837158 -0.56717737] loss [0.57684889 0.57534899 0.5763191  0.57781332 0.57692759] losses 0.5766515755659283\n",
      "iteration 460 x1[-0.57942103 -0.58242204 -0.5801964  -0.57293393 -0.57715548] x2[-0.57107732 -0.57105876 -0.57420189 -0.57565184 -0.57548459] loss [0.57441736 0.5738791  0.57369895 0.57475905 0.57401672] losses 0.5741542356764178\n",
      "iteration 470 x1[-0.58620482 -0.58744896 -0.58722951 -0.58029719 -0.58406265] x2[-0.57860758 -0.57804251 -0.57853685 -0.58330347 -0.58085308] loss [0.57178924 0.57166821 0.57161593 0.57200591 0.5717641 ] losses 0.5717686781071513\n",
      "iteration 480 x1[-0.59184518 -0.59035686 -0.58947793 -0.5908266  -0.59038639] x2[-0.58605077 -0.58260305 -0.58774303 -0.58896156 -0.58775719] loss [0.56937178 0.57028755 0.56949272 0.56901769 0.56932253] losses 0.5694984521727458\n",
      "iteration 490 x1[-0.59568486 -0.5940892  -0.59448622 -0.59821523 -0.59735627] x2[-0.59165111 -0.58980586 -0.59528615 -0.59677889 -0.59631631] loss [0.56761979 0.56825859 0.56716515 0.56619383 0.56643975] losses 0.5671354210091648\n",
      "iteration 500 x1[-0.60178236 -0.59977119 -0.60062978 -0.60393526 -0.60334665] x2[-0.59745719 -0.59372052 -0.60163677 -0.60277428 -0.60254918] loss [0.5654047  0.56647797 0.56483752 0.56400726 0.56415933] losses 0.5649773546649545\n",
      "iteration 510 x1[-0.60737063 -0.60489059 -0.60486345 -0.60873397 -0.60757218] x2[-0.604937   -0.59946453 -0.60789768 -0.61055435 -0.60943049] loss [0.56295979 0.564451   0.56287521 0.56164967 0.5620789 ] losses 0.562802913860468\n",
      "iteration 520 x1[-0.61208074 -0.61696582 -0.61244758 -0.61327393 -0.61413116] x2[-0.61027106 -0.61183323 -0.61617944 -0.61468908 -0.6164563 ] loss [0.56107388 0.55986308 0.55989392 0.56001753 0.55952329] losses 0.5600743405436013\n",
      "iteration 530 x1[-0.61420464 -0.62208114 -0.61647423 -0.61922362 -0.62004758] x2[-0.61945513 -0.62138514 -0.62227577 -0.62186671 -0.62207197] loss [0.55894646 0.55708908 0.55798562 0.55753961 0.55734448] losses 0.5577810495694282\n",
      "iteration 540 x1[-0.62150826 -0.62846103 -0.62467769 -0.62381734 -0.62577257] x2[-0.62476946 -0.62333647 -0.62551992 -0.62955287 -0.62702625] loss [0.55655778 0.55551279 0.55581322 0.555215   0.55531957] losses 0.5556836736005173\n",
      "iteration 550 x1[-0.62818406 -0.63508596 -0.62794345 -0.63162048 -0.63087764] x2[-0.62989528 -0.6272289  -0.62979288 -0.63342355 -0.6306254 ] loss [0.55431623 0.55351756 0.55438153 0.55299032 0.5536644 ] losses 0.553774008143017\n",
      "iteration 560 x1[-0.63334649 -0.64050177 -0.63288322 -0.63637514 -0.63546727] x2[-0.63576895 -0.63502874 -0.63890335 -0.63781489 -0.63794307] loss [0.55221429 0.55099225 0.55170826 0.55124493 0.55139439] losses 0.5515108259515653\n",
      "iteration 570 x1[-0.63515269 -0.64293802 -0.63624861 -0.6390454  -0.63937993] x2[-0.64117555 -0.63919583 -0.6443465  -0.64085876 -0.6416936 ] loss [0.55084055 0.549727   0.550028   0.55015247 0.54992892] losses 0.5501353885985127\n",
      "iteration 580 x1[-0.64184438 -0.65159315 -0.64295836 -0.64602228 -0.64629497] x2[-0.64396677 -0.64145757 -0.64642246 -0.6458929  -0.64601801] loss [0.54902137 0.54764474 0.54833782 0.54784999 0.54777363] losses 0.5481255116140105\n",
      "iteration 590 x1[-0.64704893 -0.65531182 -0.64722114 -0.64957632 -0.64977325] x2[-0.64717086 -0.64865453 -0.65121446 -0.64801153 -0.65004382] loss [0.54740747 0.54553866 0.54659928 0.54676059 0.54633164] losses 0.5465275261775264\n",
      "iteration 600 x1[-0.65243469 -0.6611663  -0.65348982 -0.65413855 -0.65502971] x2[-0.65137647 -0.65496727 -0.65304029 -0.65116571 -0.65250465] loss [0.54556318 0.54319199 0.54503944 0.54527663 0.54484671] losses 0.5447835900496086\n",
      "iteration 610 x1[-0.65923732 -0.6651007  -0.65769429 -0.65794298 -0.65761773] x2[-0.65664144 -0.65884894 -0.65771366 -0.65743596 -0.65827969] loss [0.54323728 0.54168166 0.54332734 0.54333297 0.5432329 ] losses 0.542962430742342\n",
      "iteration 620 x1[-0.66684993 -0.67214317 -0.66372359 -0.66424682 -0.663134  ] x2[-0.66214326 -0.66291678 -0.66229685 -0.66259509 -0.66313161] loss [0.54070359 0.53953596 0.54127651 0.54111763 0.54122882] losses 0.5407725006269806\n",
      "iteration 630 x1[-0.67327452 -0.67792301 -0.67025683 -0.67091519 -0.66984173] x2[-0.66985951 -0.67021437 -0.66889408 -0.66832915 -0.66808648] loss [0.53796048 0.53699437 0.53873236 0.53871483 0.53896971] losses 0.5382743485500001\n",
      "iteration 640 x1[-0.67903457 -0.68127476 -0.67894074 -0.67696655 -0.678123  ] x2[-0.67704688 -0.67453837 -0.67522194 -0.67399644 -0.6732445 ] loss [0.53544255 0.53549981 0.53581714 0.53643889 0.53636206] losses 0.5359120883161679\n",
      "iteration 650 x1[-0.68459986 -0.68600943 -0.68499688 -0.683022   -0.68457791] x2[-0.68209326 -0.6801433  -0.68142576 -0.68055127 -0.68001626] loss [0.53337558 0.53348436 0.53342911 0.53398372 0.53378653] losses 0.5336118605946295\n",
      "iteration 660 x1[-0.68786715 -0.68864056 -0.68740803 -0.68709835 -0.68804158] x2[-0.68860716 -0.68711227 -0.68754651 -0.68668624 -0.68593991] loss [0.53146622 0.53160732 0.53176291 0.53199133 0.53195341] losses 0.5317562397790699\n",
      "iteration 670 x1[-0.69165279 -0.69685678 -0.69525336 -0.69274879 -0.69590153] x2[-0.69161799 -0.69053954 -0.6906975  -0.69104832 -0.69012679] loss [0.53013822 0.52933632 0.52961671 0.53003568 0.52960308] losses 0.5297460029985068\n",
      "iteration 680 x1[-0.69792473 -0.7046329  -0.70257633 -0.69865577 -0.7025196 ] x2[-0.69747946 -0.69864971 -0.69504123 -0.69673754 -0.69441119] loss [0.52776435 0.52622516 0.52733768 0.5277669  0.52747327] losses 0.5273134704455436\n",
      "iteration 690 x1[-0.70383868 -0.70943164 -0.70700063 -0.70220659 -0.70606234] x2[-0.70429959 -0.70309902 -0.70001927 -0.70386197 -0.69977448] loss [0.52526889 0.52441201 0.52549401 0.52567505 0.52572489] losses 0.5253149730020714\n",
      "iteration 700 x1[-0.70979539 -0.71517713 -0.7089893  -0.70708242 -0.70904351] x2[-0.71054513 -0.70752901 -0.70415723 -0.71104413 -0.70558597] loss [0.52287424 0.52241653 0.52428917 0.52331077 0.52399678] losses 0.5233774972696077\n",
      "iteration 710 x1[-0.7155266  -0.72152134 -0.71451964 -0.71258339 -0.7149194 ] x2[-0.71658635 -0.71314686 -0.70758768 -0.71500954 -0.70875773] loss [0.52056116 0.52006693 0.5225329  0.52145016 0.52222335] losses 0.5213669006315877\n",
      "iteration 720 x1[-0.72077833 -0.72841505 -0.71757437 -0.71760789 -0.71793672] x2[-0.7219875  -0.72039255 -0.71219354 -0.71957167 -0.71330772] loss [0.51846597 0.51728432 0.52102544 0.5195652  0.52073431] losses 0.5194150466418959\n",
      "iteration 730 x1[-0.72532058 -0.73284487 -0.7218685  -0.72377481 -0.72344352] x2[-0.72471726 -0.72485489 -0.71770801 -0.72397207 -0.71908343] loss [0.51703459 0.51553332 0.51909531 0.51748553 0.51851505] losses 0.5175327599798141\n",
      "iteration 740 x1[-0.72780338 -0.73433648 -0.72449569 -0.72611732 -0.72591428] x2[-0.72886737 -0.72760912 -0.72237396 -0.72752933 -0.72273405] loss [0.51572862 0.51469478 0.51765872 0.51632425 0.51730928] losses 0.5163431276109889\n",
      "iteration 750 x1[-0.73545541 -0.7388932  -0.72799979 -0.73221125 -0.72963877] x2[-0.73068281 -0.73191568 -0.72761346 -0.73018062 -0.727588  ] loss [0.51386608 0.51294868 0.51593676 0.51460203 0.51561947] losses 0.5145946051484845\n",
      "iteration 760 x1[-0.73878358 -0.7443441  -0.73062781 -0.73704648 -0.73317175] x2[-0.73456211 -0.73488777 -0.73156693 -0.73339527 -0.73110805] loss [0.51244507 0.51129309 0.51464049 0.5130169  0.51423009] losses 0.5131251271125403\n",
      "iteration 770 x1[-0.74527591 -0.74865323 -0.73509073 -0.74314488 -0.73824863] x2[-0.73741846 -0.73786765 -0.73454754 -0.73702804 -0.73485393] loss [0.5106072  0.50985903 0.51317372 0.51110149 0.51249226] losses 0.5114467407605778\n",
      "iteration 780 x1[-0.7494965  -0.75422624 -0.73877233 -0.74668141 -0.74201507] x2[-0.7421322  -0.74239729 -0.7383605  -0.7404316  -0.73848696] loss [0.50884455 0.50786942 0.51169649 0.50973328 0.5110337 ] losses 0.5098354873155426\n",
      "iteration 790 x1[-0.75510089 -0.75695425 -0.74358348 -0.75161724 -0.74630151] x2[-0.74762304 -0.7445431  -0.74379453 -0.74475732 -0.74317693] loss [0.50665651 0.50690978 0.50967649 0.50790776 0.50926343] losses 0.5080827942691429\n",
      "iteration 800 x1[-0.75746374 -0.7596873  -0.74928937 -0.75724236 -0.75198938] x2[-0.75225002 -0.74960613 -0.74865374 -0.74944248 -0.74816008] loss [0.50527457 0.50536606 0.507593   0.50587586 0.5071595 ] losses 0.5062537968212467\n",
      "iteration 810 x1[-0.76179033 -0.76778835 -0.7514673  -0.76158833 -0.75530385] x2[-0.75459924 -0.75131159 -0.75165834 -0.75340503 -0.75203781] loss [0.50396075 0.50345147 0.50657082 0.50423787 0.50574052] losses 0.50479228338584\n",
      "iteration 820 x1[-0.76451634 -0.77327268 -0.75677094 -0.76508269 -0.76034688] x2[-0.7579262  -0.75758071 -0.75510264 -0.75949298 -0.7572797 ] loss [0.50276608 0.5011308  0.50484578 0.50234403 0.50371192] losses 0.5029597204726973\n",
      "iteration 830 x1[-0.77000192 -0.78017755 -0.76180543 -0.76705708 -0.76318753] x2[-0.76273946 -0.76274437 -0.76017575 -0.76379342 -0.76208028] loss [0.50073643 0.4987583  0.50285238 0.50110442 0.5022041 ] losses 0.501131126437309\n",
      "iteration 840 x1[-0.77352134 -0.78503672 -0.76480462 -0.77175476 -0.76716289] x2[-0.7673774  -0.76878085 -0.76161527 -0.76696216 -0.76388514] loss [0.49912673 0.49660699 0.50197796 0.49955508 0.50106548] losses 0.49966644642561053\n",
      "iteration 850 x1[-0.78005972 -0.79153015 -0.76858038 -0.77663704 -0.77081352] x2[-0.76930235 -0.77329446 -0.76428121 -0.76887796 -0.76646902] loss [0.49746785 0.4944473  0.50070882 0.49821955 0.49983735] losses 0.49813617328362536\n",
      "iteration 860 x1[-0.78267956 -0.79537186 -0.7705029  -0.77958285 -0.77305641] x2[-0.77349693 -0.77532559 -0.7694287  -0.77098676 -0.76992601] loss [0.49612198 0.49329933 0.49931317 0.4972252  0.49871289] losses 0.4969345159073086\n",
      "iteration 870 x1[-0.78511452 -0.80013098 -0.77272241 -0.78314459 -0.77577616] x2[-0.7760114  -0.77955188 -0.77301627 -0.77431094 -0.77342575] loss [0.49514722 0.49153443 0.49816864 0.49586939 0.49748689] losses 0.4956413115956698\n",
      "iteration 880 x1[-0.79079287 -0.80569253 -0.77938606 -0.78606618 -0.78011034] x2[-0.77865508 -0.78260527 -0.77635944 -0.77559652 -0.77565124] loss [0.49351651 0.48985351 0.49619835 0.49504456 0.4961964 ] losses 0.49416186707876014\n",
      "iteration 890 x1[-0.79275473 -0.80966701 -0.78416079 -0.78825883 -0.78507235] x2[-0.78150888 -0.787412   -0.78108323 -0.77841175 -0.78026599] loss [0.49256678 0.48812489 0.49432828 0.49405738 0.49431125] losses 0.4926777162290584\n",
      "iteration 900 x1[-0.79716745 -0.81228499 -0.78834805 -0.79151085 -0.7888091 ] x2[-0.78566429 -0.79079438 -0.78613452 -0.78344551 -0.78541965] loss [0.49088276 0.4869438  0.49251004 0.49242362 0.4925607 ] losses 0.4910641818049277\n",
      "iteration 910 x1[-0.8028581  -0.81601672 -0.79167051 -0.79631534 -0.7918206 ] x2[-0.78950366 -0.79526713 -0.79065808 -0.7893453  -0.79057254] loss [0.48901565 0.48533182 0.49096693 0.49031744 0.49095431] losses 0.4893172299316622\n",
      "iteration 920 x1[-0.80476512 -0.81668196 -0.79862669 -0.7984033  -0.79734301] x2[-0.79244665 -0.79810024 -0.79390893 -0.79344924 -0.79449929] loss [0.48806055 0.48463702 0.48896408 0.48909847 0.48909864] losses 0.4879717538413533\n",
      "iteration 930 x1[-0.80872829 -0.81924136 -0.80104797 -0.80547184 -0.80171911] x2[-0.79502225 -0.79952009 -0.79733153 -0.7954888  -0.79719425] loss [0.4867817  0.48386267 0.48781602 0.48731913 0.487712  ] losses 0.48669830363964445\n",
      "iteration 940 x1[-0.8131562  -0.82500208 -0.80650031 -0.81328563 -0.80915847] x2[-0.79709585 -0.80087465 -0.79960695 -0.79794154 -0.79922634] loss [0.48551488 0.48249175 0.48630398 0.4853213  0.48586317] losses 0.48509901698335733\n",
      "iteration 950 x1[-0.81641756 -0.83152016 -0.81118559 -0.81508051 -0.81253472] x2[-0.80034684 -0.80424195 -0.80229133 -0.80058034 -0.80192204] loss [0.48423922 0.4805776  0.48486323 0.48445    0.48467502] losses 0.48376101452216275\n",
      "iteration 960 x1[-0.82096558 -0.83667995 -0.8153036  -0.81892197 -0.81656069] x2[-0.80547712 -0.8088968  -0.80547706 -0.80640935 -0.80599719] loss [0.48234337 0.47866542 0.48343517 0.48255154 0.48308908] losses 0.4820169164342655\n",
      "iteration 970 x1[-0.82570693 -0.84225888 -0.81641906 -0.82245584 -0.81792186] x2[-0.80900231 -0.80976703 -0.80933234 -0.81043534 -0.80985018] loss [0.4807322  0.47743955 0.48245767 0.48107254 0.48206423] losses 0.48075323668363684\n",
      "iteration 980 x1[-0.83061067 -0.84258242 -0.8190834  -0.82755071 -0.82111091] x2[-0.81249447 -0.81481284 -0.81297473 -0.81091345 -0.81166701] loss [0.47909892 0.47636328 0.48122352 0.47999882 0.4810886 ] losses 0.4795546250111894\n",
      "iteration 990 x1[-0.83465756 -0.84781611 -0.82530513 -0.83126455 -0.82629304] x2[-0.81607514 -0.81651013 -0.81388208 -0.81337092 -0.81273336] loss [0.47761403 0.47503816 0.47984167 0.4787996  0.4798789 ] losses 0.4782344726780138\n",
      "iteration 1000 x1[-0.83632767 -0.85088126 -0.82722433 -0.83549239 -0.83053984] x2[-0.81921107 -0.82144991 -0.81722176 -0.81824311 -0.81717948] loss [0.47667256 0.47347141 0.47881247 0.47702407 0.47818296] losses 0.4768326941566808\n",
      "iteration 1010 x1[-0.84019876 -0.85430865 -0.83122916 -0.84063984 -0.83447675] x2[-0.82341646 -0.827735   -0.82098642 -0.81897628 -0.81940675] loss [0.47510063 0.4715716  0.47729903 0.47589845 0.47698759] losses 0.4753714589419286\n",
      "iteration 1020 x1[-0.84586825 -0.85559172 -0.83590242 -0.84513293 -0.83862722] x2[-0.82786058 -0.83224978 -0.8249867  -0.8229538  -0.82320606] loss [0.47314177 0.47043236 0.4756129  0.4742548  0.47544222] losses 0.4737768080762005\n",
      "iteration 1030 x1[-0.85071874 -0.86261786 -0.84160366 -0.84648618 -0.84211335] x2[-0.83263831 -0.83522552 -0.82817957 -0.82641951 -0.82565447] loss [0.47127655 0.46852234 0.47389174 0.47330989 0.47429281] losses 0.4722586654882105\n",
      "iteration 1040 x1[-0.85579011 -0.87027337 -0.84480533 -0.84915951 -0.84510797] x2[-0.83612444 -0.83556039 -0.83013294 -0.83023413 -0.82840866] loss [0.46962814 0.46703046 0.47289548 0.47204739 0.47317803] losses 0.47095589819095157\n",
      "iteration 1050 x1[-0.86176606 -0.87593726 -0.84651037 -0.85422295 -0.84767117] x2[-0.84005133 -0.84180652 -0.83224665 -0.83455616 -0.83198895] loss [0.46772618 0.4647357  0.47215406 0.47023411 0.47198368] losses 0.469366746606788\n",
      "iteration 1060 x1[-0.86685733 -0.87699613 -0.84826473 -0.859254   -0.8501332 ] x2[-0.84153661 -0.8447903  -0.83528091 -0.83482655 -0.83361054] loss [0.46647756 0.46394631 0.47122303 0.46923225 0.47119591] losses 0.4684150133231938\n",
      "iteration 1070 x1[-0.87052167 -0.8807212  -0.8503998  -0.86173418 -0.85221602] x2[-0.84371894 -0.84751631 -0.83833944 -0.83869838 -0.83702107] loss [0.46536134 0.46271683 0.47021594 0.46799947 0.47012886] losses 0.4672844898596871\n",
      "iteration 1080 x1[-0.87105165 -0.87972086 -0.85451916 -0.86303214 -0.85532684] x2[-0.84581842 -0.85122933 -0.83980754 -0.84174076 -0.83986847] loss [0.46484754 0.46216696 0.46914404 0.46715476 0.46897875] losses 0.4664584095937877\n",
      "iteration 1090 x1[-0.87233464 -0.88227452 -0.85612883 -0.86711506 -0.85885648] x2[-0.84639705 -0.85272957 -0.84413623 -0.8431195  -0.84338994] loss [0.46449392 0.46139818 0.46799049 0.46611646 0.46761872] losses 0.4655235555169182\n",
      "iteration 1100 x1[-0.87396841 -0.88334066 -0.85714996 -0.87076168 -0.86121262] x2[-0.85081122 -0.85529649 -0.84692496 -0.84799218 -0.84662894] loss [0.46331951 0.46069512 0.46725206 0.46447334 0.46653831] losses 0.4644556672483057\n",
      "iteration 1110 x1[-0.87636684 -0.88297708 -0.8618409  -0.87249851 -0.86477396] x2[-0.85310032 -0.86032917 -0.85027862 -0.85171292 -0.85088261] loss [0.46242229 0.45977566 0.46570702 0.46341741 0.46503359] losses 0.46327119264557703\n",
      "iteration 1120 x1[-0.88010466 -0.88803031 -0.86646483 -0.87342004 -0.86771177] x2[-0.85646437 -0.86530704 -0.85451806 -0.85313446 -0.85354529] loss [0.46106618 0.45786642 0.46400588 0.4629663  0.46395942] losses 0.4619728408672463\n",
      "iteration 1130 x1[-0.88094302 -0.88832953 -0.86721808 -0.87663165 -0.87014756] x2[-0.85823595 -0.86848754 -0.85613855 -0.85586838 -0.85604122] loss [0.46056327 0.45719259 0.4635486  0.46183045 0.46301393] losses 0.4612297682570096\n",
      "iteration 1140 x1[-0.88289349 -0.89073108 -0.8713491  -0.88064648 -0.87507141] x2[-0.86248543 -0.86922682 -0.8593937  -0.85953734 -0.85888653] loss [0.45937053 0.45660366 0.46213624 0.46036416 0.46153392] losses 0.46000170365852044\n",
      "iteration 1150 x1[-0.88680776 -0.8928236  -0.87342994 -0.88315711 -0.87705005] x2[-0.86688484 -0.87280456 -0.86300526 -0.86351937 -0.86293053] loss [0.45778646 0.45552265 0.46104447 0.45912014 0.46037713] losses 0.4587701682545629\n",
      "iteration 1160 x1[-0.88902139 -0.89475545 -0.87522761 -0.88593328 -0.87917691] x2[-0.86957199 -0.87198763 -0.86439588 -0.86557573 -0.8642487 ] loss [0.45685381 0.45532376 0.46043667 0.45820342 0.45972254] losses 0.4581080392024555\n",
      "iteration 1170 x1[-0.89412812 -0.90073328 -0.87897328 -0.88997353 -0.88230821] x2[-0.87196444 -0.8755209  -0.86699374 -0.86610143 -0.8654227 ] loss [0.4554441  0.45353836 0.45922996 0.45735184 0.45890884] losses 0.45689462117113067\n",
      "iteration 1180 x1[-0.89647389 -0.90144342 -0.88187529 -0.89452501 -0.88658761] x2[-0.87542943 -0.87879374 -0.86875889 -0.86847978 -0.86695677] loss [0.45434004 0.45277466 0.45834453 0.45604838 0.45781342] losses 0.4558642064209758\n",
      "iteration 1190 x1[-0.89643362 -0.90267679 -0.88738375 -0.89655234 -0.8909971 ] x2[-0.87805526 -0.8812849  -0.87378515 -0.87029562 -0.87059303] loss [0.45384083 0.45206757 0.45634518 0.45532163 0.45628934] losses 0.4547729100680279\n",
      "iteration 1200 x1[-0.89879686 -0.90476909 -0.8898257  -0.8989349  -0.89326198] x2[-0.87968501 -0.88334578 -0.8758195  -0.87242806 -0.87335138] loss [0.45309031 0.45128667 0.45549823 0.454469   0.45533569] losses 0.4539359764282995\n",
      "iteration 1210 x1[-0.90045755 -0.90514757 -0.88980591 -0.90137642 -0.8942012 ] x2[-0.88221868 -0.88512992 -0.87774601 -0.87577698 -0.87549712] loss [0.4522967  0.45087445 0.45513208 0.45337073 0.45474723] losses 0.45328423703119486\n",
      "iteration 1220 x1[-0.90440369 -0.90862911 -0.89206335 -0.90456664 -0.89666702] x2[-0.88443375 -0.88566789 -0.87977675 -0.8809001  -0.87894628] loss [0.45114473 0.45013315 0.45432182 0.45179493 0.45362613] losses 0.45220415225567995\n",
      "iteration 1230 x1[-0.90588357 -0.90770103 -0.89279384 -0.90801697 -0.89884957] x2[-0.88695337 -0.88741696 -0.88081203 -0.88301878 -0.87995648] loss [0.45038972 0.44996739 0.45398751 0.45075504 0.45302833] losses 0.45162560032265875\n",
      "iteration 1240 x1[-0.90878948 -0.90878166 -0.89647985 -0.91013267 -0.9011736 ] x2[-0.89034317 -0.89092098 -0.88420229 -0.88604908 -0.88312908] loss [0.44920811 0.44909927 0.45265354 0.44978525 0.45198984] losses 0.4505472022218525\n",
      "iteration 1250 x1[-0.91173213 -0.90850988 -0.89877557 -0.91193279 -0.90188683] x2[-0.89493978 -0.89475811 -0.88455095 -0.88947016 -0.88370452] loss [0.44779297 0.44841927 0.45216089 0.44880009 0.45174792] losses 0.4497842281126254\n",
      "iteration 1260 x1[-0.91333437 -0.91032092 -0.90347699 -0.9149063  -0.90662259] x2[-0.90000824 -0.89684281 -0.88967197 -0.89183151 -0.88673372] loss [0.44653887 0.44769099 0.45031403 0.44780613 0.45029611] losses 0.44852922486683494\n",
      "iteration 1270 x1[-0.91871411 -0.91241086 -0.90846715 -0.91789338 -0.91041574] x2[-0.90426363 -0.89839135 -0.89237149 -0.8952878  -0.88903699] loss [0.44475157 0.44701398 0.44888061 0.44660271 0.44916012] losses 0.4472817998373432\n",
      "iteration 1280 x1[-0.92130358 -0.91383727 -0.91102525 -0.92032398 -0.91225207] x2[-0.90610344 -0.90150823 -0.89571808 -0.89868975 -0.89316838] loss [0.44393302 0.44616354 0.4477748  0.44551357 0.44803498] losses 0.44628398050552065\n",
      "iteration 1290 x1[-0.92429271 -0.91565154 -0.915869   -0.92413278 -0.91681878] x2[-0.90592769 -0.90174874 -0.89887999 -0.90093444 -0.8966276 ] loss [0.44342311 0.44578562 0.44628835 0.44439738 0.44654287] losses 0.4452874664320382\n",
      "iteration 1300 x1[-0.92687583 -0.92050176 -0.91818328 -0.92626263 -0.91928395] x2[-0.90686061 -0.90287563 -0.89969083 -0.90375934 -0.89871816] loss [0.44277968 0.44468773 0.44571258 0.44347682 0.44569698] losses 0.44447075899363897\n",
      "iteration 1310 x1[-0.92850285 -0.92442948 -0.92278928 -0.92605551 -0.9218401 ] x2[-0.90938987 -0.90475346 -0.90364857 -0.90709112 -0.902602  ] loss [0.44200925 0.44362004 0.44412612 0.44288451 0.44449631] losses 0.44342724589781113\n",
      "iteration 1320 x1[-0.93166406 -0.92745888 -0.92316207 -0.92902188 -0.92341845] x2[-0.91192505 -0.90872418 -0.90541106 -0.90760372 -0.90323791] loss [0.44096278 0.44232311 0.44372563 0.44225227 0.44408977] losses 0.44267071384643353\n",
      "iteration 1330 x1[-0.93424123 -0.93171295 -0.92365578 -0.93217677 -0.92553521] x2[-0.91472688 -0.91137126 -0.90650927 -0.91010328 -0.9051401 ] loss [0.43997378 0.44105807 0.443429   0.44121336 0.4433469 ] losses 0.44180422181859696\n",
      "iteration 1340 x1[-0.93706685 -0.93495297 -0.92542809 -0.9335969  -0.92739593] x2[-0.91687474 -0.91418759 -0.90825711 -0.9128296  -0.90805109] loss [0.43906489 0.43994716 0.44277853 0.44044543 0.44246125] losses 0.4409394521971913\n",
      "iteration 1350 x1[-0.93775758 -0.93753767 -0.92498297 -0.93527639 -0.92811865] x2[-0.91993805 -0.91639644 -0.91323228 -0.91525752 -0.91203339] loss [0.43836919 0.43907015 0.44192704 0.43968857 0.44158227] losses 0.44012744462719366\n",
      "iteration 1360 x1[-0.94306852 -0.94307082 -0.9279943  -0.93858717 -0.93019342] x2[-0.92237638 -0.91825086 -0.91593279 -0.91945555 -0.91573441] loss [0.43696619 0.43773652 0.44087625 0.43831057 0.44051487] losses 0.43888087973580464\n",
      "iteration 1370 x1[-0.94670184 -0.94836842 -0.93080525 -0.94246717 -0.93358187] x2[-0.92344917 -0.92015146 -0.91830364 -0.92112688 -0.91766645] loss [0.43612102 0.43644281 0.43992559 0.43730615 0.43954292] losses 0.4378676987821205\n",
      "iteration 1380 x1[-0.94724278 -0.95069609 -0.93235264 -0.94410555 -0.93536456] x2[-0.92514197 -0.91973084 -0.92039666 -0.92441062 -0.92032231] loss [0.43571009 0.4361121  0.43925691 0.4364032  0.43872745] losses 0.4372419512884105\n",
      "iteration 1390 x1[-0.94996868 -0.95281458 -0.93276248 -0.94698099 -0.93674398] x2[-0.92781207 -0.92203349 -0.9230568  -0.92849102 -0.9239233 ] loss [0.43473186 0.43530826 0.43869012 0.43513556 0.43781123] losses 0.436335405085342\n",
      "iteration 1400 x1[-0.94954643 -0.95278551 -0.93478807 -0.94710168 -0.93848638] x2[-0.92826744 -0.92276432 -0.92392436 -0.9302721  -0.9259244 ] loss [0.43472212 0.43517645 0.43816361 0.43478517 0.43712787] losses 0.43599504420259827\n",
      "iteration 1410 x1[-0.9499187  -0.95556496 -0.93860641 -0.94728149 -0.94109288] x2[-0.92902741 -0.92381988 -0.92638991 -0.93004568 -0.92751228] loss [0.43451553 0.4344922  0.43702034 0.43479497 0.43636694] losses 0.43543799597446337\n",
      "iteration 1420 x1[-0.95302741 -0.95799229 -0.94049673 -0.94934156 -0.94276863] x2[-0.9302144  -0.92633737 -0.92971716 -0.93082691 -0.93013132] loss [0.43374704 0.43359774 0.43606774 0.43428516 0.4355842 ] losses 0.43465637652359296\n",
      "iteration 1430 x1[-0.95341224 -0.95940083 -0.94304612 -0.95136868 -0.94611563] x2[-0.93331368 -0.93004967 -0.93326093 -0.93566494 -0.93454313] loss [0.43310684 0.43266056 0.43496001 0.43303598 0.434176  ] losses 0.433587877915354\n",
      "iteration 1440 x1[-0.95671339 -0.96211917 -0.94597385 -0.95529182 -0.9494466 ] x2[-0.93413772 -0.9312128  -0.93648884 -0.93542047 -0.93641988] loss [0.43237407 0.43197132 0.43384561 0.43238784 0.43323893] losses 0.4327635548904897\n",
      "iteration 1450 x1[-0.95897788 -0.96107005 -0.94888092 -0.9581134  -0.95210258] x2[-0.93627945 -0.93338664 -0.93777696 -0.93599155 -0.93739746] loss [0.43158254 0.4317508  0.43309167 0.43178701 0.43258863] losses 0.4321601277737269\n",
      "iteration 1460 x1[-0.95999071 -0.96104242 -0.94951005 -0.9583718  -0.95205437] x2[-0.93774136 -0.93334993 -0.94185602 -0.93667723 -0.93982605] loss [0.43113647 0.43176241 0.4322374  0.4316156  0.43215375] losses 0.4317811269558929\n",
      "iteration 1470 x1[-0.96040154 -0.96313783 -0.95390531 -0.95832975 -0.95502773] x2[-0.93804091 -0.93688737 -0.94513973 -0.93704723 -0.94230165] loss [0.43100958 0.43074431 0.43086044 0.43155499 0.4311763 ] losses 0.43106912448023865\n",
      "iteration 1480 x1[-0.96209058 -0.9638137  -0.95759823 -0.95956649 -0.95746506] x2[-0.9394142  -0.93857937 -0.94527438 -0.93864948 -0.94284423] loss [0.43046238 0.43031531 0.43018248 0.43104411 0.43064726] losses 0.43053030956029703\n",
      "iteration 1490 x1[-0.96417538 -0.96810537 -0.95989946 -0.96212517 -0.9606209 ] x2[-0.94259465 -0.94091595 -0.94833368 -0.94269298 -0.94658692] loss [0.42951649 0.42914129 0.42922329 0.42985656 0.42941234] losses 0.42942999595183995\n",
      "iteration 1500 x1[-0.96663454 -0.97080373 -0.96077114 -0.96436386 -0.9622003 ] x2[-0.94411782 -0.94294092 -0.95016286 -0.94690493 -0.94996303] loss [0.42881032 0.42830367 0.42873986 0.42869881 0.42852457] losses 0.42861544475539093\n",
      "iteration 1510 x1[-0.96897731 -0.97364131 -0.96357187 -0.96670308 -0.96481709] x2[-0.94483024 -0.94240813 -0.95140981 -0.95094622 -0.95274865] loss [0.42827383 0.42791314 0.42802311 0.427559   0.42756395] losses 0.42786660593760095\n",
      "iteration 1520 x1[-0.96847271 -0.97492134 -0.96594289 -0.96779541 -0.96691966] x2[-0.94805769 -0.94332861 -0.95246568 -0.95326661 -0.95369436] loss [0.42777387 0.42752458 0.42741785 0.42695028 0.42702618] losses 0.4273385530901212\n",
      "iteration 1530 x1[-0.9696683  -0.97373807 -0.9679981  -0.9710852  -0.96965745] x2[-0.94644518 -0.94173358 -0.95381992 -0.95486502 -0.95588514] loss [0.42785973 0.42802051 0.42681541 0.42609044 0.42615543] losses 0.42698830406856453\n",
      "iteration 1540 x1[-0.96956999 -0.97647363 -0.97117784 -0.97192463 -0.9720281 ] x2[-0.94811779 -0.94423966 -0.95592741 -0.95492124 -0.9567423 ] loss [0.42757257 0.42709165 0.4258835  0.42593472 0.42558971] losses 0.42641443091822345\n",
      "iteration 1550 x1[-0.97092298 -0.97852594 -0.97163061 -0.97154138 -0.97208104] x2[-0.95031232 -0.946131   -0.95681092 -0.95540434 -0.95694735] loss [0.42694012 0.42639447 0.42564639 0.42591434 0.42554376] losses 0.4260878137995549\n",
      "iteration 1560 x1[-0.97337292 -0.97849058 -0.97296665 -0.97322103 -0.97319944] x2[-0.95216908 -0.94938757 -0.9590528  -0.95703132 -0.95912979] loss [0.42618046 0.4258059  0.42501322 0.4253311  0.42495909] losses 0.4254579540229496\n",
      "iteration 1570 x1[-0.97550847 -0.98074663 -0.973486   -0.97671718 -0.97551142] x2[-0.95375074 -0.95037129 -0.96184844 -0.95710178 -0.96065294] loss [0.42552644 0.42524173 0.42442446 0.42471475 0.42428676] losses 0.4248388261941112\n",
      "iteration 1580 x1[-0.97565529 -0.98103717 -0.9763751  -0.97898543 -0.9790717 ] x2[-0.95644273 -0.94920379 -0.96454903 -0.95842532 -0.9621927 ] loss [0.42501616 0.42540498 0.42344395 0.42408711 0.42339813] losses 0.4242700650883867\n",
      "iteration 1590 x1[-0.97845174 -0.98395768 -0.98056049 -0.98150734 -0.98277764] x2[-0.95760645 -0.94909136 -0.96645213 -0.95950853 -0.96395603] loss [0.4243258  0.4249296  0.42238464 0.42346061 0.42244807] losses 0.4235097457123234\n",
      "iteration 1600 x1[-0.9800628  -0.98565518 -0.98464308 -0.98257317 -0.98581157] x2[-0.96003373 -0.95380133 -0.96928733 -0.96233062 -0.96731892] loss [0.42361386 0.42378449 0.42118268 0.42277308 0.42133186] losses 0.4225371948293434\n",
      "iteration 1610 x1[-0.98115276 -0.98657182 -0.98413664 -0.9820078  -0.98513075] x2[-0.96214871 -0.95807897 -0.97061263 -0.96339727 -0.968587  ] loss [0.42304872 0.4228555  0.42103532 0.42267944 0.42122325] losses 0.4221684455182704\n",
      "iteration 1620 x1[-0.98404423 -0.9916103  -0.98712569 -0.9839228  -0.98744116] x2[-0.96478111 -0.96118424 -0.97275531 -0.96664024 -0.97132421] loss [0.4220846  0.42144552 0.42014694 0.4217748  0.42034534] losses 0.4211594402591903\n",
      "iteration 1630 x1[-0.9854528  -0.99044317 -0.98746812 -0.98582072 -0.9884274 ] x2[-0.96599256 -0.96269245 -0.97262498 -0.96758654 -0.97162503] loss [0.42162867 0.42137144 0.42011149 0.42128281 0.42012437] losses 0.4209037567736509\n",
      "iteration 1640 x1[-0.98604364 -0.98974723 -0.9895028  -0.98632452 -0.98969077] x2[-0.96831074 -0.96789655 -0.9748582  -0.9685041  -0.97322399] loss [0.42111639 0.42056043 0.41937242 0.42103425 0.41962779] losses 0.42034225547537424\n",
      "iteration 1650 x1[-0.98752156 -0.99275651 -0.99235961 -0.98684457 -0.99139488] x2[-0.96893034 -0.96945698 -0.97704193 -0.96977441 -0.97539528] loss [0.42075489 0.41977468 0.41850455 0.42072076 0.41895682] losses 0.41974233818531675\n",
      "iteration 1660 x1[-0.99134086 -0.99705703 -0.99574985 -0.98942344 -0.99412005] x2[-0.97277928 -0.97336465 -0.97922258 -0.97273343 -0.97753277] loss [0.41942627 0.41835945 0.41755    0.41975961 0.41812074] losses 0.4186432141107918\n",
      "iteration 1670 x1[-0.99366547 -0.99788243 -0.99874625 -0.98971688 -0.99564317] x2[-0.97454003 -0.97575209 -0.97974253 -0.97370312 -0.97830591] loss [0.41872299 0.41780007 0.41695512 0.41953903 0.41772832] losses 0.41814910601268585\n",
      "iteration 1680 x1[-0.99656107 -1.00203838 -1.00098943 -0.99185821 -0.99784524] x2[-0.9768779  -0.97711971 -0.98123858 -0.97610939 -0.98012756] loss [0.4178241  0.41686471 0.41631795 0.41875296 0.41703913] losses 0.4173597698879803\n",
      "iteration 1690 x1[-0.99934489 -1.00140693 -1.00296216 -0.99373799 -0.99951264] x2[-0.97721254 -0.97711364 -0.98185334 -0.9779063  -0.98105242] loss [0.41729823 0.41697104 0.41588122 0.41811991 0.41659774] losses 0.41697362893148854\n",
      "iteration 1700 x1[-1.00197166 -1.00187956 -1.00432582 -0.9972799  -1.00187741] x2[-0.97878202 -0.97886732 -0.98512566 -0.97888239 -0.98320874] loss [0.41658383 0.41658422 0.41508416 0.41735188 0.41582601] losses 0.41628602140625476\n",
      "iteration 1710 x1[-1.00312053 -1.00373849 -1.00654301 -0.99778865 -1.00342798] x2[-0.98015483 -0.98047425 -0.9877582  -0.98167627 -0.98611545] loss [0.41615178 0.41599299 0.41425891 0.41677847 0.41506213] losses 0.41564885580380695\n",
      "iteration 1720 x1[-1.00430616 -1.00542939 -1.00795994 -1.0001614  -1.0057962 ] x2[-0.98145974 -0.98308874 -0.9889084  -0.98287224 -0.98789274] loss [0.41572619 0.41525511 0.41382484 0.4161718  0.41435978] losses 0.41506754294979603\n",
      "iteration 1730 x1[-1.00664736 -1.0078465  -1.00778712 -1.00612927 -1.00854866] x2[-0.9833627  -0.98596435 -0.99205433 -0.98304153 -0.98938537] loss [0.41500524 0.41435374 0.41331131 0.41514717 0.41364487] losses 0.4142924655650105\n",
      "iteration 1740 x1[-1.00811559 -1.00829712 -1.0088435  -1.00692986 -1.00922341] x2[-0.98581823 -0.98711107 -0.99251501 -0.9847987  -0.99019419] loss [0.41433458 0.41408012 0.41305686 0.41470827 0.41339351] losses 0.4139146663498646\n",
      "iteration 1750 x1[-1.00872323 -1.01089597 -1.0096268  -1.00639842 -1.00894527] x2[-0.98704567 -0.98727109 -0.99379092 -0.98676974 -0.9919588 ] loss [0.41402094 0.41362307 0.41270804 0.41445414 0.4131356 ] losses 0.4135883573207172\n",
      "iteration 1760 x1[-1.01137169 -1.01271321 -1.0124098  -1.00973364 -1.01180357] x2[-0.98744697 -0.98968521 -0.99480987 -0.98897838 -0.99384016] loss [0.41351417 0.41290567 0.41207338 0.41351914 0.41233969] losses 0.4128704106916266\n",
      "iteration 1770 x1[-1.01252584 -1.01638099 -1.01282455 -1.01005439 -1.01213754] x2[-0.98993674 -0.99138503 -0.99796096 -0.99234785 -0.99708788] loss [0.412893   0.41201047 0.41146639 0.41288506 0.41172872] losses 0.4121967286967779\n",
      "iteration 1780 x1[-1.01379865 -1.01945668 -1.0165651  -1.01057123 -1.01437806] x2[-0.99377201 -0.99378017 -0.99890712 -0.99410742 -0.9971334 ] loss [0.41202276 0.41109572 0.41068986 0.41249744 0.41135167] losses 0.41153148966080033\n",
      "iteration 1790 x1[-1.01371612 -1.02098827 -1.01867078 -1.01060864 -1.01568535] x2[-0.99456252 -0.99486676 -0.99901438 -0.997527   -0.99914871] loss [0.41190063 0.41065975 0.41032696 0.41190669 0.41079307] losses 0.4111174203764373\n",
      "iteration 1800 x1[-1.01521727 -1.0239682  -1.02213911 -1.01127365 -1.01781967] x2[-0.9962957  -0.99761602 -1.001362   -0.99902546 -1.00131708] loss [0.41135697 0.409705   0.4093621  0.41154149 0.41007433] losses 0.41040797923144645\n",
      "iteration 1810 x1[-1.01760849 -1.02289028 -1.02205733 -1.01406644 -1.01881654] x2[-0.99800461 -1.00041319 -1.00453634 -1.00138006 -1.00444528] loss [0.41067294 0.40940167 0.40883712 0.41068036 0.40938138] losses 0.40979469330057616\n",
      "iteration 1820 x1[-1.01953985 -1.025714   -1.02415273 -1.01614915 -1.02073045] x2[-0.99832378 -1.00049158 -1.00589077 -1.00143962 -1.00546643] loss [0.41030299 0.40893145 0.40826789 0.41032752 0.40889623] losses 0.40934521572873317\n",
      "iteration 1830 x1[-1.0207279  -1.02677256 -1.0238578  -1.01750218 -1.02167834] x2[-1.00048297 -1.0029179  -1.00824364 -1.00336906 -1.00737963] loss [0.40974122 0.40834771 0.40791943 0.40977862 0.40841933] losses 0.4088412617425298\n",
      "iteration 1840 x1[-1.02317946 -1.0269268  -1.02440852 -1.0183095  -1.02194094] x2[-1.00355712 -1.00507428 -1.00922713 -1.00493731 -1.00815485] loss [0.40882051 0.4079572  0.40766483 0.40938135 0.40824622] losses 0.4084140235713374\n",
      "iteration 1850 x1[-1.0258829  -1.03036795 -1.02551945 -1.01996282 -1.02276379] x2[-1.00582351 -1.00835124 -1.01125594 -1.00760054 -1.01039832] loss [0.40799909 0.40685022 0.40714471 0.40866229 0.40773598] losses 0.40767845868783914\n",
      "iteration 1860 x1[-1.02723982 -1.03134452 -1.02509878 -1.0210989  -1.0228457 ] x2[-1.00671837 -1.00956674 -1.01324358 -1.00832626 -1.01243802] loss [0.40762887 0.40648903 0.40688111 0.40835478 0.4073819 ] losses 0.40734713573408304\n",
      "iteration 1870 x1[-1.02855572 -1.03319856 -1.02428711 -1.02144781 -1.02211412] x2[-1.00894003 -1.00974189 -1.01586597 -1.00988806 -1.01384345] loss [0.40704249 0.40616291 0.40657715 0.40803598 0.40726722] losses 0.40701715134307664\n",
      "iteration 1880 x1[-1.03202521 -1.03451845 -1.02594523 -1.02383444 -1.02365854] x2[-1.01083968 -1.01179206 -1.01676213 -1.01246805 -1.01546811] loss [0.40616616 0.40560799 0.40615914 0.40721589 0.40674549] losses 0.40637893496911504\n",
      "iteration 1890 x1[-1.03248366 -1.03576796 -1.02734491 -1.02616734 -1.02586593] x2[-1.01245374 -1.01299167 -1.01929083 -1.01505836 -1.0179184 ] loss [0.4058223  0.40520798 0.40551418 0.40640575 0.40598071] losses 0.4057861855092704\n",
      "iteration 1900 x1[-1.03296218 -1.03932731 -1.03010608 -1.02707113 -1.02829246] x2[-1.01298227 -1.0126793  -1.01860566 -1.0154677  -1.0176956 ] loss [0.40565731 0.40469569 0.40518108 0.40619131 0.40562436] losses 0.4054699508351777\n",
      "iteration 1910 x1[-1.03672901 -1.04284707 -1.0328341  -1.03175088 -1.03177553] x2[-1.01593715 -1.01403794 -1.02072749 -1.01858947 -1.0202413 ] loss [0.40456339 0.40391332 0.40439208 0.40491905 0.40464227] losses 0.40448602035875914\n",
      "iteration 1920 x1[-1.03825986 -1.04259682 -1.03281439 -1.03279463 -1.03232703] x2[-1.01754743 -1.01550537 -1.02263021 -1.02066288 -1.02282513] loss [0.40405239 0.4037073  0.40408218 0.40440906 0.40412848] losses 0.404075883340158\n",
      "iteration 1930 x1[-1.03814725 -1.04470226 -1.0342427  -1.03440398 -1.03442207] x2[-1.01942637 -1.01692131 -1.02500131 -1.02082189 -1.02369492] loss [0.40375873 0.40314055 0.40346434 0.40412494 0.40364959] losses 0.40362762730345486\n",
      "iteration 1940 x1[-1.03977921 -1.04461367 -1.0360039  -1.03519798 -1.03489207] x2[-1.02174335 -1.01971105 -1.02867303 -1.02343044 -1.02701767] loss [0.40311705 0.40269075 0.40258349 0.4035688  0.40303098] losses 0.4029982130158638\n",
      "iteration 1950 x1[-1.04253    -1.04797656 -1.03751983 -1.03557093 -1.03587552] x2[-1.02433542 -1.02128653 -1.03167067 -1.0272963  -1.03036435] loss [0.40225552 0.4019037  0.40185512 0.40287686 0.40232951] losses 0.40224414027805266\n",
      "iteration 1960 x1[-1.04574374 -1.05147081 -1.04014649 -1.03741047 -1.03791296] x2[-1.02528681 -1.02242606 -1.03215506 -1.02755695 -1.0307675 ] loss [0.40159373 0.4011719  0.4013584  0.40254051 0.4019386 ] losses 0.4017206274930709\n",
      "iteration 1970 x1[-1.04591345 -1.05210233 -1.04021794 -1.03893613 -1.0387697 ] x2[-1.02576349 -1.0248803  -1.03348044 -1.02817312 -1.03217277] loss [0.40148891 0.40066925 0.40113295 0.40219712 0.40157459] losses 0.401412564293086\n",
      "iteration 1980 x1[-1.0488164  -1.05320316 -1.0424967  -1.04122316 -1.04030672] x2[-1.02681712 -1.02585876 -1.0340283  -1.02990249 -1.03277535] loss [0.40086213 0.40033794 0.40068315 0.4015527  0.40123268] losses 0.4009337190644125\n",
      "iteration 1990 x1[-1.05050229 -1.05372911 -1.04094768 -1.04293175 -1.03985538] x2[-1.0295372  -1.02809538 -1.03560557 -1.03140943 -1.03367647] loss [0.40015487 0.39988983 0.40067481 0.40103778 0.40115899] losses 0.4005832581366315\n",
      "iteration 2000 x1[-1.05197512 -1.05465349 -1.04151191 -1.04417132 -1.04077887] x2[-1.03104246 -1.03057824 -1.03814652 -1.0325594  -1.03584948] loss [0.39968077 0.39934156 0.40017779 0.40065586 0.40066244] losses 0.40010368461825296\n",
      "iteration 2010 x1[-1.05238246 -1.05334713 -1.04184505 -1.0446193  -1.04077656] x2[-1.03360534 -1.03499262 -1.0400407  -1.03426897 -1.03755896] loss [0.39920164 0.39882765 0.39982241 0.40030903 0.40038865] losses 0.3997098764945767\n",
      "iteration 2020 x1[-1.05585183 -1.05610658 -1.04494412 -1.04857827 -1.04405998] x2[-1.03641797 -1.03809744 -1.04142324 -1.03604756 -1.03930535] loss [0.3982102  0.39790061 0.39911153 0.39940052 0.39958887] losses 0.39884234473661107\n",
      "iteration 2030 x1[-1.05732793 -1.05652108 -1.04688233 -1.05060235 -1.04636452] x2[-1.03889753 -1.04102467 -1.04229905 -1.03704212 -1.04011241] loss [0.39758383 0.39736762 0.39866673 0.39892427 0.39909651] losses 0.39832779138878077\n",
      "iteration 2040 x1[-1.0588015  -1.05783934 -1.04743189 -1.05171791 -1.04721679] x2[-1.04021445 -1.04068879 -1.0443136  -1.03892463 -1.04194944] loss [0.39714604 0.3972181  0.39826066 0.39844831 0.39866972] losses 0.3979485668114131\n",
      "iteration 2050 x1[-1.06051372 -1.0587919  -1.0469002  -1.05506994 -1.04837342] x2[-1.0407309  -1.03921463 -1.04520271 -1.04185932 -1.0444305 ] loss [0.39680074 0.39730777 0.39820366 0.39745874 0.3980942 ] losses 0.39757302203707745\n",
      "iteration 2060 x1[-1.06022854 -1.0592357  -1.04436796 -1.05637549 -1.04779731] x2[-1.04065307 -1.04007658 -1.04634114 -1.04334447 -1.04627671] loss [0.39685688 0.39710145 0.39842377 0.39702029 0.39789288] losses 0.39745905283429145\n",
      "iteration 2070 x1[-1.06105669 -1.05819853 -1.04531811 -1.05658602 -1.04829162] x2[-1.04219596 -1.04153247 -1.0452117  -1.04336786 -1.04513186] loss [0.39648346 0.39702798 0.39845175 0.39698405 0.39799605] losses 0.39738865756382236\n",
      "iteration 2080 x1[-1.06133966 -1.05971619 -1.04807428 -1.05631724 -1.04957161] x2[-1.04342052 -1.04116312 -1.04643894 -1.04582581 -1.04697156] loss [0.39624493 0.39685384 0.39782374 0.39663557 0.39750474] losses 0.3970125653801299\n",
      "iteration 2090 x1[-1.06449274 -1.06207117 -1.04911478 -1.05773814 -1.05001413] x2[-1.0457064  -1.04331692 -1.04873241 -1.04664438 -1.0485332 ] loss [0.39540052 0.39614959 0.3972993  0.39628665 0.39718958] losses 0.3964651272140255\n",
      "iteration 2100 x1[-1.06615304 -1.06390024 -1.05293278 -1.06058313 -1.05386749] x2[-1.04834581 -1.04724179 -1.04955397 -1.04890756 -1.04936493] loss [0.39473048 0.39524751 0.3965732  0.39549183 0.39645738] losses 0.3957000797334175\n",
      "iteration 2110 x1[-1.0689937  -1.06654567 -1.05494523 -1.06229632 -1.05563175] x2[-1.04898238 -1.04667982 -1.05051469 -1.0505792  -1.05032244] loss [0.39420014 0.39493445 0.39610947 0.39496639 0.39603312] losses 0.3952487167981425\n",
      "iteration 2120 x1[-1.07001636 -1.06850573 -1.05447648 -1.06588641 -1.05739029] x2[-1.0513619  -1.04971792 -1.05148247 -1.05148736 -1.05119638] loss [0.39367124 0.39415783 0.39603071 0.39427644 0.39562393] losses 0.39475203086981625\n",
      "iteration 2130 x1[-1.07029244 -1.06974188 -1.05632658 -1.06878796 -1.06034852] x2[-1.05308651 -1.05075441 -1.05413148 -1.05246631 -1.05296288] loss [0.39335914 0.39380811 0.39533007 0.39368329 0.39489166] losses 0.39421445403579336\n",
      "iteration 2140 x1[-1.07145243 -1.07066406 -1.05574013 -1.07128632 -1.0614578 ] x2[-1.0553637  -1.0538321  -1.05588347 -1.05517649 -1.05540955] loss [0.39282873 0.39318651 0.39514868 0.3928829  0.39433989] losses 0.3936773420923701\n",
      "iteration 2150 x1[-1.07183136 -1.07002464 -1.05867346 -1.07289133 -1.06358706] x2[-1.05716719 -1.05620693 -1.0554038  -1.05606137 -1.05540223] loss [0.39249105 0.39291243 0.39476922 0.39250392 0.39401501] losses 0.39333832515113903\n",
      "iteration 2160 x1[-1.07314707 -1.06919124 -1.05950677 -1.07405179 -1.06419469] x2[-1.05877357 -1.05717845 -1.05480758 -1.05739851 -1.05511042] loss [0.39204427 0.39288726 0.39473349 0.39212206 0.39396766] losses 0.3931509464756494\n",
      "iteration 2170 x1[-1.0719807  -1.07137445 -1.05979673 -1.07397633 -1.06494972] x2[-1.06179757 -1.06025479 -1.0547714  -1.0614756  -1.05677484] loss [0.3917525  0.39208159 0.39469448 0.39150248 0.39359371] losses 0.39272495103906707\n",
      "iteration 2180 x1[-1.07425091 -1.07392206 -1.0621103  -1.07380549 -1.06536192] x2[-1.06395889 -1.06252547 -1.05606288 -1.06409787 -1.05864286] loss [0.39107962 0.391349   0.39413827 0.39112508 0.39324142] losses 0.3921866801715999\n",
      "iteration 2190 x1[-1.07727491 -1.07716103 -1.06311202 -1.07426042 -1.06509125] x2[-1.06433138 -1.06290689 -1.05781178 -1.0641092  -1.05980477] loss [0.39057086 0.39080652 0.39371359 0.39105516 0.39310316] losses 0.39184985806034606\n",
      "iteration 2200 x1[-1.07790476 -1.07724294 -1.0641238  -1.07448877 -1.06541717] x2[-1.06530831 -1.06450922 -1.06000039 -1.06643686 -1.062814  ] loss [0.39032749 0.39054835 0.39322066 0.39066498 0.39259049] losses 0.39147039407005857\n",
      "iteration 2210 x1[-1.07778418 -1.07727834 -1.06442527 -1.07502342 -1.06596348] x2[-1.06675538 -1.06488201 -1.06137121 -1.06766003 -1.06430882] loss [0.39012431 0.39048597 0.39296349 0.39039851 0.39227825] losses 0.3912501061875049\n",
      "iteration 2220 x1[-1.07777505 -1.07736454 -1.06475086 -1.07483581 -1.06600625] x2[-1.06964466 -1.06728622 -1.06320366 -1.06910947 -1.06525759] loss [0.38968615 0.39010585 0.39263243 0.39020633 0.39212675] losses 0.3909515015499614\n",
      "iteration 2230 x1[-1.07729145 -1.075509   -1.06513537 -1.07474165 -1.06614206] x2[-1.06986001 -1.0696543  -1.06521957 -1.06998339 -1.06756021] loss [0.38972554 0.39002291 0.3922654  0.39008794 0.39175536] losses 0.3907714291336061\n",
      "iteration 2240 x1[-1.0778935  -1.07471331 -1.06485311 -1.07593965 -1.06648624] x2[-1.0703474  -1.06985641 -1.06786403 -1.07184545 -1.06974342] loss [0.389562   0.39011142 0.39190596 0.38962705 0.39137188] losses 0.39051566299794577\n",
      "iteration 2250 x1[-1.07751417 -1.07633244 -1.06617903 -1.07763311 -1.06864885] x2[-1.07136411 -1.07194352 -1.06971687 -1.072834   -1.0709761 ] loss [0.38946469 0.38955354 0.39142273 0.38922516 0.39085668] losses 0.3901045597334608\n",
      "iteration 2260 x1[-1.07820326 -1.07613987 -1.06830766 -1.0774241  -1.06995893] x2[-1.07109256 -1.07388693 -1.07050878 -1.07206364 -1.07134033] loss [0.38940312 0.38928963 0.39097906 0.38937248 0.39060313] losses 0.38992948409299344\n",
      "iteration 2270 x1[-1.0794355  -1.07656535 -1.0685085  -1.07750753 -1.06917267] x2[-1.07269004 -1.07675982 -1.07128695 -1.0723851  -1.07171367] loss [0.38897873 0.38879548 0.39083107 0.38931154 0.39066594] losses 0.38971655164764546\n",
      "iteration 2280 x1[-1.08108736 -1.07739119 -1.06977457 -1.07864513 -1.07065714] x2[-1.07298222 -1.07558378 -1.07307906 -1.07347979 -1.07298525] loss [0.38868982 0.3888481  0.39036914 0.38897722 0.39024967] losses 0.3894267914706989\n",
      "iteration 2290 x1[-1.08455939 -1.08129992 -1.07151613 -1.08315093 -1.07365661] x2[-1.07537849 -1.08001541 -1.07641153 -1.07461059 -1.0754551 ] loss [0.38781739 0.38760598 0.38960625 0.38814    0.38942672] losses 0.38851927082202986\n",
      "iteration 2300 x1[-1.08620733 -1.08431435 -1.07412696 -1.0864328  -1.0769801 ] x2[-1.077264   -1.08179733 -1.0765951  -1.07512713 -1.07588229] loss [0.38729314 0.38689663 0.38918552 0.38758034 0.38886476] losses 0.3879640776192708\n",
      "iteration 2310 x1[-1.08859942 -1.08427503 -1.07668028 -1.08863132 -1.079574  ] x2[-1.07892397 -1.08388281 -1.07793976 -1.07827049 -1.07918234] loss [0.38669569 0.38659433 0.38860221 0.38678851 0.38798587] losses 0.387333322987801\n",
      "iteration 2320 x1[-1.0881297  -1.0843321  -1.07975264 -1.09002841 -1.08266528] x2[-1.08005958 -1.08413305 -1.08164534 -1.07953365 -1.08166607] loss [0.38659515 0.38654905 0.38759389 0.3863968  0.38715924] losses 0.38685882779803354\n",
      "iteration 2330 x1[-1.08855596 -1.08486994 -1.07917108 -1.09114694 -1.08322072] x2[-1.08398361 -1.08473574 -1.08196261 -1.08205497 -1.08169724] loss [0.38595185 0.38638115 0.38763344 0.38585989 0.38707263] losses 0.38657979161714173\n",
      "iteration 2340 x1[-1.08959931 -1.08704795 -1.08226538 -1.09232674 -1.08572554] x2[-1.08565629 -1.08771487 -1.08330889 -1.08402455 -1.08360754] loss [0.38555348 0.38562433 0.38697555 0.38539771 0.38642164] losses 0.3859945412694673\n",
      "iteration 2350 x1[-1.09091618 -1.08798541 -1.08398682 -1.0917109  -1.08587356] x2[-1.08527966 -1.0902182  -1.08287682 -1.08410518 -1.08377607] loss [0.38541733 0.38512189 0.38678523 0.38547503 0.38637505] losses 0.38583490471752163\n",
      "iteration 2360 x1[-1.09166307 -1.08715557 -1.08632434 -1.0929539  -1.08830299] x2[-1.08625884 -1.0906723  -1.0830855  -1.08604123 -1.08493123] loss [0.38516502 0.38517733 0.38641084 0.38501004 0.38584918] losses 0.38552248219045726\n",
      "iteration 2370 x1[-1.09191626 -1.08730366 -1.08859857 -1.09110848 -1.08821436] x2[-1.0867288  -1.09318957 -1.08360186 -1.08659858 -1.08553673] loss [0.38505934 0.38479073 0.38600196 0.38519563 0.38577307] losses 0.38536414447587863\n",
      "iteration 2380 x1[-1.09374495 -1.08738939 -1.08994132 -1.09127511 -1.08831458] x2[-1.08826113 -1.09366761 -1.08496331 -1.08965374 -1.08753564] loss [0.38457031 0.38470909 0.38560561 0.38472467 0.38546525] losses 0.385014985570779\n",
      "iteration 2390 x1[-1.09499978 -1.08761244 -1.09181255 -1.09177611 -1.089404  ] x2[-1.08819539 -1.09412494 -1.08628334 -1.09003479 -1.08847052] loss [0.38439895 0.3846104  0.38513974 0.38459643 0.38516957] losses 0.3847830180865553\n",
      "iteration 2400 x1[-1.09802298 -1.08985858 -1.09312431 -1.09561177 -1.09165004] x2[-1.08874296 -1.09564809 -1.08734277 -1.08967311 -1.08889353] loss [0.38388487 0.38406275 0.38479443 0.38409502 0.38478114] losses 0.3843236434250294\n",
      "iteration 2410 x1[-1.10044024 -1.09085839 -1.0939659  -1.09698777 -1.09192061] x2[-1.09169761 -1.09747912 -1.08994339 -1.09255979 -1.09118562] loss [0.38310922 0.38365424 0.38429283 0.3834776  0.38440806] losses 0.383788389351808\n",
      "iteration 2420 x1[-1.10050017 -1.09199345 -1.09556394 -1.09842794 -1.09369922] x2[-1.09247679 -1.09574847 -1.08987187 -1.09357159 -1.09174751] loss [0.38298758 0.3837378  0.38407292 0.38312475 0.38406896] losses 0.3835984016555002\n",
      "iteration 2430 x1[-1.10161096 -1.09271916 -1.09461359 -1.0995196  -1.09374667] x2[-1.09402886 -1.09930979 -1.09036683 -1.09536013 -1.09283501] loss [0.38260483 0.38312216 0.3841377  0.38271049 0.38390444] losses 0.38329592333094475\n",
      "iteration 2440 x1[-1.10218099 -1.09474459 -1.0952515  -1.09852305 -1.09355064] x2[-1.09426672 -1.10097279 -1.09239457 -1.09427932 -1.09313992] loss [0.38248952 0.38259217 0.38375116 0.38300883 0.38388863] losses 0.3831460632131395\n",
      "iteration 2450 x1[-1.10384501 -1.09569715 -1.09615443 -1.10026001 -1.09446934] x2[-1.09580901 -1.10129534 -1.09276009 -1.0958253  -1.09367892] loss [0.38203129 0.38240894 0.38356826 0.38253787 0.38367798] losses 0.38284486941807533\n",
      "iteration 2460 x1[-1.10571895 -1.09674568 -1.09756096 -1.10117335 -1.09525354] x2[-1.09630421 -1.10072795 -1.09389596 -1.09531229 -1.0935936 ] loss [0.38169555 0.38233882 0.38320199 0.38248175 0.38357726] losses 0.3826590728010927\n",
      "iteration 2470 x1[-1.10570119 -1.09848211 -1.09786538 -1.10025977 -1.09473156] x2[-1.09630232 -1.0993721  -1.09525831 -1.09585191 -1.09495181] loss [0.38169832 0.38228314 0.38296173 0.38253408 0.3834564 ] losses 0.38258673298673823\n",
      "iteration 2480 x1[-1.10803945 -1.10143383 -1.09913888 -1.10199856 -1.09601469] x2[-1.09608919 -1.09891377 -1.09558553 -1.09564943 -1.09501494] loss [0.38140057 0.38192753 0.38273239 0.3823159  0.38326247] losses 0.38232777258939893\n",
      "iteration 2490 x1[-1.11007917 -1.10404593 -1.09917134 -1.10367368 -1.09653163] x2[-1.09778647 -1.10114366 -1.09845573 -1.09527245 -1.09611256] loss [0.38087142 0.38123889 0.38231561 0.38213286 0.3830301 ] losses 0.3819177749182525\n",
      "iteration 2500 x1[-1.11213798 -1.10573757 -1.10102575 -1.10592875 -1.09868806] x2[-1.09945438 -1.10121401 -1.10064809 -1.09476982 -1.09633151] loss [0.38034594 0.3809901  0.38173801 0.38188722 0.38268946] losses 0.38153014681328\n",
      "iteration 2510 x1[-1.11287476 -1.10451598 -1.10248476 -1.1074896  -1.10061832] x2[-1.099311   -1.10241378 -1.10379574 -1.09365436 -1.0977328 ] loss [0.38026422 0.38099187 0.38108364 0.38182925 0.38221273] losses 0.38127634285626405\n",
      "iteration 2520 x1[-1.11338352 -1.10478324 -1.10185597 -1.10896726 -1.10108165] x2[-1.09871884 -1.10312098 -1.10442473 -1.09405061 -1.09861516] loss [0.38027851 0.38085379 0.38108401 0.38156502 0.38202036] losses 0.38116033928477044\n",
      "iteration 2530 x1[-1.11194688 -1.10531249 -1.10247961 -1.10821466 -1.10178105] x2[-1.09937387 -1.10285664 -1.10506824 -1.09682806 -1.10044214] loss [0.380384   0.38081658 0.38090455 0.3812697  0.38165992] losses 0.3810069504455284\n",
      "iteration 2540 x1[-1.11110989 -1.10619362 -1.10477746 -1.10760783 -1.10358496] x2[-1.1004541  -1.10384175 -1.10694734 -1.09796592 -1.10195519] loss [0.38034606 0.38055283 0.38031449 0.38119134 0.38118869] losses 0.38071868341592185\n",
      "iteration 2550 x1[-1.11202788 -1.10552784 -1.10371861 -1.10983311 -1.10445559] x2[-1.10008241 -1.10347999 -1.10641483 -1.09742543 -1.10190321] loss [0.38027147 0.38069785 0.38053913 0.38095759 0.38107294] losses 0.38070779671287847\n",
      "iteration 2560 x1[-1.1128648  -1.10693357 -1.10389804 -1.11127264 -1.10518756] x2[-1.10214137 -1.10503377 -1.10613579 -1.09916896 -1.10236433] loss [0.37986194 0.38028023 0.38055301 0.38050705 0.38090408] losses 0.3804212594413518\n",
      "iteration 2570 x1[-1.11278229 -1.1078821  -1.10625811 -1.1117248  -1.10733017] x2[-1.10362837 -1.10680398 -1.10712607 -1.09967738 -1.10310446] loss [0.37966232 0.37989759 0.38008055 0.38037146 0.38049749] losses 0.38010188251370314\n",
      "iteration 2580 x1[-1.11469311 -1.10843577 -1.10661629 -1.11366775 -1.10834552] x2[-1.10316398 -1.10567636 -1.10865621 -1.10110889 -1.10482417] loss [0.37946369 0.37997876 0.37981549 0.37989766 0.38011168] losses 0.3798534578476071\n",
      "iteration 2590 x1[-1.11532662 -1.11099556 -1.10796329 -1.11532778 -1.11019359] x2[-1.10419143 -1.1049935  -1.10682779 -1.10202974 -1.10376204] loss [0.37923066 0.37971755 0.37988285 0.37953723 0.38000352] losses 0.37967436208994326\n",
      "iteration 2600 x1[-1.1152023  -1.10925276 -1.10689082 -1.11762532 -1.1113746 ] x2[-1.10494388 -1.10568089 -1.10702129 -1.10396085 -1.10485767] loss [0.3791414  0.37986377 0.38000625 0.37894711 0.37968396] losses 0.37952849854451076\n",
      "iteration 2610 x1[-1.11534956 -1.10890773 -1.10809471 -1.11844158 -1.11267069] x2[-1.1066145  -1.10587518 -1.10962008 -1.10487745 -1.10640083] loss [0.37888545 0.37988465 0.37947296 0.37870552 0.37928617] losses 0.37924695125074176\n",
      "iteration 2620 x1[-1.11580354 -1.11135179 -1.10910152 -1.11778639 -1.11264181] x2[-1.10704895 -1.10489536 -1.11093401 -1.10527441 -1.1071699 ] loss [0.37876173 0.37968181 0.37914855 0.37873923 0.37918197] losses 0.37910265918562214\n",
      "iteration 2630 x1[-1.11603714 -1.11107424 -1.11102408 -1.1179635  -1.11385986] x2[-1.10817469 -1.10650488 -1.11007148 -1.10707356 -1.1078016 ] loss [0.37857142 0.37949347 0.3790004  0.37846136 0.37892441] losses 0.3788902122017021\n",
      "iteration 2640 x1[-1.11746135 -1.11144441 -1.11114451 -1.11981994 -1.11442486] x2[-1.10810134 -1.10709299 -1.10957129 -1.10839573 -1.10848938] loss [0.37838586 0.3793592  0.37905351 0.37802163 0.37874977] losses 0.3787139954367021\n",
      "iteration 2650 x1[-1.11625894 -1.10992713 -1.11130789 -1.11876718 -1.11404579] x2[-1.10942346 -1.10993386 -1.11101512 -1.10866717 -1.10926491] loss [0.37836593 0.37917265 0.37882924 0.3781275  0.37869358] losses 0.37863778124277314\n",
      "iteration 2660 x1[-1.11583041 -1.11071239 -1.11271758 -1.11992851 -1.11588025] x2[-1.10954371 -1.1112366  -1.11456185 -1.10869756 -1.11192929] loss [0.37840814 0.37888137 0.37814096 0.37796449 0.37806854] losses 0.3782926978863085\n",
      "iteration 2670 x1[-1.11646715 -1.11144152 -1.11319137 -1.12082746 -1.11685234] x2[-1.11232246 -1.11381205 -1.11518463 -1.11136269 -1.11320325] loss [0.37793304 0.37842212 0.37798919 0.37746946 0.37775775] losses 0.37791431205929193\n",
      "iteration 2680 x1[-1.11763754 -1.11507987 -1.11394274 -1.12107136 -1.11738414] x2[-1.11236452 -1.11428146 -1.11503348 -1.11250807 -1.11407307] loss [0.37776632 0.37785265 0.37790593 0.37727687 0.37756413] losses 0.37767318144777234\n",
      "iteration 2690 x1[-1.11760531 -1.11461918 -1.11420398 -1.1213467  -1.11755078] x2[-1.11581366 -1.11528945 -1.11734405 -1.11557836 -1.11639277] loss [0.37729328 0.37777701 0.37755152 0.37681424 0.37722097] losses 0.3773314059770087\n",
      "iteration 2700 x1[-1.11883778 -1.117365   -1.11546395 -1.12309224 -1.11943697] x2[-1.11601439 -1.1170087  -1.11864907 -1.11522495 -1.11699513] loss [0.37709663 0.37716174 0.37719838 0.37662591 0.37687962] losses 0.37699245594475383\n",
      "iteration 2710 x1[-1.12130397 -1.11906946 -1.11674957 -1.12506924 -1.12080932] x2[-1.11770429 -1.11874848 -1.11992434 -1.1158814  -1.11761028] loss [0.37652744 0.37668926 0.3768468  0.37626791 0.37660773] losses 0.3765878277217992\n",
      "iteration 2720 x1[-1.12273511 -1.1200278  -1.11944264 -1.12649757 -1.12287973] x2[-1.11820644 -1.11867969 -1.12196949 -1.11683267 -1.11913787] loss [0.376264   0.37656767 0.37619869 0.37594443 0.37611677] losses 0.37621831109621934\n",
      "iteration 2730 x1[-1.12434505 -1.12159004 -1.12064512 -1.12695312 -1.12289918] x2[-1.11973426 -1.11926235 -1.12176998 -1.11974528 -1.12051554] loss [0.37583676 0.37627495 0.3760616  0.37548373 0.37592588] losses 0.3759165835259003\n",
      "iteration 2740 x1[-1.12545219 -1.12115767 -1.12107767 -1.12770493 -1.12344416] x2[-1.12098478 -1.12122932 -1.12358477 -1.12135783 -1.12249588] loss [0.3755166  0.37606532 0.37575632 0.37516279 0.37558245] losses 0.37561669534836695\n",
      "iteration 2750 x1[-1.12659481 -1.12159999 -1.12108943 -1.12901006 -1.12333684] x2[-1.12217019 -1.1219337  -1.12437153 -1.12290146 -1.12402896] loss [0.37520138 0.37590925 0.37564825 0.37477816 0.37538918] losses 0.37538524582779026\n",
      "iteration 2760 x1[-1.12871092 -1.12528387 -1.12242114 -1.13053917 -1.12487899] x2[-1.12435237 -1.12406011 -1.12730266 -1.12421984 -1.12613258] loss [0.37462165 0.37512168 0.37507216 0.37439542 0.3748966 ] losses 0.37482150337829934\n",
      "iteration 2770 x1[-1.13131286 -1.12817941 -1.12516351 -1.13115661 -1.12618203] x2[-1.12655478 -1.12657264 -1.1275118  -1.12602409 -1.12638805] loss [0.37397745 0.37439338 0.37467278 0.37406967 0.3746865 ] losses 0.37435995560451285\n",
      "iteration 2780 x1[-1.13363203 -1.12994859 -1.12705274 -1.13400376 -1.12854794] x2[-1.12825285 -1.12832852 -1.12881156 -1.12809714 -1.12797432] loss [0.37344185 0.37392109 0.37424419 0.37341357 0.37415578] losses 0.37383529627960155\n",
      "iteration 2790 x1[-1.13468615 -1.13352467 -1.12845402 -1.13437486 -1.12955821] x2[-1.1309551  -1.13083869 -1.12864421 -1.12990562 -1.12832744] loss [0.37294169 0.37311065 0.37407862 0.37312267 0.37397336] losses 0.3734453976522175\n",
      "iteration 2800 x1[-1.13432896 -1.13530087 -1.13077847 -1.13311408 -1.13080424] x2[-1.13184486 -1.13174738 -1.1304811  -1.12993368 -1.12930554] loss [0.37287052 0.37275528 0.37352284 0.37328565 0.3736763 ] losses 0.3732221166318541\n",
      "iteration 2810 x1[-1.13384882 -1.13658658 -1.13110806 -1.13243498 -1.13056528] x2[-1.13272687 -1.13448415 -1.13200784 -1.13065384 -1.13034502] loss [0.37281692 0.37222372 0.37327585 0.37327964 0.37356938] losses 0.3730331013253211\n",
      "iteration 2820 x1[-1.13394426 -1.13914103 -1.13264091 -1.1332381  -1.13203296] x2[-1.13263801 -1.13531955 -1.13400285 -1.13013397 -1.13126667] loss [0.37281608 0.37177913 0.37280796 0.3732425  0.37325141] losses 0.3727794172600052\n",
      "iteration 2830 x1[-1.1348096  -1.14072467 -1.13469636 -1.1345285  -1.13389792] x2[-1.13309829 -1.13598377 -1.13468945 -1.13234267 -1.13289056] loss [0.37264083 0.37148542 0.37244544 0.37277809 0.37278873] losses 0.3724277039230893\n",
      "iteration 2840 x1[-1.1348807  -1.14138713 -1.13718062 -1.13524579 -1.13605263] x2[-1.13284984 -1.13586059 -1.1359607  -1.13257972 -1.13395512] loss [0.37266437 0.37141556 0.37195122 0.37265205 0.37236377] losses 0.3722093938068042\n",
      "iteration 2850 x1[-1.13526115 -1.14292919 -1.13886256 -1.13521638 -1.13726965] x2[-1.13408141 -1.13488616 -1.13775984 -1.13230589 -1.13442021] loss [0.37245126 0.3713441  0.371495   0.37269225 0.37214253] losses 0.3720250282867029\n",
      "iteration 2860 x1[-1.13594736 -1.14393464 -1.1380692  -1.13425706 -1.13602441] x2[-1.13703824 -1.13720251 -1.14067272 -1.13255683 -1.13557524] loss [0.37197164 0.37090971 0.37121863 0.37278552 0.37215377] losses 0.3718078551458231\n",
      "iteration 2870 x1[-1.13742848 -1.14480152 -1.13661653 -1.13610955 -1.13597743] x2[-1.13838817 -1.13787241 -1.14023445 -1.13379939 -1.13581122] loss [0.3716004  0.37071027 0.37146604 0.37237687 0.37212889] losses 0.37165649325758515\n",
      "iteration 2880 x1[-1.13859526 -1.14551059 -1.13970507 -1.13818038 -1.1390594 ] x2[-1.13800292 -1.13705909 -1.14256819 -1.13553219 -1.13854069] loss [0.3714981  0.37072563 0.37075916 0.37187665 0.37136715] losses 0.37124533859884606\n",
      "iteration 2890 x1[-1.13894515 -1.14575616 -1.14047703 -1.1379668  -1.13912746] x2[-1.13882589 -1.14002661 -1.14445769 -1.13639826 -1.14053741] loss [0.3713448  0.37030635 0.37041472 0.3717907  0.37109794] losses 0.3709909027404929\n",
      "iteration 2900 x1[-1.14157237 -1.14793966 -1.14144    -1.14074351 -1.14090282] x2[-1.14080323 -1.14172836 -1.144952   -1.13745177 -1.14131002] loss [0.37074527 0.36980571 0.37022601 0.37129027 0.37076638] losses 0.3705667266232031\n",
      "iteration 2910 x1[-1.14301449 -1.14998715 -1.14152038 -1.14051367 -1.14094515] x2[-1.14005278 -1.14170219 -1.1463561  -1.13854876 -1.14333034] loss [0.37065615 0.36954833 0.37003527 0.3711766  0.37049928] losses 0.37038312707653354\n",
      "iteration 2920 x1[-1.14303361 -1.15101735 -1.14208856 -1.14054526 -1.14147562] x2[-1.14139454 -1.14084713 -1.14751361 -1.13962173 -1.14438981] loss [0.37047928 0.36952857 0.36981346 0.37103246 0.37029376] losses 0.3702295044232199\n",
      "iteration 2930 x1[-1.14334501 -1.1518996  -1.14179836 -1.14129604 -1.14213696] x2[-1.1422215  -1.14165638 -1.14748262 -1.14018458 -1.14471447] loss [0.37033184 0.3693119  0.36985502 0.37086159 0.37016623] losses 0.3701053169618107\n",
      "iteration 2940 x1[-1.14410271 -1.15213993 -1.14354929 -1.14251153 -1.14380152] x2[-1.14301    -1.13940855 -1.14614337 -1.14233676 -1.144508  ] loss [0.37013207 0.36957369 0.36980005 0.37042467 0.36997766] losses 0.3699816295092983\n",
      "iteration 2950 x1[-1.14529116 -1.15285897 -1.14300525 -1.14482645 -1.14452141] x2[-1.14334241 -1.14154328 -1.14829414 -1.14310722 -1.14640143] loss [0.36993617 0.36920541 0.36959521 0.3700263  0.36964166] losses 0.36968094932710793\n",
      "iteration 2960 x1[-1.14463287 -1.15199773 -1.14387315 -1.14481227 -1.14502291] x2[-1.14461315 -1.14158248 -1.14902622 -1.14342019 -1.14666215] loss [0.369857   0.36930907 0.36938989 0.36998771 0.36954373] losses 0.3696174787367846\n",
      "iteration 2970 x1[-1.14632631 -1.15334082 -1.14629519 -1.14637659 -1.14696821] x2[-1.14537316 -1.14335636 -1.14932508 -1.14261488 -1.1461768 ] loss [0.36954174 0.36891014 0.36904051 0.36989088 0.3693564 ] losses 0.3693479345267554\n",
      "iteration 2980 x1[-1.14595304 -1.15343934 -1.14706765 -1.14563969 -1.14693944] x2[-1.14567642 -1.14313258 -1.14893133 -1.14390947 -1.14673485] loss [0.36955066 0.36892663 0.36899173 0.36981822 0.36928858] losses 0.3693151624834023\n",
      "iteration 2990 x1[-1.14693755 -1.15376952 -1.1484814  -1.14541417 -1.14761387] x2[-1.14738199 -1.14486184 -1.14905001 -1.14562482 -1.14762968] loss [0.36920603 0.36866224 0.3687961  0.36962647 0.36908791] losses 0.3690757515882903\n",
      "iteration 3000 x1[-1.1469985  -1.15298211 -1.14846658 -1.14618057 -1.14850874] x2[-1.14859996 -1.14496048 -1.15059803 -1.14727275 -1.14920079] loss [0.36904278 0.36874872 0.36860134 0.36931696 0.36877343] losses 0.3688966476508211\n",
      "iteration 3010 x1[-1.14825194 -1.15297554 -1.14762551 -1.14716021 -1.14827217] x2[-1.14951532 -1.14591309 -1.15187749 -1.1484413  -1.15073954] loss [0.36876617 0.36862724 0.36854668 0.36904232 0.36860819] losses 0.3687181196079754\n",
      "iteration 3020 x1[-1.15015197 -1.15307015 -1.14752836 -1.14861112 -1.14843143] x2[-1.15157376 -1.14595364 -1.15310396 -1.14915878 -1.15133018] loss [0.36826346 0.36861011 0.36840432 0.36876573 0.36851308] losses 0.368511340752519\n",
      "iteration 3030 x1[-1.15042213 -1.15305198 -1.14704604 -1.14846716 -1.14784282] x2[-1.1519595  -1.14827908 -1.1524403  -1.15031987 -1.15143439] loss [0.36818043 0.36831508 0.36854966 0.36863655 0.36857497] losses 0.36845133637694727\n",
      "iteration 3040 x1[-1.1493245  -1.15176352 -1.14885849 -1.14748577 -1.14868689] x2[-1.15437922 -1.15003873 -1.15361955 -1.15302841 -1.15335627] loss [0.36801503 0.36825384 0.3681698  0.36841928 0.36822479] losses 0.36821654773285384\n",
      "iteration 3050 x1[-1.1502034  -1.15253204 -1.15132466 -1.14821035 -1.15033571] x2[-1.15669559 -1.15239592 -1.15368107 -1.15425937 -1.15363892] loss [0.36761342 0.36785849 0.36784911 0.36817193 0.36797967] losses 0.3678945258032535\n",
      "iteration 3060 x1[-1.15085989 -1.15080332 -1.15003502 -1.14871664 -1.14942536] x2[-1.15781109 -1.15318975 -1.15581821 -1.15368683 -1.15407626] loss [0.36739119 0.36797694 0.36774442 0.3681794  0.36804027] losses 0.3678664443989682\n",
      "iteration 3070 x1[-1.15172833 -1.15284849 -1.1488386  -1.14946705 -1.14905556] x2[-1.15795975 -1.15529153 -1.15578823 -1.15472888 -1.15448316] loss [0.36726287 0.3674546  0.36790022 0.36795302 0.36803618] losses 0.36772137975645125\n",
      "iteration 3080 x1[-1.15283563 -1.15417842 -1.14859804 -1.15020775 -1.14938211] x2[-1.15994488 -1.15483592 -1.15668871 -1.15714862 -1.15560898] loss [0.36687688 0.3673444  0.3678183  0.36755635 0.36785353] losses 0.36748989371617374\n",
      "iteration 3090 x1[-1.15232902 -1.15215003 -1.15049142 -1.1505122  -1.15078483] x2[-1.16074769 -1.15622579 -1.15776111 -1.15791419 -1.15624872] loss [0.36684147 0.36742581 0.36744409 0.3674224  0.36759554] losses 0.3673458623657133\n",
      "iteration 3100 x1[-1.15373906 -1.15106567 -1.15140975 -1.1518423  -1.15185454] x2[-1.16309758 -1.15660983 -1.15842293 -1.16156807 -1.15825842] loss [0.36637468 0.36751488 0.36724554 0.36680167 0.36720978] losses 0.36702931129675587\n",
      "iteration 3110 x1[-1.15397178 -1.15186884 -1.15259953 -1.15156213 -1.15248344] x2[-1.16377159 -1.15711882 -1.16000436 -1.16284695 -1.15966822] loss [0.3662628  0.36734985 0.36689927 0.36667968 0.36695551] losses 0.3668294212561386\n",
      "iteration 3120 x1[-1.15333108 -1.15255441 -1.15330082 -1.15293017 -1.1541333 ] x2[-1.16557845 -1.15741289 -1.16043471 -1.16431527 -1.15992332] loss [0.36612242 0.3672267  0.36675775 0.36632716 0.36671638] losses 0.36663008152499216\n",
      "iteration 3130 x1[-1.1531953  -1.1530961  -1.15357385 -1.15332537 -1.15448896] x2[-1.16385748 -1.15693266 -1.16132048 -1.16414165 -1.16100915] loss [0.36634985 0.36721831 0.36661407 0.36629869 0.36653758] losses 0.3666037001664076\n",
      "iteration 3140 x1[-1.15283419 -1.15283261 -1.15454214 -1.15301867 -1.15474371] x2[-1.16588895 -1.15633497 -1.1612657  -1.16557926 -1.16125524] loss [0.36614707 0.36732609 0.36649927 0.36616161 0.36647529] losses 0.36652186712205903\n",
      "iteration 3150 x1[-1.15296879 -1.1533536  -1.15456965 -1.15412895 -1.15556884] x2[-1.16578711 -1.15774488 -1.16239472 -1.165581   -1.16185628] loss [0.36614254 0.36708471 0.3663568  0.36602191 0.36629794] losses 0.36638078178095557\n",
      "iteration 3160 x1[-1.15359142 -1.15500789 -1.1557748  -1.15452403 -1.15662503] x2[-1.16410441 -1.15548218 -1.16345616 -1.16582216 -1.1628946 ] loss [0.36626981 0.3671594  0.36607565 0.36594297 0.36603841] losses 0.3662972491653009\n",
      "iteration 3170 x1[-1.15387688 -1.15526334 -1.15560022 -1.15534495 -1.15664267] x2[-1.16389483 -1.15336135 -1.16383945 -1.16584043 -1.16345381] loss [0.36625962 0.36739355 0.3660505  0.36583797 0.36596761] losses 0.36630185176025243\n",
      "iteration 3180 x1[-1.15600944 -1.15572626 -1.15632543 -1.1563629  -1.15687627] x2[-1.16301875 -1.15371981 -1.16286073 -1.1646973  -1.16250599] loss [0.36609999 0.36729053 0.36607994 0.36585031 0.36605483] losses 0.3662751199764759\n",
      "iteration 3190 x1[-1.15573572 -1.15779208 -1.15568003 -1.1575332  -1.15779362] x2[-1.16337589 -1.15546387 -1.16444038 -1.16480549 -1.1634457 ] loss [0.36609037 0.36681407 0.36596698 0.36569132 0.36582533] losses 0.3660776137942414\n",
      "iteration 3200 x1[-1.15710995 -1.15808237 -1.15576322 -1.15863024 -1.15807723] x2[-1.16329636 -1.15686797 -1.1643545  -1.16427833 -1.16289842] loss [0.36592869 0.36660259 0.36596709 0.3656195  0.36585721] losses 0.3659950175598967\n",
      "iteration 3210 x1[-1.15726696 -1.15654533 -1.15580759 -1.15855993 -1.15788892] x2[-1.16279358 -1.15661362 -1.16499133 -1.1639978  -1.16353315] loss [0.36597084 0.36682575 0.36588372 0.36566254 0.36580276] losses 0.3660291232601759\n",
      "iteration 3220 x1[-1.1580634  -1.1587625  -1.15611042 -1.15915587 -1.15819499] x2[-1.16234772 -1.15645726 -1.16628119 -1.16376421 -1.16447889] loss [0.36592657 0.36656936 0.36568867 0.36561727 0.36564899] losses 0.36589017170813765\n",
      "iteration 3230 x1[-1.15885948 -1.1589303  -1.15596309 -1.15884226 -1.15726048] x2[-1.16215422 -1.15588683 -1.16521834 -1.16536696 -1.16491242] loss [0.36585156 0.36661978 0.36583658 0.36546027 0.36571219] losses 0.36589607853982964\n",
      "iteration 3240 x1[-1.15890205 -1.15942965 -1.15720747 -1.16036291 -1.15924374] x2[-1.1622231  -1.15638258 -1.16491394 -1.16415709 -1.16385203] loss [0.36583782 0.36649596 0.36571861 0.36541992 0.36559563] losses 0.36581358747490667\n",
      "iteration 3250 x1[-1.15990165 -1.15821207 -1.15913763 -1.16065582 -1.16010636] x2[-1.16228575 -1.15617191 -1.16578628 -1.16579852 -1.16540016] loss [0.36570636 0.36667333 0.36537258 0.36518345 0.36529981] losses 0.3656471049778515\n",
      "iteration 3260 x1[-1.1601612  -1.15775725 -1.15979523 -1.16124972 -1.16074759] x2[-1.16282912 -1.15638523 -1.16442603 -1.167819   -1.16555227] loss [0.36560754 0.36670325 0.36545718 0.36486487 0.36520212] losses 0.3655669911305338\n",
      "iteration 3270 x1[-1.16040393 -1.15879745 -1.1588339  -1.16044442 -1.15941748] x2[-1.16429174 -1.15789243 -1.16450951 -1.16908515 -1.16628369] loss [0.36539839 0.36638624 0.36556599 0.364811   0.36527739] losses 0.3654878021514708\n",
      "iteration 3280 x1[-1.16070146 -1.15825808 -1.15884431 -1.16113512 -1.15979866] x2[-1.16705507 -1.16072242 -1.16756756 -1.17054391 -1.16791485] loss [0.36502505 0.36610259 0.36519244 0.36455011 0.36503226] losses 0.3651804903894925\n",
      "iteration 3290 x1[-1.16180128 -1.15992089 -1.16009193 -1.16257487 -1.16139376] x2[-1.17041073 -1.16425576 -1.16936706 -1.17267295 -1.16963241] loss [0.36448418 0.36546246 0.36482048 0.36411793 0.36462802] losses 0.3647026139139357\n",
      "iteration 3300 x1[-1.16361247 -1.1623918  -1.16085273 -1.16380082 -1.16215548] x2[-1.17024009 -1.16437824 -1.16837472 -1.1733962  -1.16960315] loss [0.36428263 0.36514304 0.36484651 0.36388149 0.36453791] losses 0.3645383144458273\n",
      "iteration 3310 x1[-1.16392577 -1.16205777 -1.16161907 -1.16514581 -1.16334127] x2[-1.17004122 -1.16446672 -1.16743577 -1.17404188 -1.16955655] loss [0.36426825 0.36517327 0.36486585 0.36364046 0.36439813] losses 0.36446919306519987\n",
      "iteration 3320 x1[-1.16485385 -1.16395833 -1.16037103 -1.1664107  -1.16345762] x2[-1.17033036 -1.16573514 -1.16832815 -1.17593918 -1.17134177] loss [0.36412017 0.36478555 0.36491154 0.36326142 0.36416922] losses 0.36424958133724106\n",
      "iteration 3330 x1[-1.16593463 -1.16573822 -1.15965527 -1.16742627 -1.16319574] x2[-1.16962026 -1.16461838 -1.1696091  -1.17609427 -1.17252528] loss [0.36407405 0.36470453 0.36484524 0.36312002 0.36405952] losses 0.3641606706235841\n",
      "iteration 3340 x1[-1.16656627 -1.16630211 -1.16153166 -1.16798067 -1.164552  ] x2[-1.1706351  -1.16516056 -1.17020783 -1.17650564 -1.17296188] loss [0.36387523 0.3645698  0.36454174 0.36300433 0.36384161] losses 0.3639665442780443\n",
      "iteration 3350 x1[-1.16680638 -1.16584093 -1.16233696 -1.16851722 -1.16524069] x2[-1.17141826 -1.16611134 -1.17295731 -1.17778316 -1.17553868] loss [0.36375212 0.36451014 0.36411313 0.3627888  0.36345105] losses 0.3637230467727328\n",
      "iteration 3360 x1[-1.16789385 -1.16721023 -1.16336691 -1.16908076 -1.16627155] x2[-1.1724517  -1.1657898  -1.17395629 -1.17923556 -1.17634325] loss [0.36349673 0.36438293 0.36386777 0.36255014 0.36323047] losses 0.36350560898961126\n",
      "iteration 3370 x1[-1.16855509 -1.16784711 -1.16524586 -1.17028519 -1.16803763] x2[-1.17239341 -1.16888557 -1.17494966 -1.17811486 -1.17631385] loss [0.36342383 0.36393067 0.36352033 0.36253703 0.36302013] losses 0.3632863974648406\n",
      "iteration 3380 x1[-1.16924721 -1.16925232 -1.16663832 -1.17081161 -1.1689903 ] x2[-1.17344523 -1.16925649 -1.1748829  -1.17919434 -1.17685338] loss [0.36321483 0.36371625 0.36335909 0.36234708 0.36284144] losses 0.36309573841762643\n",
      "iteration 3390 x1[-1.17207541 -1.17052847 -1.16715765 -1.172657   -1.16964618] x2[-1.17557349 -1.17084146 -1.17654782 -1.18134388 -1.17878919] loss [0.36262266 0.36337211 0.36309887 0.36187516 0.36253452] losses 0.36270066348136415\n",
      "iteration 3400 x1[-1.17333883 -1.1727269  -1.16810083 -1.17322206 -1.17062993] x2[-1.17682136 -1.16952694 -1.17650025 -1.18155929 -1.17846397] loss [0.36232442 0.36326684 0.36299045 0.36178276 0.36245462] losses 0.36256381821647987\n",
      "iteration 3410 x1[-1.17437463 -1.17216678 -1.16860397 -1.17357709 -1.17083961] x2[-1.17609455 -1.16915531 -1.17667276 -1.18112931 -1.17857826] loss [0.36228711 0.36337854 0.36290935 0.36179065 0.36241606] losses 0.36255633839259943\n",
      "iteration 3420 x1[-1.17554932 -1.1740502  -1.16888437 -1.1739176  -1.17073223] x2[-1.17631154 -1.16979793 -1.17746797 -1.18052853 -1.17858504] loss [0.3621222  0.36307651 0.36278169 0.3618203  0.36242813] losses 0.3624457654904175\n",
      "iteration 3430 x1[-1.17624921 -1.17384656 -1.16721557 -1.17423911 -1.16966045] x2[-1.17697883 -1.17020969 -1.17719816 -1.18168904 -1.17883396] loss [0.36196069 0.36305125 0.36301504 0.36164678 0.36252754] losses 0.36244026136974206\n",
      "iteration 3440 x1[-1.17674262 -1.1749654  -1.16798786 -1.17608567 -1.17122642] x2[-1.17933943 -1.17339833 -1.1777357  -1.18200876 -1.17885604] loss [0.36162504 0.36253692 0.36285828 0.36139101 0.3623371 ] losses 0.3621496688258077\n",
      "iteration 3450 x1[-1.17618585 -1.17440161 -1.16874774 -1.17743455 -1.17274023] x2[-1.17882697 -1.17174734 -1.17615632 -1.18149465 -1.17763366] loss [0.36175082 0.36280091 0.36295307 0.36129186 0.36229998] losses 0.36221932687360103\n",
      "iteration 3460 x1[-1.17628098 -1.17370608 -1.16883631 -1.1778847  -1.17301471] x2[-1.18002277 -1.17306624 -1.17616649 -1.18270431 -1.17830347] loss [0.36159953 0.36272612 0.36294119 0.36109834 0.36218846] losses 0.36211072868856664\n",
      "iteration 3470 x1[-1.17727151 -1.1731938  -1.16936127 -1.17939611 -1.17402699] x2[-1.18118612 -1.17452816 -1.17747168 -1.18199124 -1.17833016] loss [0.36134698 0.36261318 0.36272382 0.36100396 0.36206488] losses 0.36195056458808567\n",
      "iteration 3480 x1[-1.17847023 -1.17554808 -1.17094909 -1.1798107  -1.17523862] x2[-1.18343307 -1.17572452 -1.17767831 -1.18481047 -1.17947057] loss [0.36094515 0.36219175 0.36250881 0.36062913 0.36178738] losses 0.361612446217632\n",
      "iteration 3490 x1[-1.17904718 -1.17579917 -1.17141256 -1.17879991 -1.17418693] x2[-1.1834451  -1.17487226 -1.17642325 -1.18599732 -1.17920549] loss [0.36087616 0.36226299 0.36260139 0.3606107  0.36194314] losses 0.3616588768507246\n",
      "iteration 3500 x1[-1.17980069 -1.17676417 -1.17116858 -1.17850013 -1.17329426] x2[-1.18303201 -1.17504535 -1.17585467 -1.18604488 -1.17882729] loss [0.36083588 0.36212845 0.36269786 0.36064035 0.36209364] losses 0.3616792328065956\n",
      "iteration 3510 x1[-1.17944254 -1.17831981 -1.16963866 -1.17863629 -1.17264918] x2[-1.18372276 -1.17558012 -1.17681066 -1.18782181 -1.18029904] loss [0.36079777 0.36188196 0.36276845 0.36042066 0.36199807] losses 0.36157338238945574\n",
      "iteration 3520 x1[-1.18041711 -1.17867928 -1.17102379 -1.18033837 -1.17414852] x2[-1.18569663 -1.17705483 -1.17791996 -1.18867985 -1.18115025] loss [0.36045632 0.36166563 0.36247141 0.36012383 0.36172032] losses 0.36128750225009665\n",
      "iteration 3530 x1[-1.18182583 -1.17993703 -1.17213869 -1.1813375  -1.17515326] x2[-1.18591778 -1.17765149 -1.17927879 -1.18937025 -1.18248438] loss [0.36026699 0.36144807 0.36217843 0.35992891 0.36144595] losses 0.36105367162135327\n",
      "iteration 3540 x1[-1.1810718  -1.1796861  -1.17437773 -1.18168802 -1.17726512] x2[-1.18658885 -1.17782007 -1.18319534 -1.19046847 -1.18508533] loss [0.36027759 0.3614576  0.36145532 0.35976342 0.3608958 ] losses 0.3607699456667578\n",
      "iteration 3550 x1[-1.18168543 -1.1801892  -1.1762083  -1.18354284 -1.17946406] x2[-1.18617887 -1.17773498 -1.18487999 -1.19000965 -1.18622767] loss [0.36025331 0.36140878 0.36104396 0.35960079 0.36050653] losses 0.36056267419354987\n",
      "iteration 3560 x1[-1.1824977  -1.18232059 -1.17759266 -1.18402215 -1.18041927] x2[-1.18648345 -1.17908728 -1.1850255  -1.19135223 -1.18726811] loss [0.36012411 0.36100185 0.36086419 0.35939335 0.36027573] losses 0.36033184498898285\n",
      "iteration 3570 x1[-1.18373817 -1.18419795 -1.17785055 -1.18428865 -1.18028076] x2[-1.18614976 -1.17794711 -1.18587208 -1.19136428 -1.18776052] loss [0.36001889 0.36091807 0.36073641 0.35936128 0.36023553] losses 0.360254034594319\n",
      "iteration 3580 x1[-1.18340768 -1.18497953 -1.17749082 -1.18499581 -1.18072006] x2[-1.18587408 -1.176163   -1.18710156 -1.19202927 -1.18898074] loss [0.36008873 0.36103782 0.36063749 0.35920479 0.36004507] losses 0.3602027800126278\n",
      "iteration 3590 x1[-1.18376315 -1.18519591 -1.17888719 -1.1861064  -1.18212104] x2[-1.18497044 -1.17802875 -1.18920362 -1.19245888 -1.19094423] loss [0.36015159 0.36079333 0.36023357 0.35902889 0.35965927] losses 0.35997332966437634\n",
      "iteration 3600 x1[-1.18474084 -1.18729334 -1.18075287 -1.18650322 -1.18341654] x2[-1.18655348 -1.1804034  -1.18906729 -1.19292621 -1.19101875] loss [0.35985694 0.36027469 0.36003139 0.35893083 0.35950096] losses 0.35971896399733055\n",
      "iteration 3610 x1[-1.18554206 -1.18666188 -1.18210024 -1.18736076 -1.18433497] x2[-1.18592158 -1.18078985 -1.18816095 -1.19445015 -1.19179279] loss [0.35983726 0.36030203 0.35997822 0.35866175 0.35930751] losses 0.3596173542321909\n",
      "iteration 3620 x1[-1.18585738 -1.18804042 -1.18423674 -1.18865133 -1.18674782] x2[-1.18578165 -1.1821284  -1.18779409 -1.19397914 -1.1915997 ] loss [0.3598171  0.35998872 0.35977306 0.35856754 0.3590524 ] losses 0.3594397631083841\n",
      "iteration 3630 x1[-1.18444516 -1.18702852 -1.18310459 -1.18874117 -1.18666281] x2[-1.1846025  -1.18377385 -1.18918871 -1.19269542 -1.19240206] loss [0.36011527 0.35991403 0.35974475 0.35870153 0.3589716 ] losses 0.35948943512612563\n",
      "iteration 3640 x1[-1.18524703 -1.18834901 -1.1848452  -1.18904328 -1.1877974 ] x2[-1.18519067 -1.18254157 -1.18945823 -1.19250074 -1.19207023] loss [0.35995518 0.3599056  0.35951333 0.35868911 0.35887943] losses 0.3593885300979659\n",
      "iteration 3650 x1[-1.18496819 -1.19097904 -1.18479021 -1.18716577 -1.18702876] x2[-1.1851387  -1.18163702 -1.19101222 -1.1919141  -1.19241676] loss [0.35999325 0.35971146 0.35934338 0.35896913 0.35892811] losses 0.3593890648602741\n",
      "iteration 3660 x1[-1.18516895 -1.19341621 -1.1843508  -1.18841697 -1.1877276 ] x2[-1.18528975 -1.18057899 -1.19097469 -1.19325366 -1.19337262] loss [0.35995277 0.35955923 0.3593982  0.35867563 0.35874079] losses 0.3592653235483784\n",
      "iteration 3670 x1[-1.18665743 -1.19383341 -1.18719654 -1.19114551 -1.19080941] x2[-1.18483082 -1.1824295  -1.19230356 -1.19307116 -1.19455441] loss [0.35983467 0.35929761 0.35892169 0.35838683 0.35825849] losses 0.3589398586158853\n",
      "iteration 3680 x1[-1.18742742 -1.19243909 -1.18953002 -1.19179654 -1.1921592 ] x2[-1.18510718 -1.18152495 -1.19307015 -1.19445721 -1.19589215] loss [0.35971473 0.35955941 0.35856979 0.35815799 0.35795694] losses 0.35879177340700763\n",
      "iteration 3690 x1[-1.1871405  -1.19067802 -1.18967078 -1.19140201 -1.19179031] x2[-1.1870618  -1.18246682 -1.19445807 -1.19666502 -1.1975196 ] loss [0.35952332 0.35964938 0.35839814 0.3579562  0.35781756] losses 0.3586689202688026\n",
      "iteration 3700 x1[-1.18687754 -1.19006593 -1.19068448 -1.1925723  -1.19341727] x2[-1.18788907 -1.18240207 -1.1954006  -1.19773698 -1.19837148] loss [0.35945888 0.35972632 0.35817805 0.35770552 0.3575405 ] losses 0.3585218528954597\n",
      "iteration 3710 x1[-1.18858952 -1.19112489 -1.19085963 -1.19329518 -1.19383461] x2[-1.1889144  -1.18420557 -1.19654139 -1.19833994 -1.19952933] loss [0.35914662 0.35939793 0.35803114 0.35755766 0.35736596] losses 0.3582998637581042\n",
      "iteration 3720 x1[-1.18901275 -1.19392724 -1.19147963 -1.19253055 -1.19381761] x2[-1.18970224 -1.18586523 -1.19722557 -1.19960913 -1.20077329] loss [0.35900894 0.3588914  0.35788518 0.35750332 0.35723103] losses 0.35810397310806247\n",
      "iteration 3730 x1[-1.18965537 -1.19473066 -1.1908311  -1.19288701 -1.19362618] x2[-1.18899136 -1.18510974 -1.19941149 -1.19973206 -1.20217178] loss [0.35901669 0.358888   0.3577164  0.35744977 0.3570992 ] losses 0.3580340139249386\n",
      "iteration 3740 x1[-1.18984135 -1.19664696 -1.19220195 -1.19477512 -1.19576389] x2[-1.19095766 -1.18609887 -1.20064394 -1.1998785  -1.2023463 ] loss [0.35877263 0.35856062 0.35742635 0.35722245 0.35684177] losses 0.3577647641155443\n",
      "iteration 3750 x1[-1.19005653 -1.1982048  -1.19158592 -1.19333819 -1.19466968] x2[-1.19133825 -1.18589276 -1.20056104 -1.20157698 -1.20288011] loss [0.35870523 0.35841114 0.35750474 0.35719653 0.35690531] losses 0.3577445894166399\n",
      "iteration 3760 x1[-1.19246283 -1.20079619 -1.19232487 -1.19526832 -1.19561198] x2[-1.19193353 -1.18695597 -1.20178769 -1.20278177 -1.20438248] loss [0.35836634 0.3580035  0.35728707 0.35684935 0.35663691] losses 0.3574286347715475\n",
      "iteration 3770 x1[-1.19303054 -1.2013349  -1.19176404 -1.19561863 -1.19546577] x2[-1.19253567 -1.18884227 -1.20313486 -1.20197959 -1.20448399] loss [0.35823473 0.35772975 0.35720283 0.356898   0.35664214] losses 0.35734148920055275\n",
      "iteration 3780 x1[-1.19457043 -1.20184602 -1.19143826 -1.19675807 -1.19532646] x2[-1.19271602 -1.1895575  -1.20336218 -1.20251317 -1.20481043] loss [0.35804187 0.35759266 0.35721468 0.35671321 0.35662221] losses 0.3572369237211885\n",
      "iteration 3790 x1[-1.19385975 -1.20167901 -1.19133861 -1.19563661 -1.19509323] x2[-1.19350856 -1.18871886 -1.20376872 -1.20224391 -1.20461957] loss [0.35803245 0.357706   0.35718159 0.35686711 0.35666886] losses 0.35729120191139996\n",
      "iteration 3800 x1[-1.19340098 -1.20090706 -1.19266664 -1.19679484 -1.19669603] x2[-1.1952501  -1.18939869 -1.2035518  -1.20238057 -1.20413794] loss [0.35788906 0.35771367 0.35705604 0.35672361 0.35654317] losses 0.3571851095547333\n",
      "iteration 3810 x1[-1.19176931 -1.19986654 -1.19212686 -1.19527009 -1.19609071] x2[-1.19468243 -1.1897503  -1.20194407 -1.20131629 -1.20279024] loss [0.35813587 0.35778837 0.35729219 0.3570094  0.35675701] losses 0.35739656550880355\n",
      "iteration 3820 x1[-1.1928172  -1.19978527 -1.19217795 -1.19600481 -1.19618694] x2[-1.19592667 -1.19136703 -1.20298661 -1.20109527 -1.2029899 ] loss [0.35787914 0.35761477 0.3571725  0.3569519  0.35672455] losses 0.35726857054372385\n",
      "iteration 3830 x1[-1.19301133 -1.19982869 -1.19243487 -1.19532038 -1.19619544] x2[-1.19575995 -1.19111755 -1.20318902 -1.20111395 -1.20298047] loss [0.35787592 0.3576381  0.35712157 0.35702597 0.35672464] losses 0.35727724051298865\n",
      "iteration 3840 x1[-1.19382651 -1.1985145  -1.19409823 -1.19545832 -1.19680488] x2[-1.19601096 -1.19416928 -1.20379938 -1.20072292 -1.20328076] loss [0.35775657 0.35744053 0.35686891 0.35705351 0.35662434] losses 0.35714877291471947\n",
      "iteration 3850 x1[-1.19402425 -1.19950128 -1.1945094  -1.19540569 -1.19720839] x2[-1.19528359 -1.19409357 -1.20520104 -1.19995488 -1.20417715] loss [0.3578155  0.3573401  0.35667084 0.35714377 0.35648219] losses 0.3570904789590092\n",
      "iteration 3860 x1[-1.19501261 -1.19945171 -1.19394057 -1.19675323 -1.19741323] x2[-1.19601498 -1.19568383 -1.20678235 -1.20061824 -1.20544895] loss [0.35762354 0.35716821 0.35656334 0.35692115 0.35632169] losses 0.356919585335875\n",
      "iteration 3870 x1[-1.19540527 -1.20037491 -1.19423362 -1.19767976 -1.19794213] x2[-1.19653022 -1.19690088 -1.20669301 -1.2025142  -1.20659592] loss [0.35752246 0.3569315  0.35654028 0.35661109 0.35613944] losses 0.35674895287073866\n",
      "iteration 3880 x1[-1.19579243 -1.20051075 -1.19433453 -1.19799423 -1.19808237] x2[-1.19846833 -1.19991035 -1.207451   -1.20356182 -1.20752572] loss [0.35726461 0.35658447 0.35644735 0.35646222 0.35602388] losses 0.3565565088366295\n",
      "iteration 3890 x1[-1.19502409 -1.20148765 -1.19464163 -1.19815427 -1.19864405] x2[-1.1997256  -1.20041361 -1.20822244 -1.20456514 -1.20844326] loss [0.35721152 0.35642223 0.35633021 0.3563356  0.35586354] losses 0.3564326200681543\n",
      "iteration 3900 x1[-1.19615658 -1.20356189 -1.19637056 -1.19851676 -1.19968284] x2[-1.20198901 -1.20328206 -1.20858166 -1.2041489  -1.20782783] loss [0.35683719 0.35588301 0.35609968 0.35634079 0.35581543] losses 0.3561952217820623\n",
      "iteration 3910 x1[-1.19649215 -1.20531967 -1.19644502 -1.19911491 -1.20021921] x2[-1.20299494 -1.20376591 -1.20950867 -1.20398037 -1.20794154] loss [0.35669014 0.3556401  0.35599219 0.35629323 0.35574443] losses 0.35607202007750527\n",
      "iteration 3920 x1[-1.19723518 -1.2064454  -1.19773444 -1.19824324 -1.2001108 ] x2[-1.20217483 -1.20496808 -1.21002465 -1.20324906 -1.20819184] loss [0.35669732 0.3553886  0.35579462 0.35646878 0.35572946] losses 0.356015754683232\n",
      "iteration 3930 x1[-1.19980144 -1.20745608 -1.19835812 -1.19925896 -1.20012058] x2[-1.20281838 -1.20616622 -1.21032921 -1.20333962 -1.2084269 ] loss [0.35634416 0.35515083 0.35569344 0.35634704 0.3557032 ] losses 0.3558477331897624\n",
      "iteration 3940 x1[-1.20005038 -1.20873242 -1.20058969 -1.19983404 -1.20186721] x2[-1.20409909 -1.20645835 -1.20983467 -1.20391187 -1.2083894 ] loss [0.35617757 0.3549828  0.35550137 0.35622164 0.35551638] losses 0.3556799528843565\n",
      "iteration 3950 x1[-1.19993205 -1.20890379 -1.20112974 -1.20039328 -1.2026331 ] x2[-1.20492907 -1.20673315 -1.20980461 -1.2038677  -1.20798214] loss [0.35610059 0.35493498 0.35544557 0.35616509 0.35547664] losses 0.35562457375003964\n",
      "iteration 3960 x1[-1.20166244 -1.20894522 -1.20101495 -1.20100905 -1.20227823] x2[-1.20715397 -1.20834195 -1.20816569 -1.20524617 -1.20708709] loss [0.35567126 0.35475822 0.35563335 0.3559483  0.35561133] losses 0.3555244920061\n",
      "iteration 3970 x1[-1.20252861 -1.2100343  -1.20188906 -1.20262131 -1.2037437 ] x2[-1.20731633 -1.20774713 -1.20801014 -1.20482964 -1.20676717] loss [0.35555945 0.35470582 0.35555464 0.35581745 0.3554865 ] losses 0.3554247709744006\n",
      "iteration 3980 x1[-1.2029596  -1.21087831 -1.20194312 -1.20297415 -1.20375468] x2[-1.20666342 -1.20731557 -1.20870821 -1.20584521 -1.20799678] loss [0.35558278 0.35466237 0.35547398 0.35566935 0.35535331] losses 0.35534835813021115\n",
      "iteration 3990 x1[-1.20439301 -1.2113727  -1.20445443 -1.2043393  -1.20572071] x2[-1.20687816 -1.20753256 -1.20818407 -1.20541421 -1.20737537] loss [0.35540423 0.35458672 0.35525749 0.35556775 0.35520747] losses 0.35520473436981054\n",
      "iteration 4000 x1[-1.20517239 -1.21199118 -1.20339307 -1.20445417 -1.20466796] x2[-1.20690885 -1.20865644 -1.20813036 -1.2052312  -1.20751749] loss [0.3553167  0.3544012  0.35537821 0.35557508 0.35530584] losses 0.35519540759443147\n",
      "iteration 4010 x1[-1.20533744 -1.21372159 -1.20377756 -1.20315581 -1.20415462] x2[-1.20653525 -1.20875056 -1.20703423 -1.20627805 -1.20784079] loss [0.35533905 0.35420876 0.35545412 0.35560295 0.35532671] losses 0.3551863171960255\n",
      "iteration 4020 x1[-1.20588408 -1.21415252 -1.20639527 -1.20293004 -1.20530491] x2[-1.20520509 -1.21000782 -1.20781339 -1.20584926 -1.20863643] loss [0.35542345 0.35402979 0.3550879  0.35567371 0.35511725] losses 0.35506641864986893\n",
      "iteration 4030 x1[-1.20480035 -1.21267762 -1.20708487 -1.20250057 -1.20589834] x2[-1.20595406 -1.21031893 -1.20824834 -1.20763343 -1.20954561] loss [0.35545964 0.35415191 0.35496727 0.35552845 0.35495627] losses 0.3550127076198013\n",
      "iteration 4040 x1[-1.20659519 -1.21199289 -1.20759474 -1.20353837 -1.20581345] x2[-1.20506389 -1.21067714 -1.20905816 -1.20876366 -1.21113464] loss [0.35536213 0.35418617 0.35482611 0.35529468 0.35479645] losses 0.35489310968112403\n",
      "iteration 4050 x1[-1.20649704 -1.21176117 -1.20588262 -1.20454867 -1.20536086] x2[-1.20524091 -1.21121638 -1.21066747 -1.20844398 -1.21206577] loss [0.35535358 0.35415354 0.3548386  0.35521949 0.35474655] losses 0.3548623496846258\n",
      "iteration 4060 x1[-1.20740634 -1.21104197 -1.20546505 -1.20530148 -1.20543322] x2[-1.20543957 -1.21377725 -1.21039328 -1.20877919 -1.21216079] loss [0.35523445 0.3539596  0.35491269 0.35510236 0.3547287 ] losses 0.3547875618852948\n",
      "iteration 4070 x1[-1.2076626  -1.21120524 -1.20527849 -1.20563227 -1.20551481] x2[-1.20503384 -1.21236186 -1.21094943 -1.20910543 -1.21286201] loss [0.35525075 0.3540913  0.35487372 0.35503187 0.35464585] losses 0.3547786961005797\n",
      "iteration 4080 x1[-1.20809703 -1.20959418 -1.20452661 -1.20635172 -1.20530998] x2[-1.20461888 -1.21160433 -1.21044399 -1.20882622 -1.21251775] loss [0.35524903 0.35434223 0.35500855 0.35498425 0.35470425] losses 0.3548576628819462\n",
      "iteration 4090 x1[-1.20791084 -1.20997568 -1.20539096 -1.20560803 -1.2055774 ] x2[-1.20482792 -1.21154465 -1.20957246 -1.2089765  -1.21189923] loss [0.35524639 0.35430799 0.35500806 0.35504824 0.35474085] losses 0.3548703057702805\n",
      "iteration 4100 x1[-1.20974334 -1.21044953 -1.20662289 -1.20732934 -1.20696638] x2[-1.20506322 -1.21294568 -1.2113812  -1.20711026 -1.21232849] loss [0.35502519 0.35410981 0.35468332 0.35506297 0.35454626] losses 0.3546855116176916\n",
      "iteration 4110 x1[-1.21214465 -1.21116456 -1.20908723 -1.21000388 -1.20934857] x2[-1.20494032 -1.21329667 -1.21274143 -1.20638526 -1.21256504] loss [0.35478353 0.35399714 0.35427609 0.3548551  0.35426688] losses 0.35443574686551027\n",
      "iteration 4120 x1[-1.21162918 -1.20981333 -1.20965996 -1.21013123 -1.20962577] x2[-1.20504894 -1.21191025 -1.21348714 -1.20737404 -1.21337237] loss [0.35482638 0.35428658 0.35413664 0.35473546 0.35415235] losses 0.35442748287080933\n",
      "iteration 4130 x1[-1.2127517  -1.20981406 -1.21244287 -1.21130196 -1.2118413 ] x2[-1.20518286 -1.21107396 -1.21262686 -1.20894264 -1.21367374] loss [0.35469324 0.354375   0.35393266 0.3544436  0.35388599] losses 0.35426609674422227\n",
      "iteration 4140 x1[-1.21445673 -1.21036727 -1.21352973 -1.21164313 -1.21228029] x2[-1.2063449  -1.2123013  -1.21369779 -1.20986642 -1.21482213] loss [0.35438878 0.35418647 0.3537057  0.35430918 0.35371929] losses 0.35406188421697943\n",
      "iteration 4150 x1[-1.21511914 -1.20988886 -1.21358444 -1.2122491  -1.21254826] x2[-1.20648135 -1.21352867 -1.21513271 -1.20974136 -1.21551507] loss [0.35430468 0.35410795 0.35354967 0.35425844 0.35361864] losses 0.3539678770405025\n",
      "iteration 4160 x1[-1.21516126 -1.21025808 -1.21383703 -1.21304525 -1.21321409] x2[-1.20826262 -1.21451454 -1.21553179 -1.2108819  -1.21561738] loss [0.35410975 0.35396527 0.3534815  0.35405351 0.35353794] losses 0.3538295953430452\n",
      "iteration 4170 x1[-1.21606682 -1.21077065 -1.21453198 -1.21363082 -1.21378688] x2[-1.2091704  -1.21557315 -1.21611997 -1.21179507 -1.21644146] loss [0.35391842 0.3538002  0.35334741 0.35389538 0.35339196] losses 0.35367067153916193\n",
      "iteration 4180 x1[-1.21671341 -1.21035661 -1.21459714 -1.21420468 -1.21404832] x2[-1.20845022 -1.21651501 -1.21650843 -1.21128535 -1.21655351] loss [0.35392766 0.35374579 0.35330016 0.35388899 0.35335291] losses 0.3536431015495699\n",
      "iteration 4190 x1[-1.21798196 -1.21398661 -1.2144753  -1.2159922  -1.21481735] x2[-1.21022622 -1.21906182 -1.21669156 -1.21204749 -1.21668011] loss [0.35360713 0.35309946 0.35329386 0.3536216  0.35325929] losses 0.35337626913472525\n",
      "iteration 4200 x1[-1.21783823 -1.21437504 -1.21498523 -1.21672527 -1.21547164] x2[-1.20991955 -1.21819356 -1.21625137 -1.21260714 -1.21691301] loss [0.35365454 0.35314856 0.35328635 0.35348632 0.35316681] losses 0.35334851462291017\n",
      "iteration 4210 x1[-1.21847037 -1.21411123 -1.21629087 -1.21904714 -1.21753772] x2[-1.20963038 -1.21655392 -1.21629388 -1.21235775 -1.21637668] loss [0.35361968 0.35334628 0.35314584 0.35327189 0.35300778] losses 0.35327829329457117\n",
      "iteration 4220 x1[-1.21808041 -1.21456784 -1.2169506  -1.2180001  -1.2175767 ] x2[-1.20977543 -1.21845543 -1.21737157 -1.21111897 -1.21609335] loss [0.3536447  0.35310132 0.35296539 0.35351081 0.35303321] losses 0.3532510869343044\n",
      "iteration 4230 x1[-1.21876501 -1.21553746 -1.21618103 -1.21966348 -1.21793212] x2[-1.21032113 -1.22033221 -1.21800243 -1.21174761 -1.21703701] loss [0.35351597 0.35280675 0.35298001 0.35327252 0.35289838] losses 0.353094727494235\n",
      "iteration 4240 x1[-1.22004533 -1.21754547 -1.21627163 -1.21880247 -1.21726044] x2[-1.21110897 -1.22146236 -1.21880457 -1.21118333 -1.21745358] loss [0.35330052 0.35248253 0.35288769 0.35342094 0.35292476] losses 0.35300329017085585\n",
      "iteration 4250 x1[-1.22110894 -1.21714978 -1.21721396 -1.22089018 -1.21859883] x2[-1.21209024 -1.22268789 -1.22060111 -1.21228243 -1.21896977] loss [0.35308776 0.35239832 0.35260507 0.35309001 0.35262967] losses 0.3527621651023859\n",
      "iteration 4260 x1[-1.22132928 -1.21823154 -1.21694284 -1.22205835 -1.21929355] x2[-1.21104381 -1.22204176 -1.22152208 -1.21136207 -1.21903313] loss [0.35317541 0.35235245 0.3525388  0.35306714 0.35255154] losses 0.3527370673649727\n",
      "iteration 4270 x1[-1.22190374 -1.21688028 -1.21685013 -1.22273496 -1.2191273 ] x2[-1.21241375 -1.22278431 -1.22098944 -1.2116717  -1.21849007] loss [0.35297229 0.3524164  0.35260294 0.35296535 0.35262466] losses 0.3527163278160538\n",
      "iteration 4280 x1[-1.22093733 -1.21627449 -1.21620489 -1.22281969 -1.21908256] x2[-1.21423969 -1.22270331 -1.22030786 -1.21408653 -1.21915526] loss [0.35287999 0.35248746 0.35273984 0.35270343 0.35256069] losses 0.3526742831506227\n",
      "iteration 4290 x1[-1.22154792 -1.21644693 -1.21540947 -1.22368326 -1.21905515] x2[-1.21370296 -1.22347209 -1.22039112 -1.21262812 -1.21855444] loss [0.35287353 0.3523913  0.35281403 0.35276815 0.35262545] losses 0.3526944904490277\n",
      "iteration 4300 x1[-1.22155689 -1.21816029 -1.21502855 -1.22355277 -1.21864229] x2[-1.21395391 -1.22498273 -1.22046002 -1.21160293 -1.21796263] loss [0.35284636 0.35206095 0.35284664 0.35288918 0.35272915] losses 0.35267445697727257\n",
      "iteration 4310 x1[-1.22045701 -1.21840065 -1.21484461 -1.2232317  -1.21889273] x2[-1.21401557 -1.22493698 -1.22032289 -1.21232353 -1.21851954] loss [0.35295274 0.35204081 0.35287992 0.35284612 0.35264579] losses 0.3526730781742632\n",
      "iteration 4320 x1[-1.22054647 -1.21931626 -1.21429834 -1.2225445  -1.21809552] x2[-1.21540251 -1.22642869 -1.22037027 -1.21320932 -1.21867303] loss [0.3527988  0.35179618 0.35293209 0.3528233  0.35271224] losses 0.3526125221531948\n",
      "iteration 4330 x1[-1.22177227 -1.21975143 -1.215278   -1.22380645 -1.21895124] x2[-1.21485614 -1.22646044 -1.22082001 -1.21291975 -1.21911566] loss [0.3527301  0.35174835 0.35278369 0.35272503 0.3525783 ] losses 0.3525130920776855\n",
      "iteration 4340 x1[-1.22182087 -1.22015505 -1.21621276 -1.22257597 -1.21864606] x2[-1.2156843  -1.22787031 -1.22032949 -1.21283256 -1.21860385] loss [0.35263888 0.35156551 0.3527368  0.35285959 0.35266253] losses 0.35249266232833454\n",
      "iteration 4350 x1[-1.22209988 -1.21974582 -1.21671612 -1.22290817 -1.21881242] x2[-1.21648624 -1.2285223  -1.22022976 -1.21277291 -1.21839525] loss [0.35252707 0.35154218 0.35269479 0.35283194 0.3526669 ] losses 0.3524525762345495\n",
      "iteration 4360 x1[-1.22276954 -1.22172189 -1.21737017 -1.22230793 -1.21887929] x2[-1.21725539 -1.22765725 -1.22034142 -1.21366758 -1.218598  ] loss [0.35237907 0.35142693 0.35261554 0.35279949 0.35263908] losses 0.35237202342163815\n",
      "iteration 4370 x1[-1.22417616 -1.2220956  -1.21802669 -1.22308403 -1.21935517] x2[-1.2174752  -1.2269528  -1.22102471 -1.21529848 -1.21983185] loss [0.35221335 0.35145951 0.35247759 0.3525501  0.35246302] losses 0.3522327169885394\n",
      "iteration 4380 x1[-1.22514945 -1.22321366 -1.21868776 -1.22403754 -1.22021514] x2[-1.21789771 -1.22562331 -1.22190255 -1.21520328 -1.22020815] loss [0.35207117 0.35147962 0.35231963 0.35246302 0.35233603] losses 0.35213389421699415\n",
      "iteration 4390 x1[-1.22593585 -1.22495073 -1.21914918 -1.22384983 -1.22001961] x2[-1.2186836  -1.2260009  -1.22334666 -1.21453524 -1.22049054] loss [0.35191082 0.35126597 0.35212502 0.3525517  0.35232713] losses 0.3520361290783406\n",
      "iteration 4400 x1[-1.22539393 -1.22512733 -1.21943143 -1.22462959 -1.22098917] x2[-1.2202193  -1.22716224 -1.22473169 -1.21543978 -1.22153745] loss [0.35180788 0.35113164 0.35195558 0.35237835 0.35212065] losses 0.3518788193019916\n",
      "iteration 4410 x1[-1.22490638 -1.22550958 -1.22088071 -1.22480765 -1.22212235] x2[-1.21962543 -1.22638076 -1.22436746 -1.2149954  -1.2210369 ] loss [0.351918   0.35117152 0.35184397 0.35240654 0.35205608] losses 0.35187922032265095\n",
      "iteration 4420 x1[-1.22613106 -1.22806179 -1.22170218 -1.22403454 -1.22179821] x2[-1.21946444 -1.22690707 -1.22671236 -1.21513873 -1.22238413] loss [0.35181093 0.350863   0.3515237  0.35247005 0.35195165] losses 0.3517238653825256\n",
      "iteration 4430 x1[-1.22620894 -1.22891857 -1.22214989 -1.22461702 -1.22235707] x2[-1.22010807 -1.22796349 -1.22726372 -1.21451332 -1.22206897] loss [0.35173712 0.35067208 0.35142281 0.35247609 0.3519268 ] losses 0.35164698032086106\n",
      "iteration 4440 x1[-1.22650619 -1.23051379 -1.22260409 -1.22575744 -1.22328741] x2[-1.22034813 -1.22584588 -1.2274231  -1.21601287 -1.2226371 ] loss [0.35168264 0.3507256  0.35136069 0.35220472 0.35177438] losses 0.3515496063797381\n",
      "iteration 4450 x1[-1.22714434 -1.23059256 -1.22341489 -1.22552708 -1.22334261] x2[-1.2196435  -1.22536691 -1.22721397 -1.21521128 -1.22246191] loss [0.35169068 0.3507659  0.35129942 0.35231127 0.3517866 ] losses 0.3515707730155398\n",
      "iteration 4460 x1[-1.22795713 -1.23078398 -1.2245721  -1.22586924 -1.22405598] x2[-1.22108289 -1.22496747 -1.22779795 -1.21598807 -1.22259107] loss [0.35146203 0.35078712 0.351124   0.35219601 0.35170114] losses 0.35145406012049996\n",
      "iteration 4470 x1[-1.22781558 -1.22932909 -1.22569007 -1.22679962 -1.22485339] x2[-1.22133699 -1.22614143 -1.22819704 -1.21675397 -1.22350969] loss [0.35145029 0.3508135  0.35097157 0.3520229  0.35152726] losses 0.35135710365931333\n",
      "iteration 4480 x1[-1.22865591 -1.22940945 -1.22567001 -1.22717087 -1.22500676] x2[-1.22138617 -1.22724903 -1.22878335 -1.21632189 -1.22361363] loss [0.35136128 0.35069462 0.35091513 0.3520303  0.35150125] losses 0.3513005134057211\n",
      "iteration 4490 x1[-1.22832347 -1.22875713 -1.22547839 -1.22732215 -1.22553396] x2[-1.22258757 -1.22762418 -1.22973086 -1.21728572 -1.224417  ] loss [0.3512723  0.350722   0.35084015 0.35191541 0.35136683] losses 0.3512233389656223\n",
      "iteration 4500 x1[-1.22880523 -1.22935032 -1.22435394 -1.22884947 -1.22557804] x2[-1.2250629  -1.22783504 -1.22931061 -1.21784173 -1.22386685] loss [0.35097402 0.35064198 0.35099515 0.35170508 0.35141801] losses 0.35114684666080426\n",
      "iteration 4510 x1[-1.22986789 -1.2309874  -1.22460167 -1.22864164 -1.22534644] x2[-1.22517475 -1.22804182 -1.22947421 -1.21898674 -1.22448593] loss [0.35085708 0.35045919 0.3509539  0.35160809 0.35137875] losses 0.35105140232395027\n",
      "iteration 4520 x1[-1.2295621  -1.23198441 -1.22598197 -1.22882514 -1.22646453] x2[-1.22607136 -1.22761918 -1.2298594  -1.21876556 -1.22425161] loss [0.35079737 0.35040297 0.35077682 0.35161247 0.35128995] losses 0.3509759184363733\n",
      "iteration 4530 x1[-1.23179563 -1.23213458 -1.22638883 -1.22998495 -1.22689307] x2[-1.22732693 -1.22824741 -1.23178105 -1.21971821 -1.22567252] loss [0.35045073 0.35032561 0.35054594 0.35139918 0.35110374] losses 0.35076503964888267\n",
      "iteration 4540 x1[-1.23300359 -1.23171533 -1.22813143 -1.23076013 -1.22790686] x2[-1.22764841 -1.22973648 -1.23039384 -1.21973629 -1.22467148] loss [0.35029985 0.35021907 0.35050896 0.35132032 0.35110309] losses 0.3506902575362366\n",
      "iteration 4550 x1[-1.23359162 -1.23256785 -1.22847505 -1.23169647 -1.22841327] x2[-1.2273796  -1.22908216 -1.23022671 -1.22034855 -1.22469851] loss [0.35026898 0.35020007 0.3504913  0.351165   0.3510498 ] losses 0.3506350288957584\n",
      "iteration 4560 x1[-1.23453593 -1.23424933 -1.22920095 -1.23261804 -1.22921015] x2[-1.22716119 -1.22943096 -1.23085112 -1.22114859 -1.22570002] loss [0.35019838 0.35000079 0.3503574  0.35099246 0.35086964] losses 0.3504837318200499\n",
      "iteration 4570 x1[-1.23469587 -1.2349305  -1.22876252 -1.23370165 -1.22979041] x2[-1.22717196 -1.22961111 -1.23014091 -1.22137253 -1.22572753] loss [0.35018169 0.3499165  0.3504712  0.35086307 0.35080921] losses 0.3504483322025075\n",
      "iteration 4580 x1[-1.23446919 -1.23405408 -1.2283492  -1.23416783 -1.22996365] x2[-1.22774788 -1.23055665 -1.22965127 -1.22199757 -1.22577154] loss [0.35014643 0.34990859 0.35056086 0.35075385 0.3507876 ] losses 0.35043146519428475\n",
      "iteration 4590 x1[-1.23561773 -1.234385   -1.229664   -1.23447044 -1.23090447] x2[-1.22829804 -1.23223523 -1.22938254 -1.22259981 -1.22582246] loss [0.34997976 0.34971114 0.35045687 0.35066318 0.35068928] losses 0.3503000441470996\n",
      "iteration 4600 x1[-1.2353716  -1.23359694 -1.22920761 -1.23494789 -1.23103929] x2[-1.22883996 -1.23299077 -1.22839823 -1.22262655 -1.22522946] loss [0.34994992 0.34971402 0.35060002 0.35061376 0.35073551] losses 0.35032264624941883\n",
      "iteration 4610 x1[-1.23764311 -1.23533659 -1.22971581 -1.2366049  -1.23175891] x2[-1.22937525 -1.2337291  -1.22744642 -1.22322656 -1.22503439] loss [0.34967666 0.34947235 0.35064448 0.35039161 0.35068403] losses 0.3501738273035748\n",
      "iteration 4620 x1[-1.23813608 -1.23501833 -1.2318971  -1.23632368 -1.23254733] x2[-1.23070315 -1.23446282 -1.226937   -1.22520482 -1.22527172] loss [0.34949808 0.34943176 0.35047967 0.35021988 0.35058249] losses 0.3500423761699582\n",
      "iteration 4630 x1[-1.23826337 -1.23523065 -1.23232086 -1.23685486 -1.23325265] x2[-1.23197752 -1.2356458  -1.22877758 -1.22616194 -1.22657896] loss [0.34936064 0.3492962  0.35025458 0.35007246 0.35038217] losses 0.34987320832225277\n",
      "iteration 4640 x1[-1.23859388 -1.23515749 -1.23143375 -1.23661764 -1.23234237] x2[-1.2326575  -1.23526219 -1.23016275 -1.22673361 -1.22784686] loss [0.34926227 0.34934052 0.35020462 0.35003837 0.35034505] losses 0.3498381653064827\n",
      "iteration 4650 x1[-1.23835521 -1.23452938 -1.23154605 -1.23661477 -1.23244034] x2[-1.23273248 -1.2354462  -1.23055243 -1.22687673 -1.22847857] loss [0.34927789 0.34938372 0.35015503 0.35002437 0.35027255] losses 0.34982271284269384\n",
      "iteration 4660 x1[-1.23850783 -1.2356541  -1.23281801 -1.23716452 -1.23349511] x2[-1.2332073  -1.23574524 -1.23172372 -1.22684381 -1.229017  ] loss [0.34921683 0.34924548 0.34991459 0.34997436 0.35011558] losses 0.34969336821858865\n",
      "iteration 4670 x1[-1.23909287 -1.23684769 -1.23486476 -1.23754027 -1.23446457] x2[-1.23483696 -1.23616799 -1.23344351 -1.22874737 -1.23061381] loss [0.34900205 0.34908908 0.34954611 0.34974875 0.34986287] losses 0.34944977390728205\n",
      "iteration 4680 x1[-1.23912389 -1.23697197 -1.23494664 -1.2375376  -1.23455535] x2[-1.23544849 -1.23611902 -1.23264017 -1.22906153 -1.22998006] loss [0.34893979 0.34908182 0.34961673 0.34971789 0.34991659] losses 0.34945456502037836\n",
      "iteration 4690 x1[-1.23875386 -1.2377666  -1.23446101 -1.23772698 -1.23474707] x2[-1.23547286 -1.23615994 -1.23244281 -1.23013864 -1.23042498] loss [0.34897291 0.34900129 0.34968337 0.34959316 0.34985396] losses 0.3494209366878944\n",
      "iteration 4700 x1[-1.23937497 -1.23766029 -1.23340547 -1.23872435 -1.2346568 ] x2[-1.23491301 -1.23718914 -1.23300527 -1.22924787 -1.23065365] loss [0.34896764 0.34891218 0.34973132 0.34958501 0.3498402 ] losses 0.34940726926473004\n",
      "iteration 4710 x1[-1.24015356 -1.23805587 -1.23508933 -1.23853757 -1.23525242] x2[-1.23536123 -1.23741942 -1.23355701 -1.22974636 -1.23126271] loss [0.34884973 0.34885196 0.34951318 0.34955373 0.34972221] losses 0.34929816332917063\n",
      "iteration 4720 x1[-1.2392061  -1.23748389 -1.23537411 -1.23952302 -1.23679341] x2[-1.23676563 -1.23677591 -1.23355644 -1.23100807 -1.23158915] loss [0.34880463 0.34896901 0.34948556 0.34933475 0.34954061] losses 0.3492269134652341\n",
      "iteration 4730 x1[-1.23847829 -1.23808469 -1.23415663 -1.24025565 -1.23674219] x2[-1.23636965 -1.23692541 -1.2337589  -1.23111302 -1.23193557] loss [0.34891262 0.34889679 0.34958429 0.34925427 0.34951157] losses 0.349231905605986\n",
      "iteration 4740 x1[-1.23949285 -1.23922196 -1.23586893 -1.24059292 -1.23767758] x2[-1.2365755  -1.23691289 -1.23280886 -1.2321759  -1.23208677] loss [0.34879552 0.34878891 0.34951061 0.34911784 0.34940638] losses 0.3491238511010851\n",
      "iteration 4750 x1[-1.24068789 -1.23926291 -1.23597665 -1.24191512 -1.23810506] x2[-1.23794057 -1.23614357 -1.23173169 -1.23283537 -1.23148161] loss [0.34855012 0.34885923 0.34960575 0.34892742 0.34942454] losses 0.34907341224570665\n",
      "iteration 4760 x1[-1.23973017 -1.24162956 -1.2358869  -1.24069241 -1.23812953] x2[-1.2369545  -1.23656376 -1.23319943 -1.23252093 -1.23244806] loss [0.34873629 0.34859299 0.34947067 0.3490746  0.34932744] losses 0.3490403975959918\n",
      "iteration 4770 x1[-1.24077738 -1.24431758 -1.23793117 -1.24126229 -1.23969544] x2[-1.2383404  -1.23762303 -1.23367143 -1.23374951 -1.23281404] loss [0.34850326 0.34823711 0.34922704 0.34890045 0.34914128] losses 0.34880182785893077\n",
      "iteration 4780 x1[-1.24066565 -1.24463281 -1.2399046  -1.24145204 -1.2412187 ] x2[-1.23951125 -1.23772242 -1.23303534 -1.23496038 -1.23264412] loss [0.3484019  0.34819794 0.34909965 0.34876481 0.34901237] losses 0.3486953342430602\n",
      "iteration 4790 x1[-1.24172796 -1.24379531 -1.23989805 -1.24285311 -1.24156908] x2[-1.24083894 -1.23858669 -1.23245905 -1.23729002 -1.23327957] loss [0.34817462 0.34819398 0.34915658 0.34840717 0.34891701] losses 0.348569870171346\n",
      "iteration 4800 x1[-1.24316454 -1.2444482  -1.23935119 -1.24482135 -1.24204214] x2[-1.23962009 -1.23914094 -1.23422287 -1.23646666 -1.23456921] loss [0.34815478 0.34807963 0.34903695 0.34830086 0.34874667] losses 0.34846377720544025\n",
      "iteration 4810 x1[-1.24265414 -1.24443816 -1.23943465 -1.24551904 -1.24276403] x2[-1.24075273 -1.24093019 -1.23508708 -1.23724886 -1.23521146] loss [0.3480952  0.34791039 0.34894504 0.34816022 0.34861601] losses 0.3483453728827747\n",
      "iteration 4820 x1[-1.24216359 -1.24471245 -1.24112685 -1.24455411 -1.24318361] x2[-1.24089047 -1.24101375 -1.2348654  -1.23705103 -1.23493957] loss [0.34812848 0.34787674 0.34880496 0.34826977 0.34860264] losses 0.34833651835281165\n",
      "iteration 4830 x1[-1.24224582 -1.24489857 -1.24220767 -1.24396958 -1.24330592] x2[-1.24194308 -1.24191992 -1.23504664 -1.23829861 -1.23568167] loss [0.34802095 0.34777354 0.34868469 0.34820513 0.34851931] losses 0.3482407233763401\n",
      "iteration 4840 x1[-1.24163051 -1.24572953 -1.24256271 -1.24434171 -1.24426551] x2[-1.24187708 -1.24208461 -1.23558729 -1.23968361 -1.23676917] loss [0.34808541 0.34768028 0.34859873 0.34803791 0.34832401] losses 0.3481452687192676\n",
      "iteration 4850 x1[-1.24086115 -1.24482725 -1.24168512 -1.24507196 -1.244408  ] x2[-1.24216875 -1.24071199 -1.23540842 -1.24082825 -1.23719197] loss [0.34813078 0.34789459 0.34869928 0.34786064 0.34826997] losses 0.3481710505509312\n",
      "iteration 4860 x1[-1.24063544 -1.24283898 -1.24263806 -1.24558699 -1.24526707] x2[-1.2417194  -1.24092079 -1.23578044 -1.24069192 -1.23753168] loss [0.34819476 0.34806179 0.34857293 0.34782537 0.34815671] losses 0.3481623123346459\n",
      "iteration 4870 x1[-1.24096421 -1.24228481 -1.24337372 -1.24537167 -1.24511364] x2[-1.24218203 -1.2410767  -1.23634501 -1.24019908 -1.23715299] loss [0.34811974 0.34809934 0.34844891 0.3478923  0.34820743] losses 0.3481535442424782\n",
      "iteration 4880 x1[-1.2416676  -1.24230194 -1.24283388 -1.24571132 -1.24479075] x2[-1.24371055 -1.24257318 -1.23615086 -1.24118221 -1.23724129] loss [0.34790891 0.3479561  0.34851865 0.34776729 0.34822926] losses 0.3480760416170622\n",
      "iteration 4890 x1[-1.24292091 -1.24416716 -1.24428245 -1.24663233 -1.24593296] x2[-1.24466517 -1.24547486 -1.23580287 -1.24251667 -1.2380671 ] loss [0.34770099 0.34750818 0.34841551 0.34755537 0.34804307] losses 0.3478446253897419\n",
      "iteration 4900 x1[-1.24235255 -1.24368058 -1.2448054  -1.24735216 -1.24687234] x2[-1.24454547 -1.24706208 -1.23676557 -1.2423924  -1.23871115] loss [0.34776578 0.347406   0.3482736  0.34750017 0.34789384] losses 0.3477678781083299\n",
      "iteration 4910 x1[-1.24218917 -1.24541824 -1.24551948 -1.24697837 -1.24708849] x2[-1.24549959 -1.24715332 -1.23735495 -1.24352693 -1.23970773] loss [0.34769189 0.34723503 0.34815    0.3474282  0.34777878] losses 0.3476567796359918\n",
      "iteration 4920 x1[-1.24295161 -1.24554259 -1.24549518 -1.2484281  -1.24774812] x2[-1.24463939 -1.24683855 -1.23596961 -1.24336024 -1.23896616] loss [0.34770051 0.34725265 0.34828549 0.34730948 0.34778805] losses 0.3476672375304796\n",
      "iteration 4930 x1[-1.24277275 -1.24423218 -1.24546055 -1.24893324 -1.24802475] x2[-1.24507412 -1.24759775 -1.23625894 -1.24357159 -1.23933888] loss [0.34767666 0.34730462 0.34826087 0.347243   0.34772688] losses 0.34764240406125624\n",
      "iteration 4940 x1[-1.2424377  -1.24460686 -1.24652351 -1.2479776  -1.2481141 ] x2[-1.24693859 -1.24923756 -1.23744564 -1.24397539 -1.2398928 ] loss [0.34753432 0.34711807 0.34804741 0.34729348 0.34766592] losses 0.3475318418994166\n",
      "iteration 4950 x1[-1.24180662 -1.24474132 -1.24631633 -1.24925659 -1.24886511] x2[-1.24782928 -1.2496445  -1.2366147  -1.24598268 -1.24016377] loss [0.34751113 0.34706805 0.34814653 0.34698813 0.34757066] losses 0.34745690196399465\n",
      "iteration 4960 x1[-1.24208478 -1.24513826 -1.24737228 -1.24923752 -1.24932656] x2[-1.24834187 -1.25005437 -1.23564604 -1.24596589 -1.23936571] loss [0.34743741 0.34699336 0.34814126 0.34699144 0.34760382] losses 0.34743345924827446\n",
      "iteration 4970 x1[-1.24201133 -1.24591157 -1.24622122 -1.24886342 -1.24868301] x2[-1.24919982 -1.25089721 -1.2370521  -1.24596522 -1.23995169] loss [0.34736506 0.34684414 0.3481134  0.34702597 0.34760763] losses 0.34739124130671933\n",
      "iteration 4980 x1[-1.24211158 -1.24555621 -1.24728975 -1.24995983 -1.2498844 ] x2[-1.24842195 -1.25075705 -1.23715913 -1.24686622 -1.24079902] loss [0.34742748 0.34689001 0.34800345 0.3468415  0.34741642] losses 0.3473157722112298\n",
      "iteration 4990 x1[-1.2442016  -1.24658746 -1.24780065 -1.25155527 -1.25042601] x2[-1.2484062  -1.25007411 -1.23801775 -1.24704462 -1.24147356] loss [0.34723266 0.34685685 0.3478737  0.34667898 0.34730286] losses 0.3471890119731274\n",
      "iteration 5000 x1[-1.24569274 -1.24787315 -1.24994524 -1.25274685 -1.25178498] x2[-1.24824854 -1.25142709 -1.23798326 -1.24743877 -1.24197565] loss [0.34710806 0.34661415 0.34767848 0.34653406 0.34713097] losses 0.34701314690254803\n",
      "iteration 5010 x1[-1.24606892 -1.24795348 -1.24968202 -1.25248851 -1.25105582] x2[-1.24829863 -1.25079007 -1.23886553 -1.24817812 -1.24300988] loss [0.34706844 0.34666494 0.34761861 0.34648938 0.34710052] losses 0.3469883777755481\n",
      "iteration 5020 x1[-1.2466076  -1.24821075 -1.24980284 -1.25243524 -1.25127061] x2[-1.2478147  -1.25152446 -1.23953561 -1.24689708 -1.24264445] loss [0.34706312 0.34657415 0.34754372 0.34661244 0.34711515] losses 0.34698171912707565\n",
      "iteration 5030 x1[-1.24585353 -1.24900326 -1.2491911  -1.25162803 -1.25091151] x2[-1.24665405 -1.25143825 -1.23964723 -1.24582952 -1.24237449] loss [0.34724081 0.34650912 0.34758957 0.34678496 0.34717343] losses 0.34705957860811215\n",
      "iteration 5040 x1[-1.24656211 -1.24860015 -1.2500424  -1.25246384 -1.25173463] x2[-1.24733621 -1.25208092 -1.23974722 -1.24697785 -1.2428421 ] loss [0.34711164 0.34648762 0.34750155 0.34660237 0.34705414] losses 0.34695146396027643\n",
      "iteration 5050 x1[-1.24727508 -1.24913665 -1.25161814 -1.2529384  -1.25309731] x2[-1.24692634 -1.25289125 -1.2403978  -1.24646918 -1.24347782] loss [0.3470835  0.34636471 0.34729517 0.3466063  0.34687033] losses 0.3468440029520074\n",
      "iteration 5060 x1[-1.247407   -1.24857178 -1.25133145 -1.25447463 -1.25405008] x2[-1.24636008 -1.25188814 -1.2392687  -1.24634832 -1.24304151] loss [0.34712385 0.34650778 0.34742852 0.34647832 0.34682467] losses 0.34687262786399026\n",
      "iteration 5070 x1[-1.2480651  -1.24856517 -1.25014522 -1.25520456 -1.25367886] x2[-1.2459936  -1.25178314 -1.23927743 -1.24517426 -1.24245522] loss [0.34709702 0.34651795 0.34753671 0.34652132 0.34691332] losses 0.34691726601896467\n",
      "iteration 5080 x1[-1.25014002 -1.25037936 -1.25118443 -1.25662974 -1.25441686] x2[-1.24673329 -1.25178882 -1.23981264 -1.24588283 -1.24289273] loss [0.34683729 0.34635109 0.34739037 0.34632743 0.34680538] losses 0.3467423096784046\n",
      "iteration 5090 x1[-1.25071244 -1.25105701 -1.25020306 -1.25623114 -1.25333991] x2[-1.24675729 -1.25226734 -1.23907162 -1.2462272  -1.24251141] loss [0.34678261 0.34624573 0.34755096 0.34633132 0.34693884] losses 0.3467698943160206\n",
      "iteration 5100 x1[-1.2512567  -1.25069045 -1.25162091 -1.2574948  -1.25476583] x2[-1.24697844 -1.25176248 -1.24049604 -1.24712267 -1.24385724] loss [0.34671236 0.34632507 0.34728562 0.34613546 0.3466836 ] losses 0.3466284205998137\n",
      "iteration 5110 x1[-1.25322316 -1.24998123 -1.25100912 -1.25871043 -1.25433781] x2[-1.24613821 -1.25109257 -1.24137603 -1.24657111 -1.24393133] loss [0.34661111 0.34645096 0.34725853 0.34607794 0.34671539] losses 0.3466227887370688\n",
      "iteration 5120 x1[-1.25439028 -1.2517406  -1.25170252 -1.2588186  -1.25476697] x2[-1.24589999 -1.25025061 -1.24112584 -1.24750039 -1.24417627] loss [0.34652748 0.34636725 0.34721862 0.34598271 0.34665372] losses 0.34654995796562427\n",
      "iteration 5130 x1[-1.25443193 -1.25132206 -1.25291635 -1.25802086 -1.25508623] x2[-1.24496217 -1.25029975 -1.24126694 -1.24657952 -1.24396874] loss [0.34661081 0.34640088 0.34709448 0.3461386  0.34664425] losses 0.3465778042412929\n",
      "iteration 5140 x1[-1.25466411 -1.25238477 -1.25426133 -1.25886898 -1.25647149] x2[-1.24550622 -1.25016416 -1.24051507 -1.24622538 -1.24287519] loss [0.34653927 0.34631658 0.34704318 0.34609576 0.34662167] losses 0.3465232911110876\n",
      "iteration 5150 x1[-1.255272   -1.25262539 -1.25503103 -1.25843737 -1.25646781] x2[-1.24584718 -1.25048659 -1.24213769 -1.24607047 -1.24354805] loss [0.34645279 0.34626527 0.34682064 0.3461485  0.34655909] losses 0.3464492592825969\n",
      "iteration 5160 x1[-1.25585434 -1.25346083 -1.25486951 -1.25873613 -1.25690909] x2[-1.24620202 -1.24993708 -1.24246112 -1.24540438 -1.24331576] loss [0.34636751 0.34623978 0.34680489 0.34618354 0.34654117] losses 0.34642737852601\n",
      "iteration 5170 x1[-1.25714937 -1.25372525 -1.2559893  -1.26030615 -1.25824564] x2[-1.24639356 -1.24850099 -1.24223653 -1.24622867 -1.24327997] loss [0.34623363 0.34634752 0.3467249  0.34596797 0.34642488] losses 0.3463397818879749\n",
      "iteration 5180 x1[-1.25714838 -1.25460412 -1.25690708 -1.26058655 -1.2589214 ] x2[-1.24585414 -1.24958723 -1.24332242 -1.24593828 -1.24408594] loss [0.34628362 0.34616853 0.34654073 0.34596999 0.34628949] losses 0.34625047152831223\n",
      "iteration 5190 x1[-1.25788088 -1.25322125 -1.25710112 -1.26047076 -1.25859645] x2[-1.24608893 -1.25063978 -1.24418966 -1.24658782 -1.24523264] loss [0.34619642 0.34619728 0.34644243 0.34592028 0.3462119 ] losses 0.34619366086973835\n",
      "iteration 5200 x1[-1.25858279 -1.25426194 -1.25838284 -1.26111418 -1.25957593] x2[-1.24560644 -1.25156904 -1.24470572 -1.24685151 -1.24608826] loss [0.34617848 0.34601864 0.34627984 0.34583917 0.34604563] losses 0.34607235446701407\n",
      "iteration 5210 x1[-1.25854279 -1.25450662 -1.25908175 -1.26135691 -1.26024268] x2[-1.24590522 -1.2531152  -1.24470053 -1.24694776 -1.24630241] loss [0.34615439 0.34585648 0.34621808 0.34580892 0.34596678] losses 0.34600092889143985\n",
      "iteration 5220 x1[-1.25869042 -1.25378124 -1.25833796 -1.26142126 -1.25973811] x2[-1.2456456  -1.2538695  -1.2450413  -1.24704235 -1.24649709] loss [0.34616527 0.34585374 0.34625269 0.34579455 0.3459935 ] losses 0.34601195017005326\n",
      "iteration 5230 x1[-1.25885207 -1.25307176 -1.25761083 -1.26204171 -1.25960501] x2[-1.24574354 -1.25304286 -1.24464053 -1.24804058 -1.24677967] loss [0.34614182 0.34599248 0.34635484 0.34564833 0.34597925] losses 0.3460233450566517\n",
      "iteration 5240 x1[-1.25790308 -1.25310134 -1.25709532 -1.26191594 -1.25948609] x2[-1.2461998  -1.25323725 -1.24570739 -1.24791669 -1.24714445] loss [0.34618418 0.34597223 0.34630196 0.34567074 0.3459562 ] losses 0.34601706108196095\n",
      "iteration 5250 x1[-1.25845674 -1.25459203 -1.25663635 -1.26197488 -1.25902987] x2[-1.24590889 -1.25489672 -1.2467168  -1.24816345 -1.24821738] loss [0.34616172 0.34568832 0.34624972 0.34564295 0.34589809] losses 0.3459281579754371\n",
      "iteration 5260 x1[-1.25827825 -1.25540209 -1.25619389 -1.26186842 -1.25923127] x2[-1.24619402 -1.25500505 -1.24733516 -1.24913069 -1.24898641] loss [0.34615126 0.3456059  0.34623236 0.34556386 0.34580978] losses 0.34587263085487585\n",
      "iteration 5270 x1[-1.25881275 -1.25457628 -1.25526037 -1.26394807 -1.25963675] x2[-1.24665724 -1.25509587 -1.24776727 -1.25007907 -1.24974413] loss [0.34606089 0.34567186 0.34627646 0.34529559 0.34570465] losses 0.3458018908859962\n",
      "iteration 5280 x1[-1.25810952 -1.25562057 -1.25656431 -1.26325732 -1.260047  ] x2[-1.24855136 -1.25746022 -1.24892143 -1.25174489 -1.25077278] loss [0.34594931 0.34536708 0.34605339 0.34520486 0.34557475] losses 0.3456298775728483\n",
      "iteration 5290 x1[-1.25853651 -1.25740245 -1.25747756 -1.26241802 -1.260097  ] x2[-1.24914791 -1.25742628 -1.24859258 -1.25153994 -1.25049644] loss [0.34585669 0.3452113  0.34600188 0.34529673 0.34559545] losses 0.3455924113170355\n",
      "iteration 5300 x1[-1.25898951 -1.25611389 -1.25816663 -1.26400663 -1.26097019] x2[-1.24953337 -1.25685273 -1.24938464 -1.25133305 -1.25078049] loss [0.34578124 0.34537707 0.34586795 0.34517681 0.34549264] losses 0.3455391430780742\n",
      "iteration 5310 x1[-1.2587068  -1.2549777  -1.25903412 -1.26428208 -1.26174403] x2[-1.25082977 -1.25901242 -1.24943616 -1.25206449 -1.25089233] loss [0.34568823 0.34528696 0.34578616 0.34508679 0.34541447] losses 0.34545252295598095\n",
      "iteration 5320 x1[-1.26026311 -1.25652695 -1.25877942 -1.26511185 -1.26131678] x2[-1.25100386 -1.2590375  -1.25005588 -1.25298277 -1.25167179] loss [0.34553469 0.34514643 0.34575222 0.34493215 0.34538138] losses 0.34534937337913224\n",
      "iteration 5330 x1[-1.25905578 -1.25759607 -1.25947141 -1.26374186 -1.26174357] x2[-1.25045634 -1.25833654 -1.25066386 -1.25349228 -1.25241601] loss [0.34569123 0.3451134  0.34563554 0.34500529 0.34527667] losses 0.3453444274820128\n",
      "iteration 5340 x1[-1.25861899 -1.25617011 -1.25886582 -1.26404757 -1.26169737] x2[-1.2502686  -1.25847733 -1.25161995 -1.25289014 -1.25269383] loss [0.34574709 0.34522777 0.34560241 0.3450328  0.34525567] losses 0.3453731479660838\n",
      "iteration 5350 x1[-1.2589148  -1.2548043  -1.2581278  -1.26413392 -1.26129346] x2[-1.25045894 -1.25931001 -1.25235388 -1.25285734 -1.25331408] loss [0.3457035  0.34527619 0.34560147 0.34502825 0.34523527] losses 0.34536893464307805\n",
      "iteration 5360 x1[-1.25994491 -1.25720705 -1.2581328  -1.26425827 -1.26118748] x2[-1.25155983 -1.26023349 -1.25324187 -1.25265236 -1.25382386] loss [0.34551237 0.34498057 0.34552086 0.34503589 0.34519876] losses 0.3452496879920638\n",
      "iteration 5370 x1[-1.26024385 -1.25821279 -1.2585315  -1.26294848 -1.26065724] x2[-1.25282925 -1.26097235 -1.25336875 -1.25389943 -1.25447693] loss [0.34537126 0.34482665 0.34547404 0.34503787 0.34518677] losses 0.34517931750679376\n",
      "iteration 5380 x1[-1.26165955 -1.25790591 -1.25965542 -1.26407512 -1.26178758] x2[-1.25372662 -1.26034578 -1.25405486 -1.25567517 -1.25575648] loss [0.34516607 0.34490877 0.34531289 0.34478119 0.34497327] losses 0.34502843787930926\n",
      "iteration 5390 x1[-1.26207737 -1.25805631 -1.2596762  -1.26476379 -1.26206933] x2[-1.25471931 -1.25993776 -1.25553081 -1.25577255 -1.25641732] loss [0.34504052 0.34493133 0.34517888 0.34471285 0.34488981] losses 0.34495067686521136\n",
      "iteration 5400 x1[-1.26165251 -1.25750562 -1.25988034 -1.26409582 -1.26168173] x2[-1.25498748 -1.25988158 -1.25526307 -1.25603847 -1.25638091] loss [0.34505373 0.34498505 0.3451848  0.34474707 0.34492693] losses 0.3449795169327123\n",
      "iteration 5410 x1[-1.26141298 -1.25756306 -1.25956703 -1.26498123 -1.26207269] x2[-1.25592704 -1.2606984  -1.2560317  -1.25611688 -1.2565163 ] loss [0.34499087 0.34490817 0.34514381 0.34466343 0.34488072] losses 0.34491739730450055\n",
      "iteration 5420 x1[-1.26003261 -1.25807286 -1.2615226  -1.26381447 -1.26307645] x2[-1.25767467 -1.26105191 -1.25779648 -1.25756188 -1.25810193] loss [0.34495677 0.34483205 0.34481529 0.34463639 0.34465277] losses 0.3447786523240743\n",
      "iteration 5430 x1[-1.25991809 -1.25767102 -1.26204592 -1.26319284 -1.26293311] x2[-1.25749586 -1.26104456 -1.25783723 -1.25589678 -1.25727838] loss [0.3449827  0.34486825 0.34476595 0.34483813 0.34473807] losses 0.3448386190040001\n",
      "iteration 5440 x1[-1.25928757 -1.2578603  -1.26223376 -1.26324626 -1.26322075] x2[-1.25802372 -1.26191735 -1.25888752 -1.25718261 -1.25868685] loss [0.34499148 0.34477514 0.34465686 0.34471931 0.34458863] losses 0.34474628254788875\n",
      "iteration 5450 x1[-1.25971223 -1.2592578  -1.26124388 -1.26365071 -1.26300691] x2[-1.25750414 -1.26140264 -1.26007992 -1.25604555 -1.25869583] loss [0.34500009 0.34469682 0.34463845 0.34478508 0.34460643] losses 0.3447453730752259\n",
      "iteration 5460 x1[-1.25996368 -1.25940482 -1.26114333 -1.26405212 -1.26330916] x2[-1.25904819 -1.26264447 -1.25918417 -1.25698564 -1.25836458] loss [0.34484144 0.34457556 0.34472599 0.34466679 0.34460936] losses 0.3446838280071069\n",
      "iteration 5470 x1[-1.25935602 -1.25886221 -1.26120889 -1.26412995 -1.26361656] x2[-1.25953864 -1.26207165 -1.25986182 -1.25755729 -1.25880725] loss [0.34485171 0.34467323 0.34466066 0.34460944 0.34454367] losses 0.3446677404936364\n",
      "iteration 5480 x1[-1.25947635 -1.25845749 -1.26163675 -1.26455212 -1.26418053] x2[-1.26015954 -1.26370326 -1.26137162 -1.2572652  -1.25942627] loss [0.34478652 0.34456696 0.34449106 0.34459872 0.34444038] losses 0.34457672961129837\n",
      "iteration 5490 x1[-1.25979205 -1.25893263 -1.26308997 -1.26445743 -1.26490849] x2[-1.26044317 -1.26385802 -1.26234953 -1.25801089 -1.26046888] loss [0.34473386 0.3445117  0.34427946 0.34454102 0.34428615] losses 0.344470436499187\n",
      "iteration 5500 x1[-1.26028556 -1.25942269 -1.26435646 -1.26486279 -1.26595899] x2[-1.26159389 -1.26452767 -1.26264031 -1.25842443 -1.26031088] loss [0.34458983 0.34441068 0.34414465 0.34446952 0.34420954] losses 0.3443648422113103\n",
      "iteration 5510 x1[-1.25959089 -1.25802739 -1.26285207 -1.26394236 -1.26478211] x2[-1.26269512 -1.26439598 -1.26222555 -1.25933282 -1.26024489] loss [0.34455481 0.34454488 0.34431088 0.34446921 0.34431664] losses 0.3444392835102046\n",
      "iteration 5520 x1[-1.25908531 -1.2591334  -1.26380216 -1.26372659 -1.26560309] x2[-1.26239616 -1.26393052 -1.26353391 -1.25969264 -1.26153701] loss [0.34462529 0.34448776 0.34411511 0.34445631 0.34413316] losses 0.3443635255490326\n",
      "iteration 5530 x1[-1.25963522 -1.2587513  -1.26438508 -1.26353993 -1.26547744] x2[-1.26277588 -1.26255555 -1.26345234 -1.26020139 -1.26169149] loss [0.34454389 0.34464082 0.34407184 0.34442789 0.34413052] losses 0.3443629902929666\n",
      "iteration 5540 x1[-1.26085459 -1.25999783 -1.26614852 -1.26490093 -1.26715099] x2[-1.26281095 -1.26319512 -1.26322554 -1.26036897 -1.2616069 ] loss [0.344434   0.34447564 0.34393986 0.34429553 0.34399442] losses 0.34422789148579247\n",
      "iteration 5550 x1[-1.26117879 -1.26002031 -1.2654701  -1.26622359 -1.26724429] x2[-1.26253857 -1.26400381 -1.26388529 -1.2597129  -1.26171959] loss [0.34442935 0.34440357 0.34394106 0.34423915 0.34397666] losses 0.3441979575265324\n",
      "iteration 5560 x1[-1.26166313 -1.26142458 -1.26448985 -1.26665223 -1.26700576] x2[-1.26331717 -1.26342065 -1.26416772 -1.25977179 -1.26181927] loss [0.3443195  0.34433132 0.34400102 0.34419722 0.34398838] losses 0.3441674875116748\n",
      "iteration 5570 x1[-1.26266202 -1.26243727 -1.26541773 -1.26741479 -1.26778825] x2[-1.26322906 -1.26399234 -1.26358692 -1.25951003 -1.26115568] loss [0.34424026 0.34419372 0.34397132 0.34415487 0.34397928] losses 0.34410789123741176\n",
      "iteration 5580 x1[-1.26347516 -1.26342349 -1.26647573 -1.26714453 -1.26786802] x2[-1.26331649 -1.26389098 -1.26268835 -1.25925538 -1.26052331] loss [0.34416221 0.34411699 0.34395833 0.34420031 0.34402759] losses 0.3440930836474677\n",
      "iteration 5590 x1[-1.26408111 -1.26411845 -1.26612044 -1.26739895 -1.26751878] x2[-1.26377086 -1.26320168 -1.26232607 -1.25936776 -1.26015833] loss [0.34407053 0.34411654 0.34402018 0.34416869 0.34408926] losses 0.34409304043428374\n",
      "iteration 5600 x1[-1.26416212 -1.26463289 -1.26813896 -1.26694312 -1.26867902] x2[-1.26301157 -1.26295401 -1.26081384 -1.25931877 -1.25940787] loss [0.34412924 0.34409361 0.34397916 0.34421199 0.34405601] losses 0.3440940018461737\n",
      "iteration 5610 x1[-1.26491625 -1.26674095 -1.26785741 -1.26737767 -1.26887323] x2[-1.2628028  -1.26249128 -1.26176194 -1.2595941  -1.25996969] loss [0.3440823  0.34395271 0.34392067 0.34415068 0.34399035] losses 0.34401934310079973\n",
      "iteration 5620 x1[-1.2644497  -1.26690903 -1.26881363 -1.26794672 -1.26992364] x2[-1.26279864 -1.26267361 -1.26215844 -1.2598936  -1.26027129] loss [0.34412287 0.34392254 0.34380495 0.34407588 0.34387494] losses 0.34396023604046544\n",
      "iteration 5630 x1[-1.26487256 -1.26716508 -1.26990693 -1.26783164 -1.27052047] x2[-1.26312432 -1.26346709 -1.26188115 -1.25915203 -1.25964116] loss [0.34405822 0.34383206 0.34373636 0.34415064 0.34387949] losses 0.3439313540429716\n",
      "iteration 5640 x1[-1.26425718 -1.26543165 -1.26804814 -1.2677234  -1.26929127] x2[-1.26309678 -1.26286159 -1.26161414 -1.25946009 -1.25971208] loss [0.34411365 0.34403288 0.34391726 0.34413288 0.34397736] losses 0.34403480630204647\n",
      "iteration 5650 x1[-1.26501262 -1.26769147 -1.26882522 -1.26914308 -1.27066765] x2[-1.26307063 -1.26363058 -1.26117908 -1.25994011 -1.26011957] loss [0.34405081 0.34377308 0.343889   0.34397001 0.34382529] losses 0.3439016365921409\n",
      "iteration 5660 x1[-1.26456492 -1.26707826 -1.26907271 -1.2676461  -1.27005748] x2[-1.26338257 -1.26431332 -1.2604377  -1.26124547 -1.26060412] loss [0.34406237 0.34376653 0.34393255 0.34398359 0.3438346 ] losses 0.34391592840998303\n",
      "iteration 5670 x1[-1.26448264 -1.26864772 -1.27000913 -1.26874793 -1.2714247 ] x2[-1.26335878 -1.26592263 -1.2612742  -1.26063422 -1.26081812] loss [0.34407152 0.34349507 0.3437804  0.34394301 0.34370066] losses 0.34379813273389215\n",
      "iteration 5680 x1[-1.2654567  -1.26806151 -1.27042174 -1.26829574 -1.27081016] x2[-1.26421111 -1.26561439 -1.26328044 -1.26210255 -1.26223287] loss [0.34391412 0.34357116 0.34357193 0.3438538  0.34362968] losses 0.3437081360684222\n",
      "iteration 5690 x1[-1.26519339 -1.26765047 -1.27154378 -1.26888869 -1.27212437] x2[-1.26335009 -1.26645205 -1.263699   -1.26165271 -1.2625065 ] loss [0.34401108 0.3435345  0.34344151 0.34384245 0.34349561] losses 0.3436650277845213\n",
      "iteration 5700 x1[-1.26595993 -1.26769397 -1.27125384 -1.26861354 -1.27160398] x2[-1.26234773 -1.26580021 -1.26343995 -1.260683   -1.26217056] loss [0.34403206 0.3435865  0.34348815 0.34395018 0.3435683 ] losses 0.3437250381858166\n",
      "iteration 5710 x1[-1.266023   -1.26696234 -1.2709777  -1.27037833 -1.27219762] x2[-1.26324911 -1.26540655 -1.26438478 -1.26079249 -1.26262533] loss [0.34394858 0.34368252 0.34343014 0.34379109 0.34347921] losses 0.34366630711960877\n",
      "iteration 5720 x1[-1.26539922 -1.26668485 -1.27293717 -1.27037892 -1.27338092] x2[-1.2627557  -1.26605671 -1.26343187 -1.25988799 -1.26205713] loss [0.34404484 0.34365053 0.34334786 0.34386988 0.34342938] losses 0.34366849810180206\n",
      "iteration 5730 x1[-1.26686003 -1.26815251 -1.27277977 -1.27139949 -1.27350077] x2[-1.2645314  -1.26763712 -1.26406091 -1.26091551 -1.26262868] loss [0.34376639 0.34339099 0.34330696 0.34369432 0.34337003] losses 0.34350573722353483\n",
      "iteration 5740 x1[-1.26760877 -1.26813656 -1.27195965 -1.2720632  -1.27336838] x2[-1.26404098 -1.26816655 -1.26313538 -1.26142903 -1.26251131] loss [0.34374475 0.34334742 0.34345516 0.34359398 0.3433912 ] losses 0.3435065015788862\n",
      "iteration 5750 x1[-1.26731122 -1.2677998  -1.27304302 -1.27153913 -1.27393481] x2[-1.26458683 -1.26805376 -1.26258433 -1.26260183 -1.26265193] loss [0.34372314 0.34338555 0.34341204 0.34353647 0.34333188] losses 0.34347781559119683\n",
      "iteration 5760 x1[-1.268744   -1.26935274 -1.27340054 -1.27361761 -1.2750076 ] x2[-1.26427574 -1.26951913 -1.26276272 -1.2616836  -1.26263402] loss [0.34362808 0.34313032 0.34336683 0.34344195 0.34324435] losses 0.343362304773953\n",
      "iteration 5770 x1[-1.26874303 -1.26935004 -1.27273686 -1.272346   -1.27381848] x2[-1.26382045 -1.26948905 -1.26275492 -1.26169997 -1.26271551] loss [0.34366734 0.34313309 0.3434229  0.34354679 0.34333608] losses 0.3434212416202202\n",
      "iteration 5780 x1[-1.26891836 -1.26941774 -1.27242758 -1.27162626 -1.27325332] x2[-1.26356077 -1.26894435 -1.26342706 -1.26169291 -1.26328616] loss [0.34367485 0.34317332 0.34339086 0.34360778 0.34333402] losses 0.3434361673104182\n",
      "iteration 5790 x1[-1.26874487 -1.27042637 -1.273668   -1.27162662 -1.27416763] x2[-1.2631491  -1.26833757 -1.26373647 -1.26115414 -1.26323076] loss [0.34372508 0.34313971 0.34326076 0.34365449 0.34326267] losses 0.3434085438391713\n",
      "iteration 5800 x1[-1.26841505 -1.27190884 -1.27370467 -1.27231386 -1.27523949] x2[-1.26377011 -1.26873594 -1.26526043 -1.26251887 -1.26499841] loss [0.34369952 0.34298188 0.34312721 0.34347866 0.34302236] losses 0.34326192775481035\n",
      "iteration 5810 x1[-1.26931867 -1.27180706 -1.27272472 -1.27249423 -1.27474737] x2[-1.26592437 -1.26862469 -1.26418305 -1.26316349 -1.26380495] loss [0.34343815 0.34299977 0.34330107 0.34340798 0.34316524] losses 0.34326244177381804\n",
      "iteration 5820 x1[-1.26867534 -1.27171148 -1.27228246 -1.27251151 -1.27460592] x2[-1.26663413 -1.26885183 -1.26500042 -1.26277679 -1.26367621] loss [0.34343202 0.3429886  0.343268   0.34343986 0.34318801] losses 0.3432632981810797\n",
      "iteration 5830 x1[-1.26872959 -1.27170507 -1.27220656 -1.27234066 -1.27438233] x2[-1.26714341 -1.26950509 -1.26406772 -1.26310735 -1.26347408] loss [0.34338406 0.34293411 0.34335429 0.34342566 0.34322392] losses 0.343264409458994\n",
      "iteration 5840 x1[-1.26931321 -1.27316802 -1.27246012 -1.27322983 -1.2751119 ] x2[-1.26747934 -1.27041263 -1.26488711 -1.26342911 -1.26405242] loss [0.34330618 0.34273612 0.34326285 0.34332368 0.34311383] losses 0.3431485330624751\n",
      "iteration 5850 x1[-1.26922516 -1.27245945 -1.27237132 -1.27307979 -1.27487946] x2[-1.26746488 -1.27147738 -1.26655329 -1.26289314 -1.26480212] loss [0.34331485 0.342706   0.34312813 0.34338234 0.34306891] losses 0.3431200454914314\n",
      "iteration 5860 x1[-1.26862859 -1.27293948 -1.27111775 -1.27360828 -1.27458742] x2[-1.26848934 -1.27292979 -1.26677112 -1.26305909 -1.26473729] loss [0.34327842 0.3425453  0.34321451 0.34332398 0.34309864] losses 0.3430921721855994\n",
      "iteration 5870 x1[-1.26979559 -1.27297428 -1.27112632 -1.27415808 -1.27441248] x2[-1.27068648 -1.27452908 -1.26782762 -1.26547511 -1.26622578] loss [0.34299493 0.34241019 0.34312413 0.34307124 0.34298622] losses 0.342917341934527\n",
      "iteration 5880 x1[-1.27043169 -1.27295037 -1.27063777 -1.27540067 -1.27469886] x2[-1.27041404 -1.27323997 -1.2685227  -1.26475543 -1.26606151] loss [0.34296435 0.34251869 0.34310631 0.3430298  0.34297648] losses 0.3429191248043807\n",
      "iteration 5890 x1[-1.27069743 -1.27282022 -1.26999817 -1.27607819 -1.27437034] x2[-1.27136655 -1.2725975  -1.26869012 -1.26579275 -1.26634343] loss [0.34286232 0.34258278 0.34314591 0.34288547 0.34297971] losses 0.3428912378329002\n",
      "iteration 5900 x1[-1.27129513 -1.27347841 -1.26973819 -1.27727828 -1.27468932] x2[-1.27127604 -1.27333373 -1.26865968 -1.26630356 -1.26695481] loss [0.34281988 0.34246719 0.34317037 0.34274351 0.34290141] losses 0.34282047182902103\n",
      "iteration 5910 x1[-1.2713812  -1.27420882 -1.26999827 -1.27657462 -1.27423146] x2[-1.27136467 -1.27494198 -1.26966528 -1.26524927 -1.26703207] loss [0.34280528 0.3422742  0.34306367 0.34289091 0.34293276] losses 0.3427933659603852\n",
      "iteration 5920 x1[-1.2714785  -1.27485508 -1.26975311 -1.27586673 -1.27352733] x2[-1.27110878 -1.27505562 -1.27011853 -1.26525368 -1.26752903] loss [0.34281854 0.34221168 0.34304617 0.34294881 0.34294908] losses 0.3427948560541328\n",
      "iteration 5930 x1[-1.2717388  -1.27559226 -1.26987884 -1.27723795 -1.27449117] x2[-1.27122897 -1.27515484 -1.27072823 -1.26665016 -1.26869971] loss [0.34278677 0.34214303 0.34298443 0.34271743 0.34277036] losses 0.34268040370987296\n",
      "iteration 5940 x1[-1.27304362 -1.27568627 -1.27035845 -1.27671672 -1.27398944] x2[-1.27289559 -1.27598719 -1.27099083 -1.26767306 -1.26916457] loss [0.34253951 0.34206714 0.34292216 0.34267365 0.34277275] losses 0.34259504023897014\n",
      "iteration 5950 x1[-1.27278004 -1.27578504 -1.27083837 -1.27779574 -1.27524739] x2[-1.27313958 -1.27542403 -1.27126087 -1.26901868 -1.2703109 ] loss [0.34254114 0.34210516 0.34285935 0.3424721  0.34257272] losses 0.34251009542397404\n",
      "iteration 5960 x1[-1.27237003 -1.27583465 -1.27094777 -1.27732373 -1.27518091] x2[-1.27336125 -1.27579439 -1.26983583 -1.27014656 -1.26981248] loss [0.34255682 0.34207077 0.34296965 0.34241618 0.34261993] losses 0.342526668263312\n",
      "iteration 5970 x1[-1.27178341 -1.27602556 -1.27175281 -1.27601505 -1.27529934] x2[-1.27359079 -1.27453892 -1.27051878 -1.27121696 -1.27060289] loss [0.34258661 0.34215815 0.34284502 0.34243398 0.34254403] losses 0.3425135582298327\n",
      "iteration 5980 x1[-1.27277397 -1.27543024 -1.27235572 -1.27614938 -1.2751671 ] x2[-1.27466944 -1.27520998 -1.27034035 -1.27260273 -1.27087391] loss [0.34241522 0.34215179 0.34280971 0.34230783 0.34253229] losses 0.34244336846813195\n",
      "iteration 5990 x1[-1.27289917 -1.27588861 -1.27450307 -1.27681979 -1.27712131] x2[-1.27520313 -1.27535798 -1.27105214 -1.27257554 -1.27098204] loss [0.34236093 0.3421021  0.34257215 0.34225524 0.34236299] losses 0.34233068114695286\n",
      "iteration 6000 x1[-1.27407048 -1.27687647 -1.27572406 -1.27714533 -1.27782541] x2[-1.2759345  -1.27612514 -1.27126701 -1.27359313 -1.27154082] loss [0.34220416 0.34195866 0.3424537  0.34214456 0.34225905] losses 0.3422040266003251\n",
      "iteration 6010 x1[-1.27385236 -1.27706605 -1.27652207 -1.27727192 -1.27854164] x2[-1.27692305 -1.27617425 -1.2714681  -1.27389117 -1.27142389] loss [0.34214132 0.34193921 0.34237152 0.34210968 0.34221052] losses 0.34215444948314067\n",
      "iteration 6020 x1[-1.2738157  -1.27702348 -1.27618765 -1.27723846 -1.27820478] x2[-1.27626051 -1.27702826 -1.27245953 -1.27289104 -1.27179332] loss [0.34219847 0.34187306 0.34231657 0.34219495 0.34220721] losses 0.3421580539841054\n",
      "iteration 6030 x1[-1.27265698 -1.27567166 -1.27568595 -1.27559667 -1.27722104] x2[-1.27658183 -1.2764165  -1.27260923 -1.27286479 -1.27165652] loss [0.34226794 0.34203325 0.34234529 0.34233145 0.34229872] losses 0.3422553308982553\n",
      "iteration 6040 x1[-1.27279585 -1.27627755 -1.27537286 -1.27560124 -1.27691668] x2[-1.2752818  -1.27581199 -1.27289235 -1.27234097 -1.27181765] loss [0.34236302 0.34203312 0.34234755 0.34237449 0.34231019] losses 0.3422856728530558\n",
      "iteration 6050 x1[-1.27293528 -1.27640779 -1.27586091 -1.27559759 -1.27709547] x2[-1.27562524 -1.27650257 -1.2728568  -1.27246793 -1.27198269] loss [0.34232327 0.34196607 0.34231043 0.34236426 0.34228188] losses 0.3422491812459213\n",
      "iteration 6060 x1[-1.27403703 -1.27644508 -1.27585973 -1.27622301 -1.2770213 ] x2[-1.27484739 -1.27662349 -1.27330381 -1.27149316 -1.27206893] loss [0.34229615 0.34195316 0.34227355 0.34239393 0.34228078] losses 0.3422395141494392\n",
      "iteration 6070 x1[-1.27445639 -1.27770077 -1.27536223 -1.27619475 -1.27670819] x2[-1.27522446 -1.27633362 -1.27164427 -1.27150851 -1.27093718] loss [0.34223061 0.3418746  0.34245202 0.34239497 0.3424005 ] losses 0.3422705411620554\n",
      "iteration 6080 x1[-1.2755147  -1.27777887 -1.2758345  -1.27633763 -1.27655828] x2[-1.27558373 -1.27565228 -1.27131344 -1.27201549 -1.27088745] loss [0.34211422 0.3419239  0.34244076 0.34234112 0.34241692] losses 0.34224738583707554\n",
      "iteration 6090 x1[-1.27523203 -1.27685654 -1.27452088 -1.27728213 -1.27642051] x2[-1.27595146 -1.27499597 -1.27098133 -1.27253919 -1.27084188] loss [0.34210729 0.34205271 0.34257659 0.34222051 0.34243201] losses 0.34227782144111807\n",
      "iteration 6100 x1[-1.27626921 -1.27782861 -1.27612252 -1.27660346 -1.27667582] x2[-1.27693862 -1.27619954 -1.2700275  -1.27256614 -1.27024674] loss [0.34194183 0.34187516 0.34252449 0.3422737  0.34246079] losses 0.34221519387873506\n",
      "iteration 6110 x1[-1.27680296 -1.27773445 -1.27557801 -1.27741343 -1.27668973] x2[-1.27694718 -1.27560302 -1.27007037 -1.27227079 -1.27014146] loss [0.34189762 0.34193153 0.34256564 0.34223204 0.34246845] losses 0.3422190566371146\n",
      "iteration 6120 x1[-1.2773147  -1.27771501 -1.27552246 -1.27771163 -1.27661008] x2[-1.27679794 -1.27567193 -1.27044464 -1.27199922 -1.27005472] loss [0.34186813 0.34192748 0.3425389  0.34223026 0.34248223] losses 0.3422093989874751\n",
      "iteration 6130 x1[-1.27635896 -1.2778612  -1.27645698 -1.27607608 -1.27639435] x2[-1.27649497 -1.27598477 -1.27191675 -1.27236858 -1.27132264] loss [0.34197067 0.34189004 0.34233955 0.34233325 0.34239409] losses 0.34218552102751765\n",
      "iteration 6140 x1[-1.27623705 -1.27785647 -1.27657861 -1.2770563  -1.27700158] x2[-1.27588039 -1.27531468 -1.27158564 -1.27222454 -1.27126766] loss [0.34203083 0.34194522 0.34235712 0.34226501 0.34234898] losses 0.34218943215880765\n",
      "iteration 6150 x1[-1.27611202 -1.27670577 -1.27733642 -1.27702531 -1.27742314] x2[-1.27576562 -1.27612937 -1.2720932  -1.27160695 -1.27138803] loss [0.34205044 0.34197223 0.34225304 0.34231882 0.34230455] losses 0.34217981493597704\n",
      "iteration 6160 x1[-1.27501999 -1.27663723 -1.27693037 -1.27585366 -1.27677265] x2[-1.27548672 -1.27602592 -1.2716163  -1.27133534 -1.27078537] loss [0.34216275 0.34198627 0.3423258  0.34243737 0.34240789] losses 0.3422640151293606\n",
      "iteration 6170 x1[-1.27574352 -1.27617824 -1.27750973 -1.27760836 -1.27814715] x2[-1.27634387 -1.27680281 -1.27212599 -1.27235621 -1.27157518] loss [0.3420333  0.34196032 0.34223619 0.34220907 0.34223001] losses 0.3421337815537519\n",
      "iteration 6180 x1[-1.27483952 -1.27486434 -1.27712865 -1.27676706 -1.27750025] x2[-1.27637009 -1.27673043 -1.27181979 -1.2730222  -1.2718532 ] loss [0.34210527 0.3420738  0.34229269 0.34222258 0.3422596 ] losses 0.3421907898512213\n",
      "iteration 6190 x1[-1.27494385 -1.27504276 -1.27756824 -1.27677413 -1.27768889] x2[-1.27670374 -1.27746205 -1.27231815 -1.27413839 -1.27291874] loss [0.34206946 0.34199956 0.3422155  0.34212992 0.34215596] losses 0.3421140771639718\n",
      "iteration 6200 x1[-1.27551754 -1.27473182 -1.27878338 -1.27662084 -1.27802895] x2[-1.27624319 -1.27730147 -1.27156232 -1.27393021 -1.27260341] loss [0.34206003 0.34203814 0.3421794  0.34215958 0.34215438] losses 0.34211830376739905\n",
      "iteration 6210 x1[-1.27560185 -1.27622082 -1.27899807 -1.27584438 -1.27788466] x2[-1.27724558 -1.27794723 -1.27146429 -1.27486261 -1.27309906] loss [0.34197138 0.3418638  0.34217013 0.34214637 0.34212513] losses 0.3420553617148128\n",
      "iteration 6220 x1[-1.27698643 -1.27688205 -1.27825983 -1.27654845 -1.27759707] x2[-1.2782504  -1.27965179 -1.2739595  -1.27530227 -1.27447307] loss [0.34177687 0.34167218 0.34202372 0.34205273 0.34203533] losses 0.341912166006611\n",
      "iteration 6230 x1[-1.27739334 -1.27779698 -1.27903419 -1.27661832 -1.27807664] x2[-1.27794302 -1.279053   -1.27428602 -1.27605212 -1.27548666] loss [0.34176871 0.34164621 0.34193413 0.34198567 0.34191327] losses 0.34184959806801146\n",
      "iteration 6240 x1[-1.2784261  -1.27753305 -1.28028159 -1.27748486 -1.27935448] x2[-1.2783254  -1.27931519 -1.27559963 -1.2756824  -1.2760173 ] loss [0.34165407 0.34164646 0.34172595 0.34194533 0.34176655] losses 0.3417476712363563\n",
      "iteration 6250 x1[-1.27862898 -1.27714624 -1.28086346 -1.27752862 -1.27980276] x2[-1.27806723 -1.27956044 -1.27705879 -1.27452031 -1.27621814] loss [0.34165856 0.34165808 0.34156049 0.34203702 0.34171404] losses 0.3417256388308581\n",
      "iteration 6260 x1[-1.27883648 -1.27651494 -1.2804885  -1.27789963 -1.27953046] x2[-1.27813447 -1.27843466 -1.27781601 -1.27467229 -1.27680182] loss [0.34163636 0.34180032 0.3415292  0.34199438 0.34168847] losses 0.3417297473177452\n",
      "iteration 6270 x1[-1.28000094 -1.27679664 -1.28127797 -1.27904486 -1.28031456] x2[-1.27853366 -1.2791914  -1.2782416  -1.27583082 -1.27780417] loss [0.34151034 0.34171623 0.34143159 0.34180676 0.34154411] losses 0.34160180859157724\n",
      "iteration 6280 x1[-1.28115699 -1.2790355  -1.28205578 -1.27890849 -1.28045962] x2[-1.27943424 -1.27960363 -1.27720339 -1.27615626 -1.2768388 ] loss [0.34134521 0.3415018  0.34145346 0.34179123 0.34161074] losses 0.3415404878944953\n",
      "iteration 6290 x1[-1.28099422 -1.27844548 -1.28196143 -1.27845919 -1.28008818] x2[-1.28000121 -1.27956517 -1.27685744 -1.27665341 -1.27673013] loss [0.34131271 0.34155249 0.34148903 0.34178706 0.34164941] losses 0.34155814117064937\n",
      "iteration 6300 x1[-1.2817941  -1.27836097 -1.28105741 -1.27869004 -1.27925951] x2[-1.27891908 -1.27876951 -1.2765025  -1.27648171 -1.27637045] loss [0.34133579 0.34162345 0.34159013 0.34178236 0.34174542] losses 0.3416154324542445\n",
      "iteration 6310 x1[-1.282743   -1.27926016 -1.28164751 -1.27956613 -1.28008198] x2[-1.27885017 -1.28042272 -1.27856258 -1.27632012 -1.27746912] loss [0.34126583 0.34141796 0.34137619 0.3417248  0.34158993] losses 0.34147494135308626\n",
      "iteration 6320 x1[-1.28400246 -1.28022901 -1.28289778 -1.28025058 -1.28081372] x2[-1.27914949 -1.28110266 -1.27863928 -1.27651281 -1.27759067] loss [0.34114202 0.34128579 0.34127051 0.34165403 0.34152137] losses 0.3413747439873521\n",
      "iteration 6330 x1[-1.28312316 -1.27964386 -1.28297819 -1.27948263 -1.28049065] x2[-1.27960823 -1.28128692 -1.27938594 -1.27669491 -1.27819969] loss [0.34117479 0.341318   0.34120412 0.34170102 0.34149801] losses 0.3413791872484312\n",
      "iteration 6340 x1[-1.28324896 -1.27988846 -1.28371824 -1.27856839 -1.2803433 ] x2[-1.27989705 -1.28065465 -1.27962052 -1.27767676 -1.27862373] loss [0.34114169 0.34134891 0.34112671 0.34169509 0.34147559] losses 0.3413575971505477\n",
      "iteration 6350 x1[-1.28305143 -1.27931576 -1.28360118 -1.27866887 -1.28035838] x2[-1.28001772 -1.28011431 -1.28004799 -1.27780562 -1.27896606] loss [0.34114767 0.34143822 0.34110174 0.34167652 0.34144679] losses 0.34136218915819905\n",
      "iteration 6360 x1[-1.28301763 -1.27825149 -1.28414459 -1.278755   -1.28085607] x2[-1.27947878 -1.28008095 -1.27981099 -1.27712587 -1.27849625] loss [0.34119354 0.3415267  0.34107778 0.34172471 0.34144479] losses 0.3413935042972409\n",
      "iteration 6370 x1[-1.28379334 -1.27805378 -1.28550605 -1.28014164 -1.28248812] x2[-1.28040286 -1.28009804 -1.28007886 -1.27841376 -1.27894058] loss [0.34105818 0.34154131 0.34094924 0.34150872 0.34127881] losses 0.3412672518225552\n",
      "iteration 6380 x1[-1.28389738 -1.27879691 -1.28536915 -1.28019187 -1.28244808] x2[-1.27969862 -1.27991098 -1.27906973 -1.27823676 -1.27835354] loss [0.34110629 0.34149633 0.34104076 0.34151898 0.34132926] losses 0.3412983255407829\n",
      "iteration 6390 x1[-1.28497461 -1.27897239 -1.28557634 -1.28139766 -1.28299953] x2[-1.28031442 -1.28004477 -1.27969083 -1.27870285 -1.27873632] loss [0.34097216 0.34147144 0.34097474 0.34138483 0.34125463] losses 0.34121156103506284\n",
      "iteration 6400 x1[-1.28488286 -1.28018632 -1.28479665 -1.28046789 -1.28183238] x2[-1.2810981  -1.28010735 -1.27964887 -1.27919717 -1.27888715] loss [0.34091691 0.34136886 0.34103937 0.34141941 0.34133531] losses 0.34121597167408824\n",
      "iteration 6410 x1[-1.28515423 -1.28034261 -1.28533115 -1.28233439 -1.28304717] x2[-1.28233546 -1.28033125 -1.28058313 -1.27951629 -1.27920048] loss [0.34079739 0.3413384  0.34092272 0.34124478 0.34121354] losses 0.3411033654664605\n",
      "iteration 6420 x1[-1.28592376 -1.28162655 -1.28474917 -1.28368449 -1.28345008] x2[-1.2827422  -1.28121874 -1.28150177 -1.28115751 -1.28082573] loss [0.34070498 0.34116492 0.34089532 0.34100659 0.34105156] losses 0.3409646743660259\n",
      "iteration 6430 x1[-1.28651884 -1.28168369 -1.28453138 -1.28403712 -1.2834545 ] x2[-1.2839661  -1.28250448 -1.28126557 -1.28148267 -1.28039356] loss [0.34056215 0.34105811 0.34093123 0.34095289 0.34108571] losses 0.3409180186521664\n",
      "iteration 6440 x1[-1.28580994 -1.28095947 -1.28350278 -1.28374115 -1.28296718] x2[-1.28498645 -1.28390766 -1.28168018 -1.28099552 -1.28013765] loss [0.34053742 0.34100475 0.34097936 0.34101502 0.34114475] losses 0.34093626211523204\n",
      "iteration 6450 x1[-1.28528561 -1.28154097 -1.2826578  -1.28443644 -1.28314131] x2[-1.28565449 -1.2825156  -1.28125364 -1.28133734 -1.27971977] loss [0.34052615 0.34106858 0.34108018 0.34093299 0.34116441] losses 0.3409544655448545\n",
      "iteration 6460 x1[-1.28627248 -1.28391581 -1.28413636 -1.28397474 -1.28380121] x2[-1.28711383 -1.28482841 -1.28278473 -1.28233257 -1.2811825 ] loss [0.34033564 0.34069823 0.34084183 0.34089035 0.34099539] losses 0.3407522876180189\n",
      "iteration 6470 x1[-1.2864462  -1.28317223 -1.283308   -1.2833977  -1.2826771 ] x2[-1.28791088 -1.28620893 -1.283333   -1.28330314 -1.28188822] loss [0.34026044 0.34064878 0.34086382 0.34085909 0.34102816] losses 0.3407320583777339\n",
      "iteration 6480 x1[-1.28727036 -1.28384805 -1.28267997 -1.28433526 -1.28283295] x2[-1.28771356 -1.28681672 -1.28318704 -1.28310027 -1.28198344] loss [0.34021178 0.34054824 0.340925   0.34080124 0.34100825] losses 0.3406989040447079\n",
      "iteration 6490 x1[-1.28824961 -1.28532581 -1.28306683 -1.28573467 -1.28379407] x2[-1.28784998 -1.28669743 -1.28256287 -1.28422425 -1.28248804] loss [0.3401256  0.34044175 0.34094378 0.34060305 0.34089228] losses 0.34060129230167113\n",
      "iteration 6500 x1[-1.28935799 -1.28601922 -1.28312116 -1.2859744  -1.28352694] x2[-1.28849252 -1.28678098 -1.2829602  -1.28468357 -1.28283635] loss [0.33999087 0.34038118 0.34090804 0.3405483  0.34088578] losses 0.3405428362381634\n",
      "iteration 6510 x1[-1.28946932 -1.28621626 -1.28397368 -1.28606765 -1.28408514] x2[-1.28979088 -1.28751898 -1.28335279 -1.28499258 -1.28286089] loss [0.33988276 0.34030862 0.34080976 0.34051683 0.34083984] losses 0.3404715635246979\n",
      "iteration 6520 x1[-1.28879867 -1.28683681 -1.28383404 -1.28632163 -1.28422018] x2[-1.28991486 -1.2888964  -1.28405128 -1.28366963 -1.28224075] loss [0.3399247  0.34015414 0.34076572 0.34060082 0.34087829] losses 0.3404647353857896\n",
      "iteration 6530 x1[-1.2889702  -1.2855012  -1.2833709  -1.28672348 -1.28401988] x2[-1.29067631 -1.28876044 -1.28375726 -1.284503   -1.28213759] loss [0.33985339 0.34026838 0.34082538 0.3405041  0.34090225] losses 0.340470701829538\n",
      "iteration 6540 x1[-1.28813973 -1.28541532 -1.28276556 -1.286457   -1.28359186] x2[-1.29060178 -1.28934795 -1.28394405 -1.28517926 -1.2826128 ] loss [0.33992287 0.34022985 0.34085849 0.3404719  0.34089835] losses 0.34047629257125184\n",
      "iteration 6550 x1[-1.28849983 -1.28690932 -1.28332682 -1.28703551 -1.28424982] x2[-1.29133801 -1.2908221  -1.28494757 -1.28630102 -1.28412626] loss [0.3398391  0.34000097 0.34073528 0.3403395  0.34072711] losses 0.3403283901393957\n",
      "iteration 6560 x1[-1.28790025 -1.28602357 -1.28196027 -1.28809373 -1.2840144 ] x2[-1.29222578 -1.29137924 -1.28462366 -1.28675151 -1.2842152 ] loss [0.33981778 0.34002709 0.34086879 0.34022262 0.34073863] losses 0.34033498065275347\n",
      "iteration 6570 x1[-1.28748142 -1.2849215  -1.28273803 -1.28766853 -1.28403011] x2[-1.2915939  -1.29116283 -1.28414279 -1.2865359  -1.28405781] loss [0.339898   0.3401293  0.34084502 0.34027221 0.34074977] losses 0.34037885945417323\n",
      "iteration 6580 x1[-1.28819304 -1.28660108 -1.28396199 -1.28674523 -1.28419219] x2[-1.29165162 -1.29039882 -1.28435078 -1.28649351 -1.28383815] loss [0.33983884 0.34005716 0.3407321  0.34034706 0.34075431] losses 0.34034589259561193\n",
      "iteration 6590 x1[-1.28890203 -1.28791931 -1.28370428 -1.28765426 -1.2843689 ] x2[-1.29057245 -1.28974643 -1.28470395 -1.28545323 -1.28384788] loss [0.33986654 0.34000524 0.34072465 0.34035757 0.34073965] losses 0.34033872939011806\n",
      "iteration 6600 x1[-1.28843469 -1.28658313 -1.28344867 -1.28821068 -1.28454125] x2[-1.29164508 -1.2896847  -1.2845716  -1.28723622 -1.28461139] loss [0.33982077 0.34011324 0.34075518 0.34017604 0.34066611] losses 0.3403062670444488\n",
      "iteration 6610 x1[-1.28830944 -1.28601616 -1.28352978 -1.28728365 -1.28397288] x2[-1.29089375 -1.2901864  -1.28443578 -1.28603769 -1.28380371] loss [0.33988755 0.34011878 0.34075945 0.34034074 0.34077428] losses 0.34037616115898783\n",
      "iteration 6620 x1[-1.28834539 -1.28474193 -1.28324924 -1.28719647 -1.28349712] x2[-1.29129491 -1.29114495 -1.28332322 -1.28648877 -1.28317748] loss [0.33985424 0.34014467 0.34086923 0.34031242 0.34086117] losses 0.3404083468509718\n",
      "iteration 6630 x1[-1.28788209 -1.28440612 -1.28412164 -1.28743252 -1.28441662] x2[-1.29168545 -1.2912475  -1.28434603 -1.28612436 -1.28370744] loss [0.33986018 0.34016305 0.34071991 0.34032246 0.34074696] losses 0.34036251395768424\n",
      "iteration 6640 x1[-1.28778364 -1.28474996 -1.28483741 -1.28667559 -1.28466151] x2[-1.29107916 -1.29191843 -1.28551835 -1.28592018 -1.28431139] loss [0.33991389 0.34008508 0.34057186 0.34039709 0.34068022] losses 0.3403296287183518\n",
      "iteration 6650 x1[-1.28803194 -1.28494446 -1.28472417 -1.28677763 -1.28474976] x2[-1.29163843 -1.29232347 -1.28503304 -1.28635256 -1.28415278] loss [0.33985223 0.34003914 0.34061871 0.3403555  0.34068576] losses 0.3403102666224008\n",
      "iteration 6660 x1[-1.28826026 -1.28454287 -1.28494228 -1.28737623 -1.28541425] x2[-1.29154256 -1.29216775 -1.28505321 -1.2869424  -1.2845741 ] loss [0.33984196 0.34008227 0.34060003 0.34026329 0.34060064] losses 0.34027763740475436\n",
      "iteration 6670 x1[-1.28877774 -1.28548334 -1.28563199 -1.28651461 -1.28532871] x2[-1.29195538 -1.29324149 -1.2849367  -1.2880291  -1.28531187] loss [0.3397709  0.33992766 0.34055521 0.34024599 0.34054955] losses 0.3402098616167669\n",
      "iteration 6680 x1[-1.288681   -1.28496423 -1.28520549 -1.28617703 -1.28486627] x2[-1.29232822 -1.29314058 -1.28543125 -1.28885051 -1.28590747] loss [0.33975006 0.33997564 0.34054986 0.34020886 0.34053922] losses 0.34020472799084656\n",
      "iteration 6690 x1[-1.28965601 -1.28468882 -1.28602132 -1.28646929 -1.2851187 ] x2[-1.29176642 -1.2925797  -1.28669362 -1.28949133 -1.28726129] loss [0.33971803 0.3400396  0.34038781 0.34013691 0.34041414] losses 0.34013929550964805\n",
      "iteration 6700 x1[-1.28938073 -1.28556377 -1.28653263 -1.28630287 -1.28546338] x2[-1.29277484 -1.29311968 -1.2867149  -1.29027095 -1.28781694] loss [0.33966274 0.33993063 0.34034638 0.34009005 0.34034419] losses 0.34007479643973193\n",
      "iteration 6710 x1[-1.28914097 -1.28649673 -1.28748021 -1.28662258 -1.28633151] x2[-1.29375736 -1.29436908 -1.28737968 -1.29010594 -1.28799319] loss [0.339607   0.33976415 0.34022137 0.3400779  0.34026298] losses 0.3399866793014259\n",
      "iteration 6720 x1[-1.28939925 -1.28735919 -1.28797719 -1.28769772 -1.28726706] x2[-1.29394219 -1.29497733 -1.28817282 -1.28966747 -1.28817794] loss [0.33957337 0.339652   0.3401217  0.34002837 0.34017618] losses 0.339910326676105\n",
      "iteration 6730 x1[-1.28934347 -1.28744136 -1.28771294 -1.28782946 -1.287122  ] x2[-1.29490762 -1.2942885  -1.28834273 -1.29123833 -1.28905263] loss [0.33950522 0.33969738 0.340129   0.33989824 0.34012004] losses 0.33986997872005087\n",
      "iteration 6740 x1[-1.28898492 -1.28681712 -1.28714096 -1.2870601  -1.28614706] x2[-1.29538189 -1.29345917 -1.2880516  -1.29139057 -1.2885299 ] loss [0.33949713 0.33980795 0.34019569 0.33994599 0.34023589] losses 0.33993652952841186\n",
      "iteration 6750 x1[-1.28878723 -1.28650013 -1.28781897 -1.28692385 -1.28673223] x2[-1.29536564 -1.29171921 -1.28928704 -1.29214301 -1.28954679] loss [0.33951344 0.33996428 0.3400482  0.33989932 0.34011227] losses 0.3399075018521705\n",
      "iteration 6760 x1[-1.288297   -1.28680583 -1.28850202 -1.2883454  -1.28855322] x2[-1.29612139 -1.29362675 -1.29021651 -1.2933248  -1.29062775] loss [0.33949454 0.33979618 0.33992443 0.33970049 0.3398891 ] losses 0.3397609479489647\n",
      "iteration 6770 x1[-1.2884577  -1.28812263 -1.28842006 -1.2875902  -1.28780801] x2[-1.29578733 -1.29351194 -1.29037132 -1.29325806 -1.29062842] loss [0.33950715 0.33970348 0.3399189  0.33976355 0.33994638] losses 0.3397678914772172\n",
      "iteration 6780 x1[-1.28876013 -1.28825595 -1.28834035 -1.28960325 -1.28914424] x2[-1.29578233 -1.29394928 -1.28990144 -1.2922918  -1.28978638] loss [0.3394844  0.33966032 0.33996095 0.33968226 0.33990801] losses 0.3397391876755754\n",
      "iteration 6790 x1[-1.28813751 -1.28762832 -1.28765843 -1.28849709 -1.2881516 ] x2[-1.29592065 -1.29444736 -1.2897456  -1.29272747 -1.29011299] loss [0.33952172 0.33967107 0.34002542 0.33973396 0.33995929] losses 0.3397822919347135\n",
      "iteration 6800 x1[-1.2882948  -1.28671549 -1.28834555 -1.28771336 -1.28807643] x2[-1.29575523 -1.29484484 -1.28944469 -1.29177023 -1.28928162] loss [0.33952202 0.33971152 0.33999553 0.33986673 0.34002876] losses 0.3398249140120311\n",
      "iteration 6810 x1[-1.28845404 -1.28652967 -1.28963375 -1.28833089 -1.2891598 ] x2[-1.29696923 -1.29545231 -1.29006653 -1.29237075 -1.28977487] loss [0.33941947 0.33968033 0.33984911 0.3397737  0.3399077 ] losses 0.3397260627092999\n",
      "iteration 6820 x1[-1.28786597 -1.28742189 -1.29011227 -1.287886   -1.289452  ] x2[-1.29678262 -1.29553012 -1.29146812 -1.29280348 -1.29081313] loss [0.33947834 0.3396058  0.33970584 0.33977514 0.33980607] losses 0.3396742371616973\n",
      "iteration 6830 x1[-1.28760792 -1.28847617 -1.29123203 -1.28743793 -1.29021487] x2[-1.29675892 -1.29660848 -1.29159925 -1.29277007 -1.2908276 ] loss [0.33949989 0.33944458 0.33961071 0.33981215 0.33974669] losses 0.33962280513352444\n",
      "iteration 6840 x1[-1.28860402 -1.28944939 -1.29202459 -1.28793427 -1.29073532] x2[-1.29735911 -1.29721476 -1.29236431 -1.29349508 -1.29162057] loss [0.33937909 0.33932534 0.33949282 0.33971921 0.33964683] losses 0.3395126582343995\n",
      "iteration 6850 x1[-1.28912762 -1.29147046 -1.29173662 -1.28782124 -1.29079583] x2[-1.29736365 -1.29785181 -1.29327375 -1.29390276 -1.29239763] loss [0.33933881 0.33912515 0.33944606 0.33969719 0.33958342] losses 0.3394381243962002\n",
      "iteration 6860 x1[-1.28827057 -1.29176947 -1.29240263 -1.2871101  -1.29132941] x2[-1.29767492 -1.2978746  -1.29417252 -1.29505586 -1.29346286] loss [0.33938118 0.33910093 0.33932834 0.33966529 0.33946265] losses 0.3393876778550883\n",
      "iteration 6870 x1[-1.28884145 -1.29267968 -1.29321237 -1.28689092 -1.29155027] x2[-1.2982922  -1.29799198 -1.29521381 -1.2947952  -1.29381871] loss [0.33929198 0.33902388 0.33918969 0.33970172 0.33941921] losses 0.3393252935611684\n",
      "iteration 6880 x1[-1.2884676  -1.29210472 -1.29278117 -1.2868201  -1.29138268] x2[-1.29890126 -1.29773306 -1.29439691 -1.29531679 -1.2933324 ] loss [0.3392756  0.33908614 0.33928305 0.33966808 0.33946843] losses 0.33935626059457485\n",
      "iteration 6890 x1[-1.28903506 -1.29232597 -1.29298795 -1.28751811 -1.29198475] x2[-1.29902548 -1.29861848 -1.29604419 -1.29446548 -1.29416507] loss [0.33922321 0.33900434 0.33914477 0.33967818 0.33936041] losses 0.33928218268167015\n",
      "iteration 6900 x1[-1.29008024 -1.29203204 -1.29396225 -1.28791161 -1.29220229] x2[-1.29947035 -1.29947835 -1.29782522 -1.29440126 -1.29529085] loss [0.33911118 0.33896336 0.33894021 0.33965277 0.33925988] losses 0.33918548026692924\n",
      "iteration 6910 x1[-1.29049558 -1.29252317 -1.29570252 -1.28722914 -1.29258766] x2[-1.30038346 -1.29933237 -1.2975636  -1.29497014 -1.29524221] loss [0.33901294 0.33893719 0.33883012 0.33966255 0.3392345 ] losses 0.33913545970519865\n",
      "iteration 6920 x1[-1.29075073 -1.29331494 -1.29585133 -1.28748782 -1.2926515 ] x2[-1.30035609 -1.29920037 -1.29732589 -1.29445754 -1.29489815] loss [0.33899567 0.3388876  0.3388366  0.33968111 0.33925536] losses 0.33913126662911985\n",
      "iteration 6930 x1[-1.29237237 -1.29491787 -1.29706699 -1.2888193  -1.29371878] x2[-1.30036264 -1.29794381 -1.29772098 -1.295201   -1.29541427] loss [0.33887323 0.33886035 0.33871781 0.3395233  0.33913682] losses 0.3390223037374131\n",
      "iteration 6940 x1[-1.29179552 -1.29414457 -1.29580226 -1.28873527 -1.29307269] x2[-1.30052427 -1.29836133 -1.29703181 -1.29410097 -1.29401488] loss [0.33890473 0.33888721 0.3388619  0.33961219 0.33928973] losses 0.3391111530188988\n",
      "iteration 6950 x1[-1.29123667 -1.2931824  -1.29670202 -1.28773079 -1.29297414] x2[-1.30144701 -1.29888901 -1.29695524 -1.29424891 -1.29370766] loss [0.33887962 0.33892032 0.33880104 0.3396781  0.33932016] losses 0.3391198485790231\n",
      "iteration 6960 x1[-1.29087277 -1.29323692 -1.29633082 -1.28723105 -1.29248417] x2[-1.30093264 -1.29855379 -1.29580504 -1.29467317 -1.29333108] loss [0.33894443 0.33894083 0.33891347 0.33968468 0.33938532] losses 0.33917374515288845\n",
      "iteration 6970 x1[-1.29172908 -1.2933642  -1.29655844 -1.28903957 -1.29314403] x2[-1.30182714 -1.29829782 -1.29516052 -1.29510188 -1.29259566] loss [0.33881504 0.33895012 0.33894446 0.33951388 0.33939098] losses 0.33912289493510384\n",
      "iteration 6980 x1[-1.291657   -1.29342964 -1.29587345 -1.28805904 -1.29234888] x2[-1.30284512 -1.30019073 -1.29574056 -1.29445995 -1.29249071] loss [0.33874684 0.33880669 0.33895211 0.33963705 0.33945879] losses 0.339120296909192\n",
      "iteration 6990 x1[-1.29251637 -1.29289099 -1.29550656 -1.28939949 -1.29248534] x2[-1.3024679  -1.29995425 -1.29536552 -1.29446409 -1.2923052 ] loss [0.33870971 0.33886419 0.33900717 0.33953418 0.33946249] losses 0.33911554691074636\n",
      "iteration 7000 x1[-1.29288683 -1.2925809  -1.29607206 -1.29009425 -1.29330759] x2[-1.30348811 -1.29988804 -1.29549167 -1.29602084 -1.29322258] loss [0.33860856 0.33889223 0.33895586 0.33936498 0.33933151] losses 0.3390306289451729\n",
      "iteration 7010 x1[-1.29338844 -1.29350575 -1.29678578 -1.29169204 -1.29473228] x2[-1.3017192  -1.29905946 -1.29501929 -1.29464015 -1.29275731] loss [0.33869874 0.33888366 0.33893815 0.33934695 0.33925978] losses 0.3390254582408364\n",
      "iteration 7020 x1[-1.29464321 -1.29380302 -1.29749487 -1.29202119 -1.29490183] x2[-1.30138988 -1.29910286 -1.29564395 -1.29482871 -1.29361061] loss [0.33862931 0.3388583  0.33883951 0.33930801 0.33918309] losses 0.3389636463817631\n",
      "iteration 7030 x1[-1.29431141 -1.29317299 -1.29634041 -1.2918741  -1.29444968] x2[-1.30078241 -1.2994501  -1.29488239 -1.2945571  -1.29320997] loss [0.33869799 0.33887993 0.33898127 0.33933941 0.33924689] losses 0.33902909917046004\n",
      "iteration 7040 x1[-1.29398152 -1.29131333 -1.29537237 -1.29203256 -1.29400447] x2[-1.30017222 -1.29877543 -1.29518943 -1.29382209 -1.29318817] loss [0.33876691 0.339069   0.33903023 0.33938251 0.33928183] losses 0.3391060969148071\n",
      "iteration 7050 x1[-1.29440961 -1.29102215 -1.29579889 -1.29217026 -1.2944741 ] x2[-1.30095869 -1.29848879 -1.29426817 -1.29357723 -1.29217565] loss [0.3386779  0.33911204 0.33906718 0.3393905  0.33932287] losses 0.3391140991077607\n",
      "iteration 7060 x1[-1.29544657 -1.29243753 -1.29559254 -1.29124743 -1.29355007] x2[-1.30188745 -1.29912857 -1.29520731 -1.29473578 -1.29303625] loss [0.33853388 0.33895854 0.33901255 0.33937342 0.33932731] losses 0.3390411401376617\n",
      "iteration 7070 x1[-1.29571277 -1.29176409 -1.29432636 -1.2922128  -1.29320209] x2[-1.30186819 -1.29958922 -1.29517349 -1.29433716 -1.29279101] loss [0.33851562 0.33897538 0.33910933 0.33933032 0.3393719 ] losses 0.3390605108061733\n",
      "iteration 7080 x1[-1.29535048 -1.29134276 -1.29416443 -1.29114603 -1.29262669] x2[-1.30184138 -1.30056377 -1.29483153 -1.2944134  -1.29262683] loss [0.33854431 0.3389359  0.3391469  0.33940522 0.33942758] losses 0.3390919798250653\n",
      "iteration 7090 x1[-1.29561424 -1.29161881 -1.29448136 -1.29272676 -1.29384235] x2[-1.30182107 -1.30052889 -1.295563   -1.29447686 -1.29314624] loss [0.3385263  0.33891768 0.33906879 0.33928116 0.33929713] losses 0.3390182123527937\n",
      "iteration 7100 x1[-1.29539719 -1.29119416 -1.29464571 -1.29333176 -1.29418518] x2[-1.30119586 -1.30027666 -1.29506425 -1.29378416 -1.29266898] loss [0.33858754 0.33896803 0.33909363 0.33928756 0.33930733] losses 0.33904882080981646\n",
      "iteration 7110 x1[-1.29611977 -1.29139272 -1.29493558 -1.29268968 -1.29327588] x2[-1.3013443  -1.29886589 -1.29488752 -1.29326083 -1.29213253] loss [0.33852348 0.33905637 0.33908519 0.33937511 0.33941599] losses 0.3390912286801524\n",
      "iteration 7120 x1[-1.29635163 -1.29034987 -1.29491365 -1.29313292 -1.29331543] x2[-1.30149611 -1.29939527 -1.29516313 -1.29337801 -1.29244637] loss [0.33849543 0.33909627 0.33906631 0.33933296 0.33938934] losses 0.33907606265252027\n",
      "iteration 7130 x1[-1.29594549 -1.2900983  -1.29565983 -1.29249306 -1.29351694] x2[-1.30150204 -1.30037576 -1.2948323  -1.29441505 -1.29291164] loss [0.33852491 0.33904355 0.33903545 0.33930338 0.33933917] losses 0.33904929158627456\n",
      "iteration 7140 x1[-1.2954083  -1.29156557 -1.29561795 -1.29202634 -1.2935556 ] x2[-1.30150262 -1.29971465 -1.29545689 -1.29494774 -1.29375834] loss [0.33856452 0.33898114 0.33899211 0.33929874 0.3392727 ] losses 0.3390218419561837\n",
      "iteration 7150 x1[-1.29551378 -1.2925249  -1.29620751 -1.29235156 -1.29437731] x2[-1.3010513  -1.30041656 -1.29682703 -1.29422512 -1.29419121] loss [0.3385894  0.33885787 0.33884702 0.33932825 0.3391788 ] losses 0.338960266839696\n",
      "iteration 7160 x1[-1.29546183 -1.29407843 -1.29709958 -1.2926473  -1.29516637] x2[-1.30093256 -1.29958747 -1.29619487 -1.29429751 -1.29401937] loss [0.33860185 0.33880235 0.33882786 0.33930056 0.33913279] losses 0.3389330805462487\n",
      "iteration 7170 x1[-1.29588    -1.29405742 -1.29935379 -1.29323353 -1.29685707] x2[-1.30052617 -1.2994861  -1.29604981 -1.29361149 -1.29378378] loss [0.33860045 0.33881132 0.33867326 0.33930788 0.33902496] losses 0.3388835730581498\n",
      "iteration 7180 x1[-1.29645328 -1.29487871 -1.29987005 -1.29412653 -1.29736263] x2[-1.30121772 -1.29918098 -1.29793497 -1.29402321 -1.29503144] loss [0.33850808 0.33877257 0.33849709 0.3392101  0.33889469] losses 0.33877650627376027\n",
      "iteration 7190 x1[-1.29703092 -1.29584441 -1.30086069 -1.29470823 -1.29834454] x2[-1.30111271 -1.29780842 -1.29763231 -1.29535941 -1.2954981 ] loss [0.33847323 0.33880161 0.33844739 0.33906701 0.33878789] losses 0.33871542684540484\n",
      "iteration 7200 x1[-1.29603511 -1.29476002 -1.30107391 -1.2955692  -1.29946024] x2[-1.30118077 -1.296801   -1.29860492 -1.29590882 -1.2965948 ] loss [0.33854155 0.33895631 0.33836092 0.3389622  0.33862531] losses 0.3386892569485923\n",
      "iteration 7210 x1[-1.29552934 -1.29492667 -1.30115223 -1.29548359 -1.29993853] x2[-1.30077899 -1.29751741 -1.29909687 -1.29520566 -1.29658674] loss [0.338608   0.33889107 0.33831944 0.33902076 0.33859107] losses 0.3386860674137378\n",
      "iteration 7220 x1[-1.29599005 -1.29565234 -1.30092082 -1.29417757 -1.29893772] x2[-1.30207087 -1.29750293 -1.29910649 -1.29528502 -1.29603394] loss [0.33848056 0.3388383  0.33833546 0.33911214 0.33870482] losses 0.33869425561428396\n",
      "iteration 7230 x1[-1.29627995 -1.29565577 -1.30068473 -1.29506824 -1.29896305] x2[-1.30179641 -1.29734397 -1.29832386 -1.29536711 -1.29563959] loss [0.33847902 0.33884975 0.33840957 0.33903963 0.33873212] losses 0.3387020171766567\n",
      "iteration 7240 x1[-1.29747612 -1.29764572 -1.30090873 -1.29547319 -1.29913904] x2[-1.30091508 -1.29659011 -1.29757079 -1.29561087 -1.29557519] loss [0.33845489 0.33875848 0.33844841 0.33899143 0.33872402] losses 0.3386754455169471\n",
      "iteration 7250 x1[-1.29755941 -1.29772595 -1.30128233 -1.29465769 -1.29871164] x2[-1.30145287 -1.29487267 -1.29791961 -1.29722452 -1.29650996] loss [0.33840991 0.33887973 0.33839588 0.33893266 0.33868623] losses 0.3386608829249492\n",
      "iteration 7260 x1[-1.29779202 -1.29762185 -1.30101704 -1.29465696 -1.29815034] x2[-1.30197841 -1.29420819 -1.2971928  -1.29832806 -1.29642242] loss [0.338355   0.33893685 0.33846828 0.33885152 0.3387338 ] losses 0.33866908922571165\n",
      "iteration 7270 x1[-1.2990959  -1.29805301 -1.30028487 -1.29575429 -1.29768793] x2[-1.30233278 -1.29486851 -1.29693638 -1.29865441 -1.29626474] loss [0.3382345  0.338856   0.33854018 0.33874622 0.33877939] losses 0.3386312584871764\n",
      "iteration 7280 x1[-1.29990299 -1.2971625  -1.29881804 -1.29559941 -1.296406  ] x2[-1.30161341 -1.29397005 -1.29820936 -1.29881763 -1.29733066] loss [0.33822769 0.33898848 0.33855365 0.33874573 0.33879524] losses 0.3386621578126321\n",
      "iteration 7290 x1[-1.29988501 -1.29705164 -1.29833606 -1.29575096 -1.29625562] x2[-1.30123284 -1.29277064 -1.2977441  -1.30067576 -1.2983578 ] loss [0.33825641 0.33908644 0.33862296 0.33859912 0.3387309 ] losses 0.3386591657868994\n",
      "iteration 7300 x1[-1.29985858 -1.29738797 -1.29709805 -1.2959259  -1.29566352] x2[-1.30146408 -1.29361345 -1.29806294 -1.30155737 -1.29920765] loss [0.33824166 0.33899848 0.33869043 0.33852236 0.33871247] losses 0.3386330801794614\n",
      "iteration 7310 x1[-1.30076509 -1.2986553  -1.29744456 -1.29641556 -1.29602168] x2[-1.30138474 -1.29374939 -1.29805998 -1.30102998 -1.2988715 ] loss [0.33818182 0.3388951  0.33866517 0.33852445 0.33871057] losses 0.33859542228236184\n",
      "iteration 7320 x1[-1.30027528 -1.29850873 -1.29701107 -1.29626732 -1.29589418] x2[-1.30130916 -1.29443117 -1.29774833 -1.3005204  -1.29831677] loss [0.33822265 0.33885505 0.33871992 0.33857231 0.33876062] losses 0.33862610971745105\n",
      "iteration 7330 x1[-1.30056    -1.29966019 -1.29702751 -1.29642358 -1.29598654] x2[-1.30092673 -1.29317771 -1.29683642 -1.30048909 -1.29786148] loss [0.33822965 0.33886422 0.3387858  0.33856307 0.3387872 ] losses 0.3386459896475406\n",
      "iteration 7340 x1[-1.30054346 -1.29972571 -1.29797122 -1.29658585 -1.29654144] x2[-1.30147996 -1.29479992 -1.29794742 -1.30045426 -1.29856643] loss [0.33819097 0.33873863 0.33863478 0.33855365 0.33869454] losses 0.3385625141869805\n",
      "iteration 7350 x1[-1.29961253 -1.29973316 -1.29845054 -1.29610874 -1.29685618] x2[-1.30156915 -1.29693571 -1.29873053 -1.29919698 -1.2984137 ] loss [0.33825193 0.33858034 0.3385424  0.33868036 0.33868253] losses 0.33854751112066017\n",
      "iteration 7360 x1[-1.30118512 -1.30154882 -1.29831402 -1.29687857 -1.29694125] x2[-1.30166737 -1.29718699 -1.29949918 -1.30058718 -1.29980233] loss [0.3381312  0.33843026 0.33849634 0.33852249 0.3385749 ] losses 0.3384310398697762\n",
      "iteration 7370 x1[-1.30072133 -1.30100782 -1.29912296 -1.29624174 -1.29718386] x2[-1.3016362  -1.29682111 -1.30025164 -1.29965239 -1.29962325] loss [0.33816688 0.33849623 0.33838269 0.33863732 0.33857011] losses 0.33845064693941784\n",
      "iteration 7380 x1[-1.30101134 -1.30101085 -1.29929535 -1.29635701 -1.29747465] x2[-1.30321828 -1.29882263 -1.30080939 -1.29979908 -1.29974791] loss [0.33803259 0.33834961 0.33832978 0.33861814 0.3385397 ] losses 0.33837396396068203\n",
      "iteration 7390 x1[-1.2997355  -1.30128304 -1.29771297 -1.29520738 -1.29638882] x2[-1.30430577 -1.30075633 -1.30176534 -1.30037787 -1.30015196] loss [0.33804712 0.33818978 0.33837613 0.33866094 0.33859012] losses 0.33837281871352076\n",
      "iteration 7400 x1[-1.30011499 -1.30026381 -1.29850397 -1.2952592  -1.2966413 ] x2[-1.3043388  -1.30147872 -1.30253435 -1.30122581 -1.30111836] loss [0.33801736 0.33821127 0.33826308 0.33859558 0.33850144] losses 0.33831774505840484\n",
      "iteration 7410 x1[-1.29946321 -1.30037008 -1.29884185 -1.29487862 -1.29696806] x2[-1.30350848 -1.30203643 -1.30244484 -1.30102004 -1.30134318] loss [0.33812366 0.33816347 0.33824492 0.33863866 0.33846118] losses 0.33832637900935925\n",
      "iteration 7420 x1[-1.30026828 -1.29931136 -1.29917915 -1.29565353 -1.29728773] x2[-1.30358386 -1.30091291 -1.30279035 -1.30126366 -1.30149092] loss [0.33806006 0.33832113 0.33819563 0.3385637  0.33842706] losses 0.3383135165938363\n",
      "iteration 7430 x1[-1.30106085 -1.29950314 -1.29981478 -1.29569793 -1.29754103] x2[-1.30350295 -1.30046161 -1.30341452 -1.30121957 -1.30185821] loss [0.33800872 0.33833984 0.33810492 0.33856361 0.33838201] losses 0.3382798204973551\n",
      "iteration 7440 x1[-1.30125928 -1.30071989 -1.29958115 -1.29602978 -1.29794095] x2[-1.30402164 -1.30176646 -1.30388695 -1.30161794 -1.3025097 ] loss [0.33795751 0.33815762 0.33808811 0.33851033 0.33830591] losses 0.33820389469940293\n",
      "iteration 7450 x1[-1.30071965 -1.30017004 -1.29963367 -1.2963474  -1.29832012] x2[-1.30294361 -1.30211364 -1.30276446 -1.30100263 -1.30177542] loss [0.33807323 0.33817239 0.33816453 0.33853144 0.33833106] losses 0.3382545308572579\n",
      "iteration 7460 x1[-1.30032573 -1.29891797 -1.29896726 -1.29737427 -1.2985467 ] x2[-1.30362055 -1.30280104 -1.30341615 -1.30170409 -1.30244007] loss [0.33805329 0.33821383 0.33816623 0.33840534 0.33826674] losses 0.33822108650003085\n",
      "iteration 7470 x1[-1.30039168 -1.29937634 -1.29790039 -1.29795052 -1.29827187] x2[-1.30369398 -1.30339028 -1.30375198 -1.30254441 -1.30316554] loss [0.3380433  0.3381384  0.33821987 0.33830271 0.33823473] losses 0.3381878024461155\n",
      "iteration 7480 x1[-1.30060674 -1.29997226 -1.29759864 -1.29765812 -1.29787485] x2[-1.30434473 -1.30338828 -1.30378186 -1.30234726 -1.30299133] loss [0.33798148 0.3380954  0.33823976 0.33833824 0.33827617] losses 0.33818620938747246\n",
      "iteration 7490 x1[-1.30139992 -1.30004515 -1.29788163 -1.29883323 -1.29829008] x2[-1.3045597  -1.30412836 -1.30482714 -1.30318482 -1.30413513] loss [0.33790919 0.33803737 0.33814461 0.33819251 0.33816413] losses 0.33808956219726727\n",
      "iteration 7500 x1[-1.30058317 -1.29940616 -1.29744659 -1.29953751 -1.29855925] x2[-1.30520738 -1.30419059 -1.30528421 -1.30300448 -1.30418109] loss [0.33792199 0.33807915 0.33814387 0.33815431 0.33814128] losses 0.33808811699618696\n",
      "iteration 7510 x1[-1.30094996 -1.29999728 -1.29704215 -1.30051011 -1.29904687] x2[-1.30423837 -1.30317673 -1.30615172 -1.30196087 -1.30444012] loss [0.33796434 0.33810871 0.33811193 0.33815879 0.33808743] losses 0.33808623847187425\n",
      "iteration 7520 x1[-1.30086298 -1.29955631 -1.29767895 -1.30057112 -1.29937486] x2[-1.30461178 -1.30320418 -1.30641979 -1.30182434 -1.30426071] loss [0.33794407 0.33813866 0.33804654 0.33816419 0.33807642] losses 0.33807397726106514\n",
      "iteration 7530 x1[-1.30195812 -1.29972841 -1.2981673  -1.30209444 -1.300288  ] x2[-1.30554982 -1.30328772 -1.30697482 -1.30243006 -1.3046055 ] loss [0.33779914 0.33812022 0.33797189 0.33801116 0.33798592] losses 0.33797766823987196\n",
      "iteration 7540 x1[-1.3018601  -1.29981638 -1.29849838 -1.30343259 -1.3012521 ] x2[-1.30473213 -1.30206859 -1.30682181 -1.30217121 -1.30454219] loss [0.33786398 0.33820122 0.33795863 0.33793406 0.33792105] losses 0.33797578888189894\n",
      "iteration 7550 x1[-1.3017649  -1.30054205 -1.29897847 -1.30313583 -1.30154327] x2[-1.30510369 -1.3027109  -1.30682344 -1.30264748 -1.30498744] loss [0.33784449 0.33810269 0.33792373 0.33792115 0.3378686 ] losses 0.3379321334269107\n",
      "iteration 7560 x1[-1.30285076 -1.30162784 -1.29842449 -1.30330111 -1.30088454] x2[-1.30546921 -1.3033509  -1.30682692 -1.30311664 -1.30542688] loss [0.33774113 0.33797883 0.33796363 0.33787589 0.33788478] losses 0.3378888523562896\n",
      "iteration 7570 x1[-1.30274029 -1.30175345 -1.29918629 -1.30375647 -1.30148238] x2[-1.30467678 -1.30383933 -1.30625566 -1.3030032  -1.30542092] loss [0.33780501 0.33793502 0.3379487  0.33785157 0.3378423 ] losses 0.33787652241160265\n",
      "iteration 7580 x1[-1.30278165 -1.30188475 -1.29979817 -1.30419463 -1.30207154] x2[-1.30461921 -1.30358634 -1.30483587 -1.3034651  -1.30498074] loss [0.33780614 0.33794362 0.33800492 0.33778757 0.33783125] losses 0.3378747022226331\n",
      "iteration 7590 x1[-1.30295625 -1.30193876 -1.2997967  -1.30418435 -1.30213396] x2[-1.30370028 -1.30326611 -1.30637682 -1.30246324 -1.30550191] loss [0.33785892 0.33796258 0.33789606 0.33785971 0.33778995] losses 0.3378734418461383\n",
      "iteration 7600 x1[-1.30355778 -1.30154177 -1.30052821 -1.30357789 -1.30204226] x2[-1.30398733 -1.30332829 -1.30686675 -1.30280267 -1.30565636] loss [0.33779569 0.33798662 0.3378089  0.33787858 0.33778561] losses 0.33785107913229684\n",
      "iteration 7610 x1[-1.30385603 -1.30247063 -1.30225842 -1.30445684 -1.30356147] x2[-1.30426635 -1.30303062 -1.30516664 -1.30269478 -1.30442913] loss [0.33775471 0.3379413  0.33780475 0.33782385 0.3377641 ] losses 0.33781774063469167\n",
      "iteration 7620 x1[-1.30400169 -1.30264441 -1.30306297 -1.30400629 -1.30372885] x2[-1.30397253 -1.30326613 -1.30629738 -1.30244694 -1.30506504] loss [0.33776521 0.33791208 0.33766771 0.33787352 0.33770723] losses 0.3377851504867276\n",
      "iteration 7630 x1[-1.30503506 -1.30297285 -1.30472005 -1.30372304 -1.30404332] x2[-1.30500804 -1.30459359 -1.30683563 -1.3032302  -1.30577274] loss [0.33761883 0.33779433 0.33751262 0.33783778 0.33763504] losses 0.3376797183486816\n",
      "iteration 7640 x1[-1.3049027  -1.30418966 -1.30474951 -1.30346603 -1.30407426] x2[-1.30500867 -1.30459183 -1.30678227 -1.30370286 -1.30602265] loss [0.33762812 0.33770801 0.33751427 0.33782242 0.33761527] losses 0.33765761980355746\n",
      "iteration 7650 x1[-1.30506479 -1.30530102 -1.3044914  -1.30306447 -1.30359853] x2[-1.30486385 -1.30395044 -1.30628145 -1.30285116 -1.30517006] loss [0.33762691 0.33767486 0.3375676  0.3379117  0.33770906] losses 0.3376980252135577\n",
      "iteration 7660 x1[-1.30507542 -1.30616267 -1.30596663 -1.30238211 -1.30421137] x2[-1.30517574 -1.30391709 -1.30594118 -1.30362361 -1.30520909] loss [0.33760415 0.33761656 0.33748761 0.33790537 0.33766286] losses 0.33765530932669635\n",
      "iteration 7670 x1[-1.30408112 -1.30628906 -1.30696739 -1.30186993 -1.30466791] x2[-1.30590873 -1.3050642  -1.30548566 -1.30436153 -1.30525876] loss [0.3376228  0.33752665 0.3374495  0.33788956 0.33762707] losses 0.3376231168536781\n",
      "iteration 7680 x1[-1.30457245 -1.3053315  -1.30793456 -1.30225098 -1.30533413] x2[-1.30502262 -1.30457603 -1.30579006 -1.30420538 -1.30575554] loss [0.33765047 0.33762843 0.3373607  0.33787338 0.33754511] losses 0.3376116175462062\n",
      "iteration 7690 x1[-1.30373379 -1.30432151 -1.30844971 -1.30086183 -1.30517964] x2[-1.30489169 -1.30467311 -1.30595035 -1.30303026 -1.30536462] loss [0.33771913 0.33769292 0.33731367 0.33805679 0.3375835 ] losses 0.3376732010455162\n",
      "iteration 7700 x1[-1.30452038 -1.30442376 -1.30850972 -1.30081026 -1.30508971] x2[-1.30577956 -1.30594132 -1.30625998 -1.30376459 -1.30585525] loss [0.33760081 0.33759627 0.33728785 0.3380081  0.33755531] losses 0.33760966937462594\n",
      "iteration 7710 x1[-1.30559208 -1.30447391 -1.30829244 -1.30151063 -1.30509021] x2[-1.30651799 -1.30614908 -1.30729186 -1.30405701 -1.30647659] loss [0.33747347 0.33757813 0.33723093 0.33793695 0.33751167] losses 0.3375462301090117\n",
      "iteration 7720 x1[-1.30620892 -1.30569187 -1.30793127 -1.30075138 -1.30451456] x2[-1.30636823 -1.30606756 -1.30697364 -1.30363574 -1.30592204] loss [0.33744067 0.33749803 0.33727817 0.33802153 0.33759121] losses 0.3375659206957323\n",
      "iteration 7730 x1[-1.30681082 -1.30694053 -1.30800993 -1.30045281 -1.30445367] x2[-1.30696613 -1.30608555 -1.30679325 -1.30351908 -1.3055911 ] loss [0.33735675 0.33740928 0.33728529 0.33805136 0.33761879] losses 0.3375442960354734\n",
      "iteration 7740 x1[-1.30813101 -1.30684059 -1.30750183 -1.30148747 -1.30425639] x2[-1.30668726 -1.3048723  -1.3063218  -1.30442175 -1.30591456] loss [0.33728428 0.33750154 0.33735358 0.3379127  0.33760998] losses 0.3375324158764331\n",
      "iteration 7750 x1[-1.30882634 -1.30680571 -1.307591   -1.30221186 -1.30428982] x2[-1.307144   -1.30331566 -1.30674307 -1.30474274 -1.30631769] loss [0.33720424 0.33761408 0.33731793 0.33783807 0.3375793 ] losses 0.3375107237553543\n",
      "iteration 7760 x1[-1.30861961 -1.3060915  -1.30709405 -1.30190637 -1.30381723] x2[-1.30730131 -1.30273924 -1.30642877 -1.30506627 -1.30606003] loss [0.3372076  0.33770522 0.33737453 0.33783701 0.33763085] losses 0.33755104434267\n",
      "iteration 7770 x1[-1.30841544 -1.30545729 -1.30705026 -1.30205498 -1.30387454] x2[-1.30729241 -1.30180405 -1.30698624 -1.30552067 -1.30675025] loss [0.33722237 0.33781669 0.33733863 0.33779427 0.33757835] losses 0.33755006298500473\n",
      "iteration 7780 x1[-1.30937731 -1.30651398 -1.30672443 -1.30277772 -1.30371531] x2[-1.30714367 -1.30234069 -1.30637549 -1.30596706 -1.30655076] loss [0.3371662  0.33770392 0.33740408 0.33771124 0.33760361] losses 0.33751780927387015\n",
      "iteration 7790 x1[-1.30856632 -1.30542725 -1.3075546  -1.30218947 -1.3039283 ] x2[-1.30816214 -1.30178693 -1.30606785 -1.30685154 -1.30629804] loss [0.33715152 0.33782004 0.33736768 0.33769101 0.33760626] losses 0.3375273021652606\n",
      "iteration 7800 x1[-1.30735125 -1.30545095 -1.30778105 -1.30016994 -1.30333867] x2[-1.30914053 -1.30188941 -1.30591614 -1.30696186 -1.30597158] loss [0.33716811 0.33781104 0.33736254 0.33782799 0.33767103] losses 0.33756814060296864\n",
      "iteration 7810 x1[-1.30646701 -1.30483188 -1.30754619 -1.29936283 -1.3031115 ] x2[-1.30876804 -1.30263747 -1.30634635 -1.30661679 -1.30615306] loss [0.33725548 0.33780137 0.33734877 0.33791048 0.3376744 ] losses 0.3375981009292597\n",
      "iteration 7820 x1[-1.30706225 -1.30474361 -1.30732317 -1.29972976 -1.30266965] x2[-1.30811286 -1.30321413 -1.30617154 -1.30627335 -1.30588473] loss [0.33725938 0.33776653 0.33737655 0.33790818 0.33772474] losses 0.33760707627887154\n",
      "iteration 7830 x1[-1.30763484 -1.30429322 -1.30783006 -1.30066376 -1.30347396] x2[-1.30778014 -1.3038505  -1.30614432 -1.30507329 -1.30526215] loss [0.33724264 0.3377532  0.33734315 0.33792568 0.33771141] losses 0.3375952155728276\n",
      "iteration 7840 x1[-1.30790392 -1.30482091 -1.30758901 -1.30114414 -1.30331334] x2[-1.30803944 -1.30512045 -1.30656676 -1.30594574 -1.30605036] loss [0.33720594 0.33762601 0.33733038 0.33782951 0.33766728] losses 0.3375318240076782\n",
      "iteration 7850 x1[-1.30758459 -1.30535113 -1.30708081 -1.30146166 -1.30345506] x2[-1.308738   -1.30447536 -1.30610633 -1.30695956 -1.3060941 ] loss [0.33717972 0.33763416 0.33739803 0.33773544 0.33765414] losses 0.3375202976092531\n",
      "iteration 7860 x1[-1.30626356 -1.30456118 -1.30602877 -1.3006114  -1.30258997] x2[-1.30926338 -1.30603004 -1.30796748 -1.3073599  -1.30743824] loss [0.33723542 0.33758032 0.33734168 0.33776832 0.33762137] losses 0.3375094230990342\n",
      "iteration 7870 x1[-1.30572202 -1.30489505 -1.30748913 -1.29935874 -1.30299582] x2[-1.31021348 -1.30667839 -1.3083263  -1.30831626 -1.30787166] loss [0.33720776 0.33751129 0.33721486 0.33779156 0.33756224] losses 0.3374575413322448\n",
      "iteration 7880 x1[-1.30578815 -1.30501251 -1.30788334 -1.30004708 -1.3036114 ] x2[-1.30982934 -1.30659307 -1.30768846 -1.30835723 -1.30786359] loss [0.3372296  0.33750899 0.33723174 0.3377391  0.33751915] losses 0.33744571561206055\n",
      "iteration 7890 x1[-1.3060044  -1.30382503 -1.30739692 -1.30057361 -1.30348763] x2[-1.30974183 -1.30714905 -1.30779382 -1.30869474 -1.30807625] loss [0.33722051 0.33755393 0.33725824 0.33767774 0.33751309] losses 0.33744470107069896\n",
      "iteration 7900 x1[-1.30576414 -1.30404962 -1.30808569 -1.30005918 -1.30372896] x2[-1.30921653 -1.3065105  -1.30761032 -1.30787176 -1.30771175] loss [0.3372736  0.33758276 0.33722313 0.33777217 0.33752142] losses 0.33747461313122135\n",
      "iteration 7910 x1[-1.30655099 -1.30353548 -1.30802502 -1.30129895 -1.30410062] x2[-1.30943561 -1.30691289 -1.30699455 -1.30764757 -1.30691648] loss [0.33720346 0.33759098 0.3372702  0.33769888 0.3375507 ] losses 0.3374628440534177\n",
      "iteration 7920 x1[-1.30731654 -1.30420566 -1.3078245  -1.30177991 -1.30417488] x2[-1.30921645 -1.30642911 -1.3078487  -1.30758813 -1.30731509] loss [0.33716528 0.33757743 0.33722469 0.33766864 0.33751758] losses 0.33743072480059677\n",
      "iteration 7930 x1[-1.30703765 -1.30289458 -1.30690538 -1.30138097 -1.30302081] x2[-1.30930373 -1.30726406 -1.30911373 -1.30724267 -1.30813552] loss [0.33717865 0.33761189 0.33720099 0.33772136 0.33754207] losses 0.33745099146159263\n",
      "iteration 7940 x1[-1.30647692 -1.30233956 -1.30646203 -1.30171151 -1.30321259] x2[-1.30967094 -1.30764034 -1.3082997  -1.30835487 -1.30819872] loss [0.33719239 0.33762507 0.3372883  0.33761999 0.33752406] losses 0.33744996156351936\n",
      "iteration 7950 x1[-1.30783075 -1.30319888 -1.30704835 -1.30204848 -1.30347645] x2[-1.30930519 -1.30822382 -1.30866981 -1.30886688 -1.30891968] loss [0.33712345 0.33752328 0.33722174 0.33756031 0.33745523] losses 0.33737680156965766\n",
      "iteration 7960 x1[-1.30768392 -1.30317255 -1.30633787 -1.30355374 -1.30404977] x2[-1.30954819 -1.30887513 -1.30933308 -1.30966557 -1.30984764] loss [0.33711688 0.33747985 0.33722542 0.33739809 0.33735047] losses 0.3373141406607457\n",
      "iteration 7970 x1[-1.30697976 -1.30288967 -1.30695735 -1.303132   -1.30460854] x2[-1.30948235 -1.31051859 -1.30926235 -1.30928673 -1.30974553] loss [0.33717036 0.3373862  0.3371871  0.33745417 0.33731816] losses 0.3373031966032741\n",
      "iteration 7980 x1[-1.30701425 -1.30334047 -1.30538259 -1.30328928 -1.30383525] x2[-1.30884271 -1.30972166 -1.30918595 -1.30876392 -1.30912733] loss [0.33721215 0.33740929 0.33730245 0.3374793  0.33741545] losses 0.33736373026625877\n",
      "iteration 7990 x1[-1.30790251 -1.3029688  -1.30573699 -1.30400337 -1.30416341] x2[-1.30793044 -1.30959999 -1.30909465 -1.30768879 -1.30874304] loss [0.3372136  0.33744404 0.33728393 0.33750361 0.33741894] losses 0.33737282326005824\n",
      "Training took: 2.778535842895508s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.linalg as la\n",
    "from util import Trainer   \n",
    "import networkx \n",
    "import time\n",
    "import math\n",
    "# from scipy.sparse import isspmatrix\n",
    "# from scipy.special import expit as sigmoid\n",
    "# from constants import INIT_WEIGHT_STD\n",
    "from parameters import Parameters\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "def qsgd_quantize(x, d, is_biased):\n",
    "    norm = np.sqrt(np.sum(np.square(x)))\n",
    "    if norm <= 0.1: #norm cannot be zero\n",
    "        norm = 0.1\n",
    "    level_float = d * np.abs(x) / norm\n",
    "    previous_level = np.floor(level_float)\n",
    "    is_next_level = np.random.rand(*x.shape) < (level_float - previous_level)\n",
    "    new_level = previous_level + is_next_level\n",
    "    scale = 1\n",
    "    if is_biased:\n",
    "        n = len(x)\n",
    "        scale = 1. / (np.minimum(n / d ** 2, np.sqrt(n) / d) + 1.)\n",
    "    return scale * np.sign(x) * norm * new_level / d\n",
    "\n",
    "def qsgd_quantize_1(x, d, is_biased):   # d quantization level\n",
    "    norm = np.sqrt(np.sum(np.square(x)))\n",
    "    if norm <= 0.1: #norm cannot be zero\n",
    "        norm = 0.1\n",
    "    level_float_1 = 2*d * x /  norm\n",
    "    previous_level_1 = np.floor(level_float_1)\n",
    "    previous_level_2 = np.where(previous_level_1 % 2 == 0, previous_level_1 - 1, previous_level_1)\n",
    "    is_next_level_1 = (2*np.random.rand(*x.shape)) < (level_float_1 - previous_level_2)\n",
    "    new_level_1 = previous_level_2 + (2*is_next_level_1)\n",
    "    scale = 1\n",
    "    if is_biased:\n",
    "        n = len(x)\n",
    "        scale = 1. / (np.minimum(n / d ** 2, np.sqrt(n) / d) + 1.)\n",
    "    return scale *  norm * new_level_1 / (2*d)\n",
    "\n",
    "\n",
    "def logistic_loss(x, l2):\n",
    "    Z = np.log(1+np.exp(-np.prod(x, axis=0)))\n",
    "    a = l2/2 * (la.norm(x, axis=0))**2  \n",
    "    return Z+a\n",
    "\n",
    "def logistic_gradient(x, l2, normalize=True):# x is a vector for an agent\n",
    "    grad_1 = (- x[1]) / (1+np.exp(np.prod(x)))+l2*x[0]\n",
    "    grad_2 = (- x[0]) / (1+np.exp(np.prod(x)))+l2*x[1]\n",
    "    grad = [grad_1, grad_2]\n",
    "    # if normalize:\n",
    "    #     return grad\n",
    "    return grad\n",
    "\n",
    "\n",
    "\n",
    "class Parameters:\n",
    "    \"\"\"\n",
    "    Parameters class used for all the experiments, redefine a string representation to summarize the experiment\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 t_0=0,\n",
    "                 num_iterations=15000,\n",
    "                 num_epoch=1,\n",
    "                 lr_type='constant',\n",
    "                 initial_lr=1,\n",
    "                 regularizer= 1,\n",
    "                 lr_alpha = 0.62,\n",
    "                 lr_beta = 0.94,\n",
    "                 lr_ck = 1,\n",
    "            \n",
    "                 epoch_decay_lr=None,\n",
    "                 consensus_lr=None,\n",
    "                 quantization=\"qsgd-unbiased\",\n",
    "                 # number of coordinates k in top-k or random-k quantization\n",
    "                 coordinates_to_keep=None,\n",
    "                 # number of levels in qsgd quantization\n",
    "                 num_levels=10,\n",
    "                 estimate='final',\n",
    "                 name=None,\n",
    "                 # number of machines\n",
    "                 n_cores=5,\n",
    "                 topology='connected',\n",
    "                 method='sample-hold',\n",
    "                 distribute_data=False,\n",
    "                 # whether each machine gets random data or continuous set of data\n",
    "                 # might not have any difference, depends on the dataset\n",
    "                 split_data_strategy=None,\n",
    "                 tau=None,\n",
    "                 real_update_every=1,\n",
    "                 random_seed=None,\n",
    "                 split_data_random_seed=None,\n",
    "                 ):\n",
    "        # a lot of sanity checks to fail fast if we have inconsistent parameters\n",
    "        assert num_epoch >= 0\n",
    "        assert lr_type in ['constant', 'epoch-decay', 'decay', 'sample-hold', 'bottou',]\n",
    "\n",
    "        if lr_type in ['constant', 'decay']:\n",
    "            assert initial_lr > 0\n",
    "        if lr_type == 'decay':\n",
    "            assert initial_lr and tau\n",
    "            assert regularizer > 0\n",
    "        if lr_type == 'epoch-decay':\n",
    "            assert epoch_decay_lr is not None\n",
    "        if lr_type == 'sample-hold':    \n",
    "            assert t_0 and initial_lr\n",
    "            assert regularizer > 0\n",
    "            \n",
    "        if method in ['choco']:\n",
    "            assert consensus_lr > 0\n",
    "        else:\n",
    "            assert consensus_lr is None\n",
    "\n",
    "        assert quantization in ['full', 'top', 'random-biased', 'random-unbiased',\n",
    "                                'qsgd-biased', 'qsgd-unbiased']\n",
    "        if quantization == 'full':\n",
    "            assert not coordinates_to_keep\n",
    "        elif quantization in ['top', 'random-biased', 'random-unbiased']:\n",
    "            assert coordinates_to_keep > 0\n",
    "        else:\n",
    "            assert num_levels > 0\n",
    "\n",
    "        assert estimate in ['final', 'mean', 't+tau', '(t+tau)^2']\n",
    "\n",
    "        assert n_cores > 0\n",
    "\n",
    "        assert topology in ['connected','centralized', 'ring', 'torus', 'disconnected']\n",
    "\n",
    "        assert method in ['sample-hold','choco', 'dcd-psgd', 'ecd-psgd', 'plain']\n",
    "        if method in ['dcd-psgd', 'ecd-psgd']:\n",
    "            assert quantization in ['random-unbiased', 'qsgd-unbiased']\n",
    "\n",
    "        if not distribute_data:\n",
    "            assert not split_data_strategy\n",
    "        else:\n",
    "            assert split_data_strategy in ['naive', 'random', 'label-sorted']\n",
    "        \n",
    "        self.t_0 = t_0\n",
    "        self.num_epoch = num_epoch\n",
    "        self.num_iterations=num_iterations\n",
    "        self.lr_type = lr_type\n",
    "        self.initial_lr = initial_lr  \n",
    "        self.regularizer = regularizer   \n",
    "        self.epoch_decay_lr = epoch_decay_lr\n",
    "        self.lr_alpha = lr_alpha\n",
    "        self.lr_beta = lr_beta\n",
    "        self.lr_ck = lr_ck \n",
    "        self.consensus_lr = consensus_lr\n",
    "        self.quantization = quantization\n",
    "        self.coordinates_to_keep = coordinates_to_keep\n",
    "        self.num_levels = num_levels\n",
    "        self.estimate = estimate\n",
    "        self.name = name\n",
    "        self.n_cores = n_cores\n",
    "        self.topology = topology\n",
    "        self.tau = tau\n",
    "        self.real_update_every = real_update_every\n",
    "        self.random_seed = random_seed\n",
    "        self.method = method\n",
    "        self.distribute_data = distribute_data\n",
    "        self.split_data_strategy = split_data_strategy\n",
    "        self.split_data_random_seed = split_data_random_seed\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.name:\n",
    "            return self.name\n",
    "\n",
    "        lr_str = self.lr_str()\n",
    "        sparse_str = self.sparse_str()\n",
    "\n",
    "        reg_str = \"\"\n",
    "        if self.regularizer:\n",
    "            reg_str = \"-reg{}\".format(self.regularizer)\n",
    "\n",
    "        return \"epoch{}-{}{}-{}-{}\".format(self.num_epoch, lr_str, reg_str, sparse_str, self.estimate)\n",
    "\n",
    "    def lr_str(self):\n",
    "        lr_str = \"\"\n",
    "        if self.lr_type == 'constant':\n",
    "            lr_str = \"lr{}\".format(self.initial_lr)\n",
    "        elif self.lr_type == 'decay':\n",
    "            lr_str = \"lr{}decay{}\".format(self.initial_lr, self.epoch_decay_lr)\n",
    "        elif self.lr_type == 'custom':\n",
    "            lr_str = \"lr{}/lambda*(t+{})\".format(self.initial_lr, self.tau)\n",
    "        elif self.lr_type == 'bottou':\n",
    "            lr_str = \"lr-bottou-{}\".format(self.initial_lr)\n",
    "        else:\n",
    "            lr_str = \"lr-{}\".format(self.lr_type)\n",
    "\n",
    "        return lr_str\n",
    "\n",
    "    def sparse_str(self):\n",
    "        sparse_str = self.quantization\n",
    "        if self.quantization != 'full':\n",
    "            sparse_str += \"{}\".format(self.coordinates_to_keep)\n",
    "        return sparse_str\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Parameter('{}')\".format(str(self))\n",
    "    \n",
    "\n",
    "class Switch_qdgd:\n",
    "    \n",
    "    def __create_mixing_matrix(self, topology, n_cores):\n",
    "        if topology == 'ring':\n",
    "            W = np.zeros(shape=(n_cores, n_cores))\n",
    "            value = 1./3 if n_cores >= 3 else 1./2\n",
    "            np.fill_diagonal(W, value)\n",
    "            np.fill_diagonal(W[1:], value, wrap=False)\n",
    "            np.fill_diagonal(W[:, 1:], value, wrap=False)\n",
    "            W[0, n_cores - 1] = value\n",
    "            W[n_cores - 1, 0] = value\n",
    "            return W\n",
    "        elif topology == 'centralized':\n",
    "            W = np.ones((n_cores, n_cores), dtype=np.float64) / n_cores\n",
    "            return W\n",
    "        elif topology == 'connected':\n",
    "            W = np.array([[0.6, 0, 0, 0.4, 0],[0.2, 0.8, 0, 0, 0], [0.2, 0.1, 0.4, 0, 0.3], [0, 0, 0, 0.6, 0.4],[0, 0.1, 0.6, 0, 0.3]])\n",
    "            return W\n",
    "        elif topology == 'disconnected':\n",
    "            W = np.eye(n_cores)\n",
    "            return W\n",
    "        else:\n",
    "            print('torus topology!')\n",
    "            assert topology == 'torus'\n",
    "            assert int(np.sqrt(n_cores)) ** 2 == n_cores\n",
    "            G = networkx.generators.lattice.grid_2d_graph(int(np.sqrt(n_cores)),\n",
    "                int(np.sqrt(n_cores)), periodic=True)\n",
    "            W = networkx.adjacency_matrix(G).toarray()\n",
    "            for i in range(0, W.shape[0]):\n",
    "                W[i][i] = 1\n",
    "            W = W / 5\n",
    "            return W\n",
    "        \n",
    "    \n",
    "    def __init__(self, params: Parameters):\n",
    "        self.params=params\n",
    "        # super().__init__()\n",
    "        # super().__init__(params)\n",
    "        self.x = None\n",
    "        self.x_estimate = None\n",
    "        self.W = self.__create_mixing_matrix(params.topology, params.n_cores) # topology='connected', n_cores=5\n",
    "  \n",
    "    def __quantize(self, x):\n",
    "        # quantize according to quantization function\n",
    "        # x: shape(num_features, n_cores)\n",
    "        if self.params.quantization in ['qsgd-biased', 'qsgd-unbiased']:\n",
    "            is_biased = (self.params.quantization == 'qsgd-biased')\n",
    "            assert self.params.num_levels\n",
    "            q = np.zeros_like(x) #creat q\n",
    "            for i in range(0, q.shape[1]):\n",
    "                q[:, i] = qsgd_quantize(x[:, i], self.params.num_levels, is_biased)\n",
    "            return q\n",
    "        if self.params.quantization == 'full':\n",
    "            return x\n",
    "        if self.params.quantization == 'top':\n",
    "            q = np.zeros_like(x)\n",
    "            k = self.params.coordinates_to_keep\n",
    "            for i in range(0, q.shape[1]):\n",
    "                indexes = np.argsort(np.abs(x[:, i]))[::-1]\n",
    "                q[indexes[:k], i] = x[indexes[:k], i]\n",
    "            return q\n",
    "        \n",
    "    def __quantize_1(self, x):\n",
    "        \n",
    "        if self.params.quantization in ['qsgd-biased', 'qsgd-unbiased']:\n",
    "            is_biased = (self.params.quantization == 'qsgd-biased')\n",
    "            assert self.params.num_levels\n",
    "            q = np.zeros_like(x)\n",
    "            for i in range(0, q.shape[1]):\n",
    "                q[:, i] = qsgd_quantize_1(x[:, i], self.params.num_levels, is_biased)\n",
    "            return q\n",
    "        if self.params.quantization == 'full':\n",
    "            return x\n",
    "        if self.params.quantization == 'top':\n",
    "            q = np.zeros_like(x)\n",
    "            k = self.params.coordinates_to_keep\n",
    "            for i in range(0, q.shape[1]):\n",
    "                indexes = np.argsort(np.abs(x[:, i]))[::-1]\n",
    "                q[indexes[:k], i] = x[indexes[:k], i]\n",
    "            return q\n",
    "\n",
    "    def lr(self, t_list, iteration):\n",
    "        p = self.params\n",
    "        t = iteration\n",
    "        \n",
    "        if t <= t_list[0]:\n",
    "            lrep = p.initial_lr / (1 + p.regularizer * (t) ** p.lr_alpha)\n",
    "            lret = p.initial_lr / (1 + p.regularizer * (t) ** p.lr_beta)\n",
    "        elif t > t_list[-2] and t < t_list[-1]:\n",
    "            lrep = p.initial_lr / (1 + p.regularizer * (t_list[-2]) ** p.lr_alpha)\n",
    "            lret = p.initial_lr / (1 + p.regularizer * (t_list[-2]) ** p.lr_beta)\n",
    "        elif t >= t_list[-1]:\n",
    "            lrep = p.initial_lr / (1 + p.regularizer * (t) ** p.lr_alpha)\n",
    "            lret = p.initial_lr / (1 + p.regularizer * (t) ** p.lr_beta)\n",
    "            pre_idx = t_list[-1] + math.ceil(p.lr_ck/(p.initial_lr / (1 + p.regularizer * (t) ** p.lr_alpha)))\n",
    "            t_list.append(pre_idx)\n",
    "            \n",
    "        return t_list, lrep, lret\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        \n",
    "        # y = np.copy(y_init)\n",
    "        # num_samples, num_features = A.shape\n",
    "        p = self.params\n",
    "        num_samples, num_features = [1,2]\n",
    "        # losses = np.zeros(p.num_epoch + 1)\n",
    "        losses = np.zeros(p.num_iterations + 1)\n",
    "        x_list = np.zeros((p.num_iterations+1, num_features, p.n_cores))\n",
    "        data = []  \n",
    "    \n",
    "        INIT_WEIGHT_STD= 0.05\n",
    "        # Initialization of parameters\n",
    "        if self.x is None:\n",
    "            self.x = np.random.normal(0, INIT_WEIGHT_STD, size=(num_features,))\n",
    "            self.x = np.tile(self.x, (p.n_cores, 1)).T\n",
    "            print(self.x)\n",
    "            self.x_estimate = np.copy(self.x)\n",
    "            self.x_hat = np.copy(self.x)\n",
    "            if p.method == 'old':\n",
    "                self.h = np.zeros_like(self.x)\n",
    "                alpha = 1. / (A.shape[1] / p.coordinates_to_keep + 1)\n",
    "\n",
    "        # splitting data onto machines, p.distribute_data == none\n",
    "        if p.distribute_data:\n",
    "            np.random.seed(p.split_data_random_seed)\n",
    "            num_samples_per_machine = num_samples // p.n_cores\n",
    "            if p.split_data_strategy == 'random':\n",
    "                all_indexes = np.arange(num_samples)\n",
    "                np.random.shuffle(all_indexes)\n",
    "            elif p.split_data_strategy == 'naive':\n",
    "                all_indexes = np.arange(num_samples)\n",
    "            elif p.split_data_strategy == 'label-sorted':\n",
    "                all_indexes = np.argsort(y)\n",
    "\n",
    "            indices = []\n",
    "            for machine in range(0, p.n_cores - 1):\n",
    "                indices += [all_indexes[num_samples_per_machine * machine:\\\n",
    "                                        num_samples_per_machine * (machine + 1)]]\n",
    "            indices += [all_indexes[num_samples_per_machine * (p.n_cores - 1):]]\n",
    "            print(\"length of indices:\", len(indices))\n",
    "            print(\"length of last machine indices:\", len(indices[-1]))\n",
    "        else:\n",
    "            num_samples_per_machine = num_samples\n",
    "            indices = np.tile(np.arange(num_samples), (p.n_cores, 1))\n",
    "        # should have shape (num_machines, num_samples)\n",
    "\n",
    "        # if cifar10 or mnist dataset, then make it binary\n",
    "        # if len(np.unique(y)) > 2:\n",
    "        #     y[y < 5] = -1\n",
    "        #     y[y >= 5] = 1\n",
    "        # print(\"Number of different labels:\", len(np.unique(y)))\n",
    "        # epoch 0 loss evaluation\n",
    "        seq_loss = logistic_loss(self.x, l2=0.1)\n",
    "        losses[0] = np.sum(seq_loss) / len(seq_loss)                                         \n",
    "        print(losses)\n",
    "        # compute_loss_every = int(num_samples_per_machine / LOSS_PER_EPOCH)\n",
    "        # all_losses = np.zeros(int(num_samples_per_machine * p.num_epoch / compute_loss_every) + 1)\n",
    "        compute_loss_every = 1000\n",
    "        \n",
    "        losses = np.zeros(p.num_iterations + 1)\n",
    "        \n",
    "\n",
    "        train_start = time.time()\n",
    "        np.random.seed(p.random_seed)\n",
    "       \n",
    "        \n",
    "\n",
    "        t_list = [p.t_0,]\n",
    "\n",
    "        pre_idx = p.t_0 + math.ceil(p.lr_ck/(p.initial_lr / (1 + p.regularizer * (p.t_0) ** p.lr_alpha)))\n",
    "        t_list.append(pre_idx)\n",
    "        lrep_list = []\n",
    "        lret_list = []\n",
    "        \n",
    "        for t in np.arange(p.num_iterations):\n",
    "            # for iteration in range(num_samples_per_machine):\n",
    "                #t = epoch * num_samples_per_machine + iteration\n",
    "                loss = logistic_loss(self.x, l2=0.1)\n",
    "                x_list[t] = self.x\n",
    "                losses[t] = np.sum(loss) / len(loss) \n",
    "                \n",
    "#                 if t % compute_loss_every == 0:\n",
    "#                     print('iteration {} x{} loss {} losses {}'.format( t, self.x, \n",
    "#                          loss, losses[t]))\n",
    "                       \n",
    "#                     if np.isinf(losses[t]) or np.isnan(losses[t]):\n",
    "#                         print(\"finish training\")\n",
    "#                         break\n",
    "\n",
    "                # lr = self.lr(epoch, iteration, num_samples_per_machine, num_features)\n",
    "                t_list, lrep, lret = self.lr (t_list, t)   \n",
    "                # print('lrep', lrep, 'lret', lret)\n",
    "                lrep_list.append([lrep])\n",
    "                lret_list.append([lret])\n",
    "                \n",
    "                # if t in t_list:\n",
    "                if t % 10 == 0:\n",
    "                    \n",
    "                    # data.append([t, self.x, loss, losses[t]])\n",
    "                    # data.append([t] + self.x.ravel().tolist() + [loss, losses[t]])\n",
    "                    y=[]\n",
    "                    for i in range(len(self.x)):\n",
    "                        for j in range(len(self.x[i])):\n",
    "                            y.append(self.x[i][j])\n",
    "                    # print([t] + y + [loss, losses[t]])\n",
    "                    \n",
    "                    data.append([t] + y + [loss, losses[t]])\n",
    "                    # data.append( y )\n",
    "                    # data.append( losses[t] )\n",
    "                   \n",
    "                    \n",
    "                    \n",
    "                    # print(data)\n",
    "\n",
    "\n",
    "                    print('iteration {} x1{} x2{} loss {} losses {}'.format( t, self.x[0], self.x[1], \n",
    "                         loss, losses[t]))\n",
    "                       \n",
    "                    if np.isinf(losses[t]) or np.isnan(losses[t]):\n",
    "                        print(\"finish training\")\n",
    "                        break\n",
    "\n",
    "                # Gradient step\n",
    "                x_plus = np.zeros_like(self.x)\n",
    "                for machine in range(0, p.n_cores):\n",
    "                    # sample_idx = np.random.choice(indices[machine])\n",
    "                    # a = A[sample_idx]\n",
    "                    x = self.x[:, machine]\n",
    "                    minus_grad = logistic_gradient (x, l2=0.1, normalize=True)   \n",
    "                    \n",
    "                    # minus_grad = y[sample_idx] * a * sigmoid(-y[sample_idx] * a.dot(x).squeeze())\n",
    "                    # if isspmatrix(a):\n",
    "                    #     minus_grad = minus_grad.toarray().squeeze(0)\n",
    "                    # if p.regularizer:\n",
    "                    #     minus_grad -= p.regularizer * x\n",
    "                    x_plus[:, machine] = (1-lrep) * x  - [lret * grad for grad in minus_grad]\n",
    "\n",
    "                # Communication step\n",
    "                if p.method == \"plain\":\n",
    "                    self.x = (self.x + x_plus).dot(self.W)\n",
    "                if p.method == \"choco\":\n",
    "                    x_plus += self.x\n",
    "                    self.x = x_plus + p.consensus_lr * self.x_hat.dot(self.W - np.eye(p.n_cores))\n",
    "                    quantized = self.__quantize(self.x - self.x_hat)\n",
    "                    self.x_hat += quantized\n",
    "                elif p.method == 'dcd-psgd':\n",
    "                    x_plus += self.x.dot(self.W)\n",
    "                    quantized = self.__quantize(x_plus - self.x)\n",
    "                    self.x += quantized\n",
    "                elif p.method == 'ecd-psgd':\n",
    "                    x_plus += self.x_hat.dot(self.W)\n",
    "                    z = (1 - 0.5 * (t + 1)) * self.x + 0.5 * (t + 1) * x_plus\n",
    "                    quantized = self.__quantize(z)\n",
    "                    self.x = np.copy(x_plus)\n",
    "                    self.x_hat = (1 - 2. / (t + 1)) * self.x_hat + 2./(t + 1) * quantized\n",
    "                elif p.method == 'sample-hold':\n",
    "                    if t % 2 == 0:\n",
    "                        quantized = self.__quantize(self.x)\n",
    "                    else:\n",
    "                        quantized = self.__quantize_1(self.x)\n",
    "\n",
    "                    self.x = x_plus + lrep * (quantized).dot(self.W)\n",
    "                    \n",
    "                \n",
    "                csv_file = 'optimization_log.csv'\n",
    "                write_header = not os.path.isfile(csv_file)\n",
    "\n",
    "        with open(csv_file, 'a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            # if write_header:\n",
    "                # writer.writerow(['Iteration', 'x', 'Loss', 'Total Loss'])\n",
    "            writer.writerows(data)\n",
    "\n",
    "        print(\"Training took: {}s\".format(time.time() - train_start))\n",
    "\n",
    "        return losses, x_list\n",
    "    \n",
    "# switch_qsdg = Switch_qdgd (t_0=2700, num_iterations=10000,lr_alpha = 0.64,lr_beta = 0.94,lr_ck = 1)\n",
    "p_param=Parameters(t_0=10, num_iterations=8000, lr_alpha = 0.62, lr_beta = 0.94, lr_ck = 3, num_levels=10)\n",
    "switch_qsdg = Switch_qdgd (p_param)\n",
    "losses, x_list = switch_qsdg.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf8e02-57af-4c5a-8710-d9d519f378a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
